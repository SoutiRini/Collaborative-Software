[{"count": 0, "tags": [], "bug_id": 28727, "attachment_id": null, "text": "We use Tomcat 5.018/5.0.19 in a mission critical application. Every second or \nthird try specific connections fail. Tomcat then seems to be unable to close \nthe connections, although the client already has terminated its session (and \nshutdown his computer). Within Tomcat the connections are left \nas \"CLOSE_WAIT\". (=> netstat -a)\n\nAs soon as one connection shows up as \"CLOSE_WAIT\", the connection-thread \nbegins to loop (seems as if select is no more blocking) and starts to eat up \ncpu power. When two or three threads are in the state \"CLOSE_WAIT\", Tomcat \nperformance slows down until the non-blocking \"CLOSE_WAIT\"-threads are \nconsuming everything.\n\nWe have to shutdown Tomcat then.\n\nWhat is happening here? Is there a workaround available? What about the CLOSE-\nWAIT-connections (they are all issued via mobile clients via GPRS)\n\nWe tried both Tomcat 5.0.19 and 5.0.18. Same situation.\n\n\nEnvironment: \nWindows 2000/XP, Service Packs applied; Apache 2.0.47, Mode_JK2, JDK1.4.2_03 \nand JDK 1.4.2_04 (tried both, both SUN)", "id": 56714, "time": "2004-05-01T18:49:25Z", "creator": "thomas.strasser@silbergrau.com", "creation_time": "2004-05-01T18:49:25Z", "is_private": false}, {"count": 1, "tags": [], "bug_id": 28727, "attachment_id": null, "id": 56979, "creation_time": "2004-05-07T10:54:42Z", "time": "2004-05-07T10:54:42Z", "creator": "remm@apache.org", "text": "I can't reproduce this, and I have yet to experience one of your \"non-blocking\nCLOSE_WAIT-threads\". What is exactly \"looping\", and do you have any idea why ?\nIs it the Apache <-> Tomcat link which has a problem ?\nGiven that we can't really look into it, you'll have to provide more details if\nyou want a fix.", "is_private": false}, {"count": 2, "tags": [], "creator": "ensorn@osti.gov", "attachment_id": null, "id": 62157, "time": "2004-08-19T01:45:50Z", "bug_id": 28727, "creation_time": "2004-08-19T01:45:50Z", "is_private": false, "text": "I'm experiencing something similar I believe using Tomcat 5.0.27 on an\napplication server that's proxied over from another (Apache) web front-end.  The\napplication runs fine for a time, but quickly CLOSE_WAIT connections to the\nApache server start building up and the TC5 server becomes completely\nnon-responsive.  truss-ing the Tomcat process reveals some sort of looping activity:\n\n/88:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n/111:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/65:    lwp_cond_wait(0x0078EE88, 0x0078EE70, 0x00000000) (sleeping...)\n/84:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n/9:     lwp_cond_wait(0x0002D020, 0x0002D008, 0x00000000) (sleeping...)\n/141:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/25:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n/118:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/60:    lwp_cond_wait(0x00D4DDF0, 0x00D4DDD8, 0x00000000) (sleeping...)\n/42:    lwp_cond_wait(0x003FF4A8, 0x003FF490, 0xEE9FF7F0) (sleeping...)\n/68:    lwp_cond_wait(0x00791258, 0x00791240, 0xECFFF7F0) (sleeping...)\n/61:    lwp_cond_wait(0x00D4E4A0, 0x00D4E488, 0x00000000) (sleeping...)\n/158:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/107:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/22:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n/112:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/71:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n/183:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/54:    lwp_cond_wait(0x0045D220, 0x0045D208, 0x00000000) (sleeping...)\n/16:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n/144:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/114:   lwp_mutex_lock(0x000EC290)      (sleeping...)\n/23:    lwp_mutex_lock(0x000EC290)      (sleeping...)\n\nfollowed by many lines of :\n/10:    poll(0xF98FFD58, 0, 50)                         = 0\n/2:     lwp_cond_wait(0x0002CB80, 0x0002CB68, 0xFC77FD30) Err#62 ETIME\n\nDuring this time, Tomcat is apparently sleeping, and completely non-responsive.\nA restart results in the server responding again for a short time, then going\nback into the same state.\n\nApache 1.3.27 on web server, using ProxyPass to the application server, Solaris\n9 OS, JVM 1.4.2_04.  Tomcat version 5.0.27. Any pointers would be appreciated."}, {"count": 3, "tags": [], "creator": "yoavs@computer.org", "attachment_id": null, "id": 62795, "time": "2004-08-30T18:59:25Z", "bug_id": 28727, "creation_time": "2004-08-30T18:59:25Z", "is_private": false, "text": "Does it happen with Tomcat-standalone, i.e. no Apache or connector in front?"}, {"count": 4, "tags": [], "creator": "yoavs@computer.org", "text": "Can you also please try Tomcat 5.0.28 and the latest connector binary (1.2.6 \nfor mod_jk)?\n\nI'm downgrading this from a Blocker severity to normal, as no one else has \ncomplaind, and we haven't been able to reproduce it.", "id": 63615, "time": "2004-09-15T18:18:21Z", "bug_id": 28727, "creation_time": "2004-09-15T18:18:21Z", "is_private": false, "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 28727, "text": "I can confirm this bug on jakarta-tomcat-5.0.19-embed on Solaris 2.8\n\nSuddenly, CLOSE_WAIT connections start to grow and the whole application\nwhich embeds tomcat becomes unresponsive.\nI understand it is hard to reproduce this bug, but this is a blocker for us.\nOf course, I can help checking new versions where this issue has been addressed.\n\nPlatform:\nSunOS e4500 5.8 Generic_108528-16 sun4u sparc SUNW,Ultra-Enterprise\nj2re1.4.2_02", "count": 5, "id": 64117, "time": "2004-09-23T17:45:41Z", "creator": "aquilino@dreamteam.it", "creation_time": "2004-09-23T17:45:41Z", "is_private": false}, {"attachment_id": null, "tags": [], "bug_id": 28727, "text": "Well, then please try newer versions than 5.0.19 ;)", "count": 6, "id": 64118, "time": "2004-09-23T17:47:10Z", "creator": "yoavs@computer.org", "creation_time": "2004-09-23T17:47:10Z", "is_private": false}, {"attachment_id": null, "tags": [], "bug_id": 28727, "text": "I'm going to switch to Tomcat 5.0.28 embedded.\nThe bug usually shows up in 2/3 days, depending on users activity.\n", "count": 7, "id": 64162, "time": "2004-09-24T10:41:15Z", "creator": "aquilino@dreamteam.it", "creation_time": "2004-09-24T10:41:15Z", "is_private": false}, {"count": 8, "tags": [], "text": "Please keep us posted ;)  I don't want to leave the issue open forever without \nus being able to reproduce it.", "attachment_id": null, "bug_id": 28727, "id": 64455, "time": "2004-09-30T19:12:04Z", "creator": "yoavs@computer.org", "creation_time": "2004-09-30T19:12:04Z", "is_private": false}, {"attachment_id": null, "tags": [], "bug_id": 28727, "text": "Tomcat calls close on all the sockets, in a very obvious way. After that, if the\nsocket isn't properly closed, then it's a bug in either the VM or the network stack.", "count": 9, "id": 64457, "time": "2004-09-30T20:31:42Z", "creator": "remm@apache.org", "creation_time": "2004-09-30T20:31:42Z", "is_private": false}, {"attachment_id": null, "tags": [], "bug_id": 28727, "text": "I can confirm this bug on jakarta-tomcat-5.0.28-embed on Solaris 2.8\n\n\nHere are my suggestions to reproduce it:\n\n- start Tomcat on server S\n\n- monitor the status of connections on server S\nwhile(1)\nnetstat -a|grep CLOSE_WAIT|wc -l\nsleep 5\nend\n\n- establish more than 500 concurrent HTTP connections from client C\n(We used JMeter to run a work job with 500 threads, 5 requests each)\n\n- DETACH THE NETWORK CABLE on client C\nwhen you are sure the server is managing at least 500 connections from C\n\n- ATTACH THE NETWORK CABLE on client C\n\nExpected result:\nConnections in CLOSE_WAIT status get closed gracefully on server S.\n\nActual Result:\nConnections in CLOSE_WAIT status never get closed on server S.\nIf you connect to the Tomcat server, response time is very slow.\nThe number of connections in CLOSE_WAIT status keeps growing.\n\n\nThanks for your time and efforts\n\n\n", "count": 10, "id": 64702, "time": "2004-10-06T16:02:05Z", "creator": "aquilino@dreamteam.it", "creation_time": "2004-10-06T16:02:05Z", "is_private": false}, {"count": 11, "tags": [], "bug_id": 28727, "attachment_id": null, "text": "I am not really interested in observations on the \"problem\".\nPlease reopen this report only when you can actually prove that Tomcat is at\nfault. Tomcat will call close on all these sockets. If they are not properly\nclosed for some reason, then there is nothing that can be done here.", "id": 64703, "time": "2004-10-06T16:10:34Z", "creator": "remm@apache.org", "creation_time": "2004-10-06T16:10:34Z", "is_private": false}, {"count": 12, "tags": [], "creator": "aquilino@dreamteam.it", "attachment_id": null, "id": 64704, "time": "2004-10-06T16:38:20Z", "bug_id": 28727, "creation_time": "2004-10-06T16:38:20Z", "is_private": false, "text": "Sorry,\nI just suggested how to reproduce this bug. That's not \"observations\".\n\nAs far as \"Tomcat fault\" is concerned, let me know which evidence\ndo you need, as a non-responsive Tomcat server draining 100% of cpu is not enough.\n\n"}, {"count": 13, "tags": [], "creator": "remm@apache.org", "attachment_id": null, "id": 64705, "time": "2004-10-06T16:48:03Z", "bug_id": 28727, "creation_time": "2004-10-06T16:48:03Z", "is_private": false, "text": "It's obviously not enough. If you cannot point out some flaw with socket\nhandling in Tomcat, or indicate where it would go into a loop, then there's\nnothing I can fix.\n\nSince you're using Solaris, please first make sure you have applied ALL service\npacks and stuff (Sun fixes Java on Solaris this way)."}, {"count": 14, "tags": [], "creator": "aquilino@dreamteam.it", "text": "The solaris server we use to run Tomcat is up to date.\nHowever, the \"OS\" field of this bug is Windows XP,\nso it doesn't seem to be a platform issue.\n\nI checked and we do not use a particular SocketFactory, or set any socket params.\n\nI believe the Connection pool could lock up itself when too many\nconnections have to be closed. \n", "id": 64713, "time": "2004-10-06T18:27:37Z", "bug_id": 28727, "creation_time": "2004-10-06T18:27:37Z", "is_private": false, "attachment_id": null}, {"count": 15, "tags": [], "creator": "rainer.jung@kippdata.de", "text": "I suggest you try to reproduce first with only 10 or 50 threads. Reproduction\nwould be successful, if you still observe continuous CPU usage in this case,\nmaybe less than 100%, but still noticeable.\n\nThen in this state you take a Thread Dump (sending the QUIT signal to the tomcat\nprocess). It will write the method stack for all threads inside tomcat to\ncatalina.out. Wait a few seconds an take another Thread Dump, again wait and\ntake a third one.\n\nThen look at the stacks of your working threads. Anything special about the top\npart of the individual stacks?\n", "id": 64731, "time": "2004-10-07T06:56:11Z", "bug_id": 28727, "creation_time": "2004-10-07T06:56:11Z", "is_private": false, "attachment_id": null}, {"count": 16, "tags": [], "creator": "remm@apache.org", "text": "Right. Stack traces showing some kind of bad behavior with the Tomcat code would\nbe a start.", "id": 64734, "time": "2004-10-07T09:18:40Z", "bug_id": 28727, "creation_time": "2004-10-07T09:18:40Z", "is_private": false, "attachment_id": null}, {"count": 17, "tags": [], "text": "BTW, for that kind of problem, would it be possible to test using the new thread\npool from Tomcat 5.5 ?\nGet Tomcat 5.5.3, and set strategy=\"ms\" on the Connector element.", "attachment_id": null, "bug_id": 28727, "id": 64735, "time": "2004-10-07T09:54:06Z", "creator": "remm@apache.org", "creation_time": "2004-10-07T09:54:06Z", "is_private": false}, {"count": 18, "tags": [], "creator": "evans@hansenet.com", "attachment_id": null, "id": 90913, "time": "2006-07-05T15:40:28Z", "bug_id": 28727, "creation_time": "2006-07-05T15:40:28Z", "is_private": false, "text": "We are seeing exactly the same symptoms with Tomcat/5.0.28 (on Linux).  Yes, I\nknow, this is pretty old.  But it worked well enough until we changed to a\ndifferent architecture that causes more load.  As we already have the latest\nmod_jk it would appear that tomcat is the problem.  Does anybody see this\nproblem any more with 5.5? "}, {"attachment_id": null, "tags": [], "bug_id": 28727, "text": "I think it is been resolved. Please check this\nhttp://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6215050 \nThe java 1.4.2.12 and java 1.5.0.07 should fix the problem.\n", "count": 19, "id": 91468, "time": "2006-07-21T16:48:32Z", "creator": "jay.qu@ncmail.net", "creation_time": "2006-07-21T16:48:32Z", "is_private": false}, {"count": 20, "tags": [], "creator": "pksudhir@yahoo.com", "attachment_id": null, "id": 114015, "time": "2008-02-22T04:20:47Z", "bug_id": 28727, "creation_time": "2008-02-22T04:20:47Z", "is_private": false, "text": "Same Problem faced on solaries10 related to CLOSE_WAIT.Even I reduced \ntcp_time_wait_interval kernel parameter 10000(ms)."}, {"count": 21, "tags": [], "bug_id": 28727, "attachment_id": null, "id": 101740, "creation_time": "2008-02-26T01:54:29Z", "time": "2008-02-26T01:54:29Z", "creator": "bugmenot@lortemail.dk", "text": "also happens with debian:\n\nJava HotSpot(TM) 64-Bit Server VM (build 1.6.0_02-b05, mixed mode)\napache-tomcat-6.0.14\nlibapache-mod-jk 1.2.18-3etch1\n", "is_private": false}, {"count": 22, "tags": [], "creator": "bugmenot@lortemail.dk", "attachment_id": null, "id": 101327, "time": "2008-02-26T02:49:32Z", "bug_id": 28727, "creation_time": "2008-02-26T02:49:32Z", "is_private": false, "text": "(In reply to comment #21)\n> Java HotSpot(TM) 64-Bit Server VM (build 1.6.0_02-b05, mixed mode)\n> apache-tomcat-6.0.14\n> libapache-mod-jk 1.2.18-3etch1\n\nmy fault. Works for me!\n\nI am using apache httpclient class, which doesnt close sockets correctly. See\nhttp://www.mail-archive.com/commons-httpclient-dev@jakarta.apache.org/msg04338.html \n\n"}, {"count": 23, "tags": [], "bug_id": 28727, "attachment_id": null, "text": "Re-closing as invalid based on last comment.", "id": 114159, "time": "2008-03-01T10:23:38Z", "creator": "markt@apache.org", "creation_time": "2008-03-01T10:23:38Z", "is_private": false}]