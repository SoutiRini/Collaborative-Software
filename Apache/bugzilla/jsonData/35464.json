[{"count": 0, "tags": [], "creator": "francois.robert@unisys.com", "attachment_id": null, "is_private": false, "id": 76601, "time": "2005-06-22T13:43:01Z", "bug_id": 35464, "creation_time": "2005-06-22T13:43:01Z", "text": "I am new to Ant. We are using it in a Configuration Management context. Here is \nthe situation :\n\nPreliminary definition: Targets in a build.xml files can be broadly divided into \ntwo categories : Target that produce a \"deliverable\" (ie. something that will be \npassed to the customer/QA group/etc... Typically, a deliverable is a jar file, \nan executable, a shared object...) and those that don't (deployments, cleanup, \ntests etc...)\n\n- We have a bunch of distinct build.xml files, which are used to build Java-\nbased deliverables (for now). Each Ant file typically builds a handfull of \ndeliverables.\n- The deliverables can be built in debug or release \"flavor\" (or maybe some \nother, like \"instrumented\" ...)\n- The building process of all deliverables is sprayed accross all the different \nant files.\n- Deliverables have dependencies on other deliverables, whose target is not \nnecessarily located in the same ant file. In other words, the entire build \nprocess must run all build.xml files, but in a specific order, passing specific \ntargets.\n\nThe problem is : I neeed to determine (automatically) : \n- What are the deliverables that can be produced by all the ant files.\n- What target in what file will produce what deliverable(s).\n- What target depend on what other target in which ant file.\n- The \"flavor\" of each deliverable.\n\nThe objective is to create automatically a \"master\" ant file that can produce \nall the deliverables. (by calling <ant> or <subant> against the right file and \nthe right targets, with the right expression of dependencies).\n\nTo achieve this, a minimum parsing of each build.xml is necessary, but without \nexecution (or rather: replacing the execution of most task with emitting on \nstandard output what would be executed. A few tasks, such as <ant>, <subant>, \n<property> and the like needs to be \"executed\", however). This is what I call a \n\"dry-run\". \nIdeally, for my particular need, the \"dry-run\" should span multiple ant files \n(but that may not fit too well with the general philosophy of having Ant \nexecuting a single file at a time). A dry run mode would also what are the \ndependencies of each target and what are the deliverables produced by each \ntarget (and what is its \"flavor\")\n\nI have tried to implement the scenario above and here are some observations I \ngathered during this attempt (for what it's worth).\n- I first thought of parsing the Ant file through the Ant API (a bit like the \nGrand tool) but then I am a bit stuck with property resolution and sub-builds \nexecution.\n- A second approach that I then looked into was to redefine core and optionnal \ntasks with appropriate no-op task (except for sub-builds and <property> tasks \nand maybe others).  I then thought that such a definition could done inside each \ntask class (with a dry-run flag added or maybe with some OO trick), or that a \nmodified class loader pointing to a different set of class files may do the \ntrick. \n- The definition of \"deliverable\" is fuzzy. Typically, in any build process, \nsome \"intermediate compilation products\" (static library, object files, class \nfiles etc...) are also produced. Those usually don't qualify as deliverable \nbecause they are consumed by some other subsequent build action. Tracking what \nis produced and consumed by the various steps is not easy (and may well be \nimpossible with <taskdef>s, unless the task writer somewhat hints what are the \ninputs and outputs of its task) but is essentially what allows to distinguish \nbetween \"deliverables\" and mere temporary files. It also allows to assign a \n\"flavor\" to a deliverable: If we track the compilation settings (debug, release, \ninstrumented, optimized, whatever...) of intermediate products, then you can \nassign a \"flavor\" to each deliverable down the chain as well. You can also flag \nsituations like mixing different flavors in the same deliverable/intermediate \nproduct (which is most of a time a mistake)."}, {"count": 1, "tags": [], "bug_id": 35464, "text": "I'm not sure that this can be done. It isnt enough to parse the file, you have\nto know the output of every single task in the system. In make (i.e. make -n)\nthe output is there, as it is just walking the dependency chain you specify by\nhand. \n\nIn ant, things work it out for themselves, based on (chained) input files. you\nneed to know the output of all predecessors before you can predict what the next\ncomponents will do, something that is done using the filesystem as a persistent\nstate communication mechanism.\n\nNow Maven, that does have a more explicit model of deliverables, and you may\nwant to look at that to see if it works on your (seemingly large/complex)\nproject. For reference, I use their ant tasks and have sub projects deploy into\nthe maven repository on a local machine, as a way of decoupling projects from\neach other.\n\nI would also encourage looking at the <import> task in Ant1.6+, which lets you\nshare stuff across projects. Having many sub projects does not imply lots of\nduplicated code. If you can have everything share the same build files, you will\nstay in control.", "id": 76609, "time": "2005-06-22T17:26:05Z", "creator": "stevel@apache.org", "creation_time": "2005-06-22T17:26:05Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "creator": "francois.robert@unisys.com", "attachment_id": null, "text": "Thanks for your (fast !) answers and suggestions. I will definitely have a look \nat Maven, to see whether it can help me. \n\nRegarding <import>. Can you elaborate a bit more ? Are you suggesting to write a \ntop level ant file that call others via <import> ?  Or did I miss the point ? (I \nwant to avoid writting -and maintaining...- a top-level build file, because it's \nso easy do get it out-of-synch with the child projects)\n\nThe point is that the projects have no direct knowledge of each other. \nDependencies are basically expressed indirectly, through the content of the \n\"classpath\" settings.\n\nHo. And then there is Eclipse. At some point in the future, I want to be able to \ncheck that all build.xml are in synch with Eclipse projects (same classpath, \nbasically...). Admitedly, this has nothing to do directly with a \"dry-run\" \nfeature per se. It may however help you frame the business use case I have in my \nhands...", "id": 76611, "time": "2005-06-22T18:00:38Z", "bug_id": 35464, "creation_time": "2005-06-22T18:00:38Z", "is_private": false}, {"count": 3, "tags": [], "bug_id": 35464, "attachment_id": null, "id": 76614, "time": "2005-06-22T18:32:01Z", "creator": "francois.robert@unisys.com", "creation_time": "2005-06-22T18:32:01Z", "is_private": false, "text": "One more bit of context : The source control system is imposed and is Rational \nClearCase, which means that sources and projects files are typically fetched \nfrom a remote, special Windows or Unix filesystem (called MultiVersion \nFileSystem or MVFS)."}, {"count": 4, "tags": [], "creator": "stevel@apache.org", "attachment_id": null, "is_private": false, "id": 76632, "time": "2005-06-22T23:40:08Z", "bug_id": 35464, "creation_time": "2005-06-22T23:40:08Z", "text": "the way I work in a big project, we have one common file (common.xml), that\ncontains the base targets for everything. \n\nchild projects <import> this, and override targets only if they need to do\nsomething different. \n\nThis isnt perfect, common.xml is a bit scary now, but it means we can have 10+\nprojects all in sync. To add new targets is easy too.\n\nfor file sharing, we have targets to put versioned files into the m2 repository\ntree, and other build files can pull them out, with .properties files driving\nversion control. this gives us a unified way of dealing with our own artifacts\nas well as remote things. \n\nhere is the target from one project, for example\n\n  <target name=\"m2-files\" depends=\"m2-tasks\">\n    <m2-libraries pathID=\"m2.classpath\">\n      <dependency groupID=\"org.ggf\"\n        artifactID=\"cddlm\"\n        version=\"${cddlm.version}\"/>\n      <dependency groupID=\"commons-lang\"\n        artifactID=\"commons-lang\"\n        version=\"${commons-lang.version}\"/>\n      <dependency groupID=\"commons-logging\"\n        artifactID=\"commons-logging-api\"\n        version=\"${commons-logging.version}\"/>\n      <dependency groupID=\"log4j\"\n        artifactID=\"log4j\"\n        version=\"${log4j.version}\"/>\n      <dependency groupID=\"org.smartfrog\"\n        artifactID=\"sf-xml\"\n        version=\"${Version}\"/>\n      <dependency groupID=\"xom\"\n        artifactID=\"xom\"\n        version=\"${xom.version}\"/>\n      <dependency groupID=\"xalan\"\n        artifactID=\"xalan\"\n        version=\"${xalan.version}\"/>\n    </m2-libraries>\n  </target>\n\nregarding clearcase, it scares me. when it works, it is wonderful, but when it\ngoes wrong, you are truly hosed. And mostly works well on it, but if something\nlike your clean target keeps failing, reboot your box and try again before\nfiling a bug that <delete> doesnt work. Also note that the filesystem is\nslightly case sensitive, even on windows. "}, {"count": 5, "tags": [], "creator": "francois.robert@unisys.com", "attachment_id": null, "is_private": false, "id": 76736, "time": "2005-06-27T15:52:58Z", "bug_id": 35464, "creation_time": "2005-06-27T15:52:58Z", "text": "Firstly, I had a quick look at Maven. I am not too sure how suitable it is to my \nneed. \nIn fact, thinking again about my business use case, I now believe that I am \ntrying to achieve something closer to \"auditing\" or \"monitoring\" (more passive \nbehavior) than to \"building\" (more prescriptive behavior).\nThe idea is that I could have an overall view of that *can* be built from the \nsource, which is a superset of what *will* be built. If something is added or \nremoved, (even if should not be built) then I can see that as well.\n\nAlso, I thought about Steve Loughran's observation (comment #1) that \"you need \nto know the output of all predecessors before you can predict what the next \ncomponents will do, something that is done using the filesystem as a persistent \nstate communication mechanism\".\nIndeed. \nThis made me thought about the fact that merely *simulating* the chaining of \ninput and output files on the filesystem could be enough to get a reasonnably \nmeaningful set of deliverables. What I mean is that it is possible to define for \nmany tasks which file(s) name(s) they will consume and which they will emit as a \nresult (assuming successful completion). For instance, the <tar> tasks produces \nwhat is specified in the \"destfile\" attributes and consumes whatever file in the \n\"basedir\" folder whose name match/don't match the include/exclude patterns. \n<javac> produces a set of .class files from a certain set of .java files etc...\nThe idea would be then to simulate the lifecycle of files (production/\nconsumption/deletion), simulate the chaining and deduce from it what are the \ndeliverables.\n\nOf course this scenario breaks in various cases :\n- <taskdefs> : In the current version of Ant, custom-define <taskdefs> have \numpredictable inputs and outputs. If Ant mandated that taskdefs explicitely \ndefine their inputs and outputs, then this issue would disappear.\n- output filename existence that depends on input file contents (and not merely \non existence + Ant build file content). An example is linker output located in \nresponse files. I would suspect that this is truly hard to solve only if the \ninput file is dynamically generated during the build. Otherwise, parsing of \nstatic input files (that exists before the build is started) can do the job \n(Admitedly could be very tedious to cover formats exhaustively, but feasible in \ntheory).\n- A variant of the previous case is when a task has unpredictable output(s) \n(like <get> when used with wildcards). Maybe a deeper/smarter simulation could \nhelp hint the filenames (ie in the case of <get>, obtain a directory listing of \nthe files and track the filenames so obtained ?). Non-Ant scripting may be one \nsticky case where output may be truly unpredictable (<telnet> tasks with \nembedded shell scripting come to mind).\n\nI also have the gut feeling in such a file-lifecycle tracking, outputs are more \nimportant than the input : In many cases, inputs are pattern-based, whereas \noutput is well-defined.\n\nThen there is the fact that simulating all targets (at least all target without \npredecessors) will cause different execution paths, that will yield different \nfile chains, all of which needs to be simulated. That may well cause a \ncombinatorial explosion of cases (?).\n\nOne of the things I don't know is how prevalent in practice are the cases that \ncannot be simulated (I suspect that there may be well more than the above \nmentionned three...).\n\nComments ?\n"}]