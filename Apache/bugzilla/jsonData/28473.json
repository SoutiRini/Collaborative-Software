[{"count": 0, "tags": [], "bug_id": 28473, "attachment_id": null, "text": "Maybe I misunderstand something, but for me it seems that RLimitCPU and \nRLimitMEM do not work. In my httpd.conf, I set\n\nRLimitCPU 2\nRLimitMEM 10485760\n\nwhich - to my understanding - should limit executing time for external scripts \nto 2 seconds and limit the all scripts 10 MB memory limit. This does not work.\n\nI have PHP running as CGI with 2.0.49 on Linux 2.4.26 here, and with a hughe PHP \nfile involving some diagram creation, I can kill the machine if I re-load the \nscript for five seconds continuously. It soaks up all my memory - thus is not \nlimited to 10 MB - and runs for nearly a minute.\n\nWhat could be wrong in here? If you need more information, please let me know. \nThanks!", "id": 56034, "time": "2004-04-19T17:48:04Z", "creator": "floeff@arcor.de", "creation_time": "2004-04-19T17:48:04Z", "is_private": false}, {"count": 1, "tags": [], "creator": "nd@perlig.de", "attachment_id": null, "id": 56040, "time": "2004-04-19T19:08:04Z", "bug_id": 28473, "creation_time": "2004-04-19T19:08:04Z", "is_private": false, "text": "RLimitCPU limits the CPU seconds, not wall clock seconds.\n\nAdditionally both of these directives take a second argument -- a hard limit.\nI don't know, if PHP raises the limits to the max (the hard limit), try setting\nthem as well."}, {"count": 2, "tags": [], "creator": "floeff@arcor.de", "attachment_id": null, "id": 56120, "time": "2004-04-20T17:39:07Z", "bug_id": 28473, "creation_time": "2004-04-20T17:39:07Z", "is_private": false, "text": "In my httpd.conf for Apache 2.0.49, I have set\n\nRLimitCPU 2 2\nRLimitNPROC 1 1\nRLimitMEM 10485760 10485760\n\n(Is this the right syntax?)\n\nbut it still bogs down my server, so no limitation seems to be in effect. I'd be\nhappy to provide you with anything you need, including SSH access to the\nmachine, but this bug has to be fixed ;-)"}, {"count": 3, "text": "Sebastian Marsching from suPHP wrote the following on the mailing list:\n\n===\nThis problem is caused by the fact, that the fork() is done by the \nApache User, so that the RLimit does not really apply for the desired \nuser, I guess.\n\nA solution might be using grsecurity and enabling the \ncheck-rlimit-on-execve feature, which will make the linux kernel to \ncheck for the limits not only on fork()s but also on execve() calls.\n===\n\nMaybe it helps you finding the problem, because I think it should be fixed ASAP ;-)", "bug_id": 28473, "is_private": false, "id": 56182, "time": "2004-04-21T16:41:16Z", "creator": "floeff@arcor.de", "creation_time": "2004-04-21T16:41:16Z", "tags": [], "attachment_id": null}, {"count": 4, "text": "That's just plain wrong. The limits are process attributes and get inherited\n(though they don't apply to the root user itself).\n\nAnyway, I've just tried to reproduce it again, with and without suexec on a\n2.4.26 vanilla kernel with perl and php CGI scripts like below -- it works like\na charm:\n\n#!/usr/bin/php\n<?\n  $i = 0;\n  while(1) { $i = $i + 1; }\n?>\n\nwith a limit of\nRLimit 4\n\nin httpd.conf it stops right after 4 seconds (busy loop) with a 500.", "bug_id": 28473, "attachment_id": null, "id": 56198, "time": "2004-04-21T18:42:25Z", "creator": "nd@perlig.de", "creation_time": "2004-04-21T18:42:25Z", "tags": [], "is_private": false}, {"count": 5, "tags": [], "bug_id": 28473, "is_private": false, "text": "RlimitCPU 4 :-)", "id": 56200, "time": "2004-04-21T18:49:36Z", "creator": "nd@perlig.de", "creation_time": "2004-04-21T18:49:36Z", "attachment_id": null}, {"count": 6, "text": "Thanks for taking the time to test, I really appreciate that a lot! I checked\nsome more things, here some more results:\n\n- Your script terminates fine after about five seconds. I've set two as a limit,\nbut I think the time is okay as it takes some time to close the PHP instance.\nI've checked the status of the script via ps auxw | grep php.\n\n- Your script terminates with \"Premature end of script headers\". No other error\nmessage is shown in the logs. Is that correct or should Apache print out\nsomething like \"I've killed ID so and so\"?\n\n- On my test machine, I've set MaxClients to 20 and I couldn't kill the machine\nanymore. This is only a workaround, as it knocks out a lot of users on higher\nload machines, but at least it shows that MaxClients works for that.\n\n- When a \"normal access\" (i.e. not my \"attack\") accesses a PHP script, the PHP\nparser is only shown during the run of the script, checked with ps auxw | grep\nphp. However, when I \"attack\", it runs for quite a while several times. Possibly\nfor the 300 timeout seconds in httpd.conf, but I'll check that. \"killall php\" or\n\"killall -9 php\" doesn't help. However, shutting down Apache brings down the PHP\ninterpreters, so I think that Apache just \"forgets\" about the running instances\nwhen it is flooded and cannot handle them anymore.\n\nDo you have any idea? Do you need more information? Again, thanks so much for\ntaking the time!", "bug_id": 28473, "attachment_id": null, "id": 56204, "time": "2004-04-21T19:28:13Z", "creator": "floeff@arcor.de", "creation_time": "2004-04-21T19:28:13Z", "tags": [], "is_private": false}, {"count": 7, "tags": [], "creator": "floeff@arcor.de", "text": "Addition: It does NOT seem to use the 300 seconds timeout, as I lowered this to\n10 seconds, but the scripts continued to run.", "id": 56205, "time": "2004-04-21T19:31:26Z", "bug_id": 28473, "creation_time": "2004-04-21T19:31:26Z", "is_private": false, "attachment_id": null}, {"count": 8, "text": "Again an addition ;)\n\nIt indeed DOES use the TimeOut value:\n\n(70007)The timeout specified has expired: ap_content_length_filter:\napr_bucket_read() failed\n\nHowever, it does not help to lower it, the load rises even more. Had about 97\n(!) some seconds ago :-(", "bug_id": 28473, "is_private": false, "id": 56206, "time": "2004-04-21T19:34:56Z", "creator": "floeff@arcor.de", "creation_time": "2004-04-21T19:34:56Z", "tags": [], "attachment_id": null}, {"count": 9, "tags": [], "creator": "nd@perlig.de", "attachment_id": null, "id": 56209, "time": "2004-04-21T19:44:56Z", "bug_id": 28473, "creation_time": "2004-04-21T19:44:56Z", "is_private": false, "text": "The difference between 5 and 2 is probably the difference between CPU seconds\nand wall clock seconds. I've tested on a totally lazy machine (my desktop box\n:-). If the machine is more busy, then it take longer, of course (you get a\nhigher load instead).\nSecondly, the script is not killed by apache. It's killed by the kernel itself.\nTherefore httpd can only determine \"premature end of script headers\".\n\nIt seems to be more a problem of social engeneering, which is per definition not\nsolvable with technical sanctions :-)\n\nFinally - I'm now wondering, what kind of bug are we discussing now?"}, {"count": 10, "tags": [], "creator": "floeff@arcor.de", "text": "Okay, I understood that. ;-)\n\nMy problem still is there: Assume a huge CGI script (because I would say that\nPHP as a CGI and a huge CGI script behave the same way, at least regarding my\nproblem) that soaks up some amount of memory and CPU resources when started. A\n\"bad guy\" can go to the page where the CGI is located, reload it continuously\nfor about 10 seconds an crash the whole server.\n\nThere MUST be a way to limit that, which seems to be currently impossible?! By\nre-loading the script for 10 seconds, I caused a load of 67 (!) on an otherwise\nabsolutely idle 1.7 GHz/256 MB RAM server! Reloading it for 30 seconds and the\nkernel closed nearly all processes including SSH because of swapping issues.\nCan't I do ANYTHING about that (except modifying PHP to check the load average\nbefore starting or writing a manual wrapper)?", "id": 56210, "time": "2004-04-21T19:55:27Z", "bug_id": 28473, "creation_time": "2004-04-21T19:55:27Z", "is_private": false, "attachment_id": null}, {"count": 11, "tags": [], "creator": "nd@perlig.de", "text": "Okay, but it's not a bug in apache if your system's resources are not enough ;-)\n\nYou could try something like <http://www.defunced.de/modules/mod_loadavg2.c.gz>.\n(Don't know if it works on linux).", "id": 56211, "time": "2004-04-21T20:17:52Z", "bug_id": 28473, "creation_time": "2004-04-21T20:17:52Z", "is_private": false, "attachment_id": null}, {"count": 12, "tags": [], "creator": "floeff@arcor.de", "text": "Exactly THAT is the problem. I don't think it is a problem with system resource.\nI think that with a certain \"amount\" of floodings, any machine can be crashed\nthat way.\n\nHowever: Running the script once or twice is absolutely no problem, but when I\nstart it 30 times, it gets out of control. And these \"30 times\" must be limited\nsomewhere. I thought RLimitCPU and RLimitMEM were exactly for these purposes?\n\nI'm really not sure, so I don't want to blame Apache for that, but as I didn't\nknow where to start I thought I try it here.", "id": 56212, "time": "2004-04-21T20:23:26Z", "bug_id": 28473, "creation_time": "2004-04-21T20:23:26Z", "is_private": false, "attachment_id": null}, {"count": 13, "tags": [], "bug_id": 28473, "is_private": false, "text": ";-)\n\nThe RlimitFoo stuff can decrease the possibility to run out of control but not\ndeny. I think there are other modules out there, that can limit different things\n(mod_bandwidth, mod_security). I'd suggest, you take a look there.\n\nWell, I'm finally marking the report invalid, because there's no bug discovered\nand the rest actually belongs to a user forum.", "id": 56213, "time": "2004-04-21T20:35:09Z", "creator": "nd@perlig.de", "creation_time": "2004-04-21T20:35:09Z", "attachment_id": null}, {"count": 14, "tags": [], "bug_id": 28473, "attachment_id": null, "text": "Okay, thanks so much again! I'll have a look at that ;-)", "id": 56246, "time": "2004-04-22T13:22:09Z", "creator": "floeff@arcor.de", "creation_time": "2004-04-22T13:22:09Z", "is_private": false}]