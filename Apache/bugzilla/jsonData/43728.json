[{"count": 0, "tags": [], "bug_id": 43728, "attachment_id": null, "is_private": false, "id": 109921, "time": "2007-10-29T12:39:18Z", "creator": "mgeiser@mgeiser.net", "creation_time": "2007-10-29T12:39:18Z", "text": " "}, {"count": 1, "attachment_id": null, "bug_id": 43728, "is_private": false, "id": 109922, "time": "2007-10-29T12:49:13Z", "creator": "mgeiser@mgeiser.net", "creation_time": "2007-10-29T12:49:13Z", "tags": [], "text": "Using a clustered WebLogic server with two managed server, we misconfigured \nthe DailyRollingFileAppender so that both managed servers to use the same log \nfile.  \n\nEach managed server runs in it's own JVM and the two JVMS cannot have an \nexclusive lock on the same file (duh!)\n\nI noticed that the log files for previous intervals frequently contained data \nfrom the wrong time interval, some data was entirely missing and that you have \nto look in the current log as well as the log for the previous interval to \nensure you get all the logged information.\n\nIt appeared one of the JVMs wrote to the previous interval log and over-wrote \nthe logs from that interval.\n\nTo conclusively demonstrate this was the case, I left both Log4j config files \nspecify the same log file but added the sting \"MS1\" and \"MS2\" to the \nConversionPattern parameter for each log file so that it was apparent which \nmanaged server was writing to which log file.\n\nI saw when both Managed Servers try to log to the same log, one managed server \nwrites to the specified file (the Managed Server that does get the lock \nvaries) and the other managed server writes to the previous interval\u2019s log \nfile.  Since the appenders also do not specify to append to (but instead \noverwrite) files, the previous interval\u2019s log file is overwritten with new \ndata.  This also confirmed that a managed server always wrote to the same log \nfile instead of each managed server opportunistically writing to any unlocked \nlog file. \n\nWe can see demonstrated this below. The first few bytes of the first lines of \nthe files are associated with the log file name.    \n\nPrior to 10:00am, only one managed server (MS1) had any activity to log and it \nlogged to the docmgt.log file.  \n \nAt 10:00am, I ran a test were a client ran 10 treads calling an EJB via RMI.  \nThe 10 calls were balanced by WebLogic across the two managed servers in the \ndomain.  When this test ran and both Managed Servers were being used, the log \ndata from MS1 that was in the docmgt.log file was now located in \ndocmgt.log.2007-10-28-PM (the docmgt.log file at 9:58 was renamed) and the \ndata from MS2 was logged to the docmgt.log file.  The data that was in \ndocmgt.log.2007-10-28-PM prior to 10:00am was over-written and lost. \n\nat 9:58 am \ndocmgt.log                |MS1|20071029||08:56:05,850||\ndocmgt.log.2007-10-28-PM  |MS2|20071028||21:20:08,318||\ndocmgt.log.2007-10-27-PM  |MS1|20071028||21:19:41,689||\ndocmgt.log.2007-10-27-AM  |MS2|20071027||19:55:26,386||\ndocmgt.log.2007-10-26-PM  |MS1|20071026||12:59:47,760||  \ndocmgt.log.2007-10-26-AM  |MS1|20071027||00:46:54,637||\ndocmgt.log.2007-10-25-PM  |MS2|20071026||09:15:08,077||\n\nat 10:01\ndocmgt.log                |MS2|20071029||10:00:22,993||                \ndocmgt.log.2007-10-28-PM  |MS1|20071029||08:56:05,850||\ndocmgt.log.2007-10-27-PM  |MS1|20071028||21:19:41,689||\ndocmgt.log.2007-10-27-AM  |MS2|20071027||19:55:26,386||\ndocmgt.log.2007-10-26-PM  |MS1|20071026||12:59:47,760||  \ndocmgt.log.2007-10-26-AM  |MS1|20071027||00:46:54,637||\ndocmgt.log.2007-10-25-PM  |MS2|20071026||09:15:08,077||\n\nAlthough we could specify the append parameter be true, overwritting the file \nin this case is clearly a bug.  It is important to perform the log, but there \nis not alert that there is a file contention and it would be infinately \npreferable that the previous interval log NOT be overwritten.  add a short \nrandom sting or time stamp to the log file name specified in the appender if \nnothing else.\n\n\n\n\n\n"}, {"count": 2, "tags": [], "bug_id": 43728, "attachment_id": null, "text": "I don't know why this was just marked assigned.  I started writing a comment on this a week or so ago \nand got side tracked.  \n\nThe proposed solution would help their strongly discouraged case, but could break a legitimate case \nthat depended on overwriting existing files.  If you wanted to keep hourly log files, but only until the \nnext day (or similarly with daily files for a month, etc), you could use a pattern that suppresses the \nmore significant elements of the time.  For example, if your pattern was hourly-log-%d(HH}.log, then \nrolling would discard yesterday's file from the same hour.\n\nSince there is a valid use and existing users may depend on that behavior and the \"fix\" only temporarily \nimproves life for people that are doing what is strongly discouraged, I don't see that proposed solution \nis acceptible.", "id": 110374, "time": "2007-11-09T12:18:26Z", "creator": "carnold@apache.org", "creation_time": "2007-11-09T12:18:26Z", "is_private": false}, {"count": 3, "tags": [], "text": "We have a similar situation. However, in our case its not a misconfiguration. \nWe are using an Oracle application which runs on Websphere 5 under AIX 5. This \ncombination of application server and operating system means we are only able \nto use a limited amount of heap (around 2Gb max). Therefore, we are forced to \nuse multiple JVMs on each of the nodes (in a 2 node cluster). We are \nexperiencing similar behaviour. However, we have observed the writing by the \nvarious JVMs to rolled-over files but I not sure that we have observed file \ntruncation by overwriting.\n\nIt sounds very much like the exclusive file lock problem mentioned by Michael.\n\nRegards\nHanif\nOracle IDM Developer", "attachment_id": null, "bug_id": 43728, "id": 111640, "time": "2007-12-11T08:16:05Z", "creator": "mhn001@yahoo.co.uk", "creation_time": "2007-12-11T08:16:05Z", "is_private": false}, {"count": 4, "tags": [], "bug_id": 43728, "attachment_id": null, "text": "Hanif:\n\nIn your case, the two JVMs and in the same node, in my case the two JVMs are \nin separate nodes, but the end result is the same; two instances of Jog4j are \nrunning in two JVMs trying to write to the same log file.  \n\nI'm going to change the settings to append to existing logs instead of \noverwrite so my data is not destroyed. I still believe it is wrong that data \nis written to a previous - and wrong - interval log.  It should be straight \nforward to come up with a predicable behavior in this situation so that if a \nnew file must be created, a log file monitor would also pick up the other file \nas well.\n\n\n", "id": 111644, "time": "2007-12-11T11:06:48Z", "creator": "mgeiser@mgeiser.net", "creation_time": "2007-12-11T11:06:48Z", "is_private": false}, {"count": 5, "tags": [], "text": "When I said \"misconfiguration\", I did not mean that it was unintentional, but that it is was known to be \nproblematic and should be avoided.  As far as I can tell, it can't be \"fixed\" (at least in a platform \nindependent manner), so don't do it.\n\nThe writing-to-a-previous log file scenario is at the OS level.  If you take any program on a Unix that \ndoes file IO and have some other process mv or del the file that it is writing to, the program will continue \nto write to the file in its new location.  It is not informed that the directory entry pointing to the file has \nbeen modified.  The write-to-a-previous log file occurs when one JVM is currently writing to the current \nlog file and then another JVM effectively mv's the file and creates a new file.", "attachment_id": null, "id": 111650, "creation_time": "2007-12-11T11:41:21Z", "time": "2007-12-11T11:41:21Z", "creator": "carnold@apache.org", "bug_id": 43728, "is_private": false}, {"count": 6, "tags": [], "bug_id": 43728, "attachment_id": null, "id": 112713, "time": "2008-01-09T15:17:46Z", "creator": "chintakar@gmail.com", "creation_time": "2008-01-09T15:17:46Z", "is_private": false, "text": "I noticed that the rollOver() method in RollingAppender class does not check for\nthe return value of  file.renameTo(target). Java doc for File.rename says that\nthe caller should always check the value to see if the operation was a\nsuccess.We noticed that rename method returns 'false' when appender tries to\nwrite to a locked file.     "}, {"count": 7, "tags": [], "bug_id": 43728, "attachment_id": null, "text": "For comment 6, could you confirm that you are looking at log4j 1.2.15 or later.  Bug 41735 addressed \nmissing checks of the status of File.rename.", "id": 112963, "time": "2008-01-17T09:59:44Z", "creator": "carnold@apache.org", "creation_time": "2008-01-17T09:59:44Z", "is_private": false}, {"count": 8, "tags": [], "bug_id": 43728, "text": "I have the same problem when two webapps (in Tomcat) using the same file. I am using the 1.2.15", "id": 114740, "time": "2008-03-19T05:43:30Z", "creator": "ger.onimo@gmx.de", "creation_time": "2008-03-19T05:43:30Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "bug_id": 43728, "attachment_id": null, "text": "Is this the same underlying issue as reported in 44867 ?\n\n", "id": 118130, "time": "2008-06-30T13:11:50Z", "creator": "thorbjoern@gmail.com", "creation_time": "2008-06-30T13:11:50Z", "is_private": false}]