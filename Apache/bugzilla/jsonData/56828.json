[{"count": 0, "tags": [], "creator": "krishna.saran100@gmail.com", "attachment_id": null, "id": 177008, "time": "2014-08-08T10:08:46Z", "bug_id": 56828, "creation_time": "2014-08-08T10:08:46Z", "is_private": false, "text": "We have J2EE war application deployed in a cluster setup having two nodes. Tomcat 6.0.39 is installed in the both nodes having identical war deployed in both. Its deployed in Amazon AWS environment, and the two ec2-nodes are beneath an ELB , with session stickiness enabled for JSESSIONID. Also the two tomcat nodes are session replication enabled too.\n\nFollowing is Cluster config updated server.xml file:\n=============================================================================\n <Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\" channelSendOptions=\"6\" channelStartOptions=\"3\">\n\n<Manager className=\"org.apache.catalina.ha.session.DeltaManager\" expireSessionsOnShutdown=\"false\" notifyListenersOnReplication=\"true\" />\n\n<Channel className=\"org.apache.catalina.tribes.group.GroupChannel\">\n\n<Receiver className=\"org.apache.catalina.tribes.transport.nio.NioReceiver\"\n                                autoBind=\"0\" selectorTimeout=\"5000\" maxThreads=\"6\"\n                                address=\"x.x.x.x\" port=\"4444\" />\n<Sender className=\"org.apache.catalina.tribes.transport.ReplicationTransmitter\">\n<Transport className=\"org.apache.catalina.tribes.transport.nio.PooledParallelSender\"\n                                        timeout=\"60000\"\n                                        keepAliveTime=\"10\"\n                                        keepAliveCount=\"0\"\n/>\n</Sender>\n<Interceptor className=\"org.apache.catalina.tribes.group.interceptors.TcpPingInterceptor\" staticOnly=\"true\"/>\n<Interceptor className=\"org.apache.catalina.tribes.group.interceptors.TcpFailureDetector\"/>\n<Interceptor className=\"org.apache.catalina.tribes.group.interceptors.StaticMembershipInterceptor\">\n<Member className=\"org.apache.catalina.tribes.membership.StaticMember\"\n                                        host=\"x.x.x.x\"\n                                        port=\"4444\"\n                                        uniqueId=\"{0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4}\"/>\n</Interceptor>\n</Channel>\n<Valve className=\"org.apache.catalina.ha.tcp.ReplicationValve\" filter=\"\" />\n<Valve className=\"org.apache.catalina.ha.session.JvmRouteBinderValve\" />\n<ClusterListener className=\"org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener\"/>\n<ClusterListener className=\"org.apache.catalina.ha.session.ClusterSessionListener\"/>\n</Cluster>\n\n==========================================================================\n\nReceiver ip, static member ip and unique id is different in the server.xml of the other node in the cluster.\n\nthis was running fine in production environment for 3 months. Suddenly there was\nan exception logged like this :, and started coming up infinitely.\n\n\n==================================================\nAug 6, 2014 12:00:39 AM org.apache.catalina.tribes.group.interceptors.TcpFailureDetector memberDisappeared\nINFO: Received memberDisappeared[org.apache.catalina.tribes.membership.MemberImpl[tcp://10.160.40.12:4444,10.160.40.12,4444, alive=0,id={0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 }, payload={}, command={}, domain={}, ]] message. Will verify.\nAug 6, 2014 12:00:39 AM org.apache.catalina.tribes.group.interceptors.TcpFailureDetector memberDisappeared\nINFO: Verification complete. Member still alive[org.apache.catalina.tribes.membership.MemberImpl[tcp://10.160.40.12:4444,10.160.40.12,4444, alive=0,id={0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 }, payload={}, command={}, domain={}, ]]\nAug 6, 2014 12:00:39 AM org.apache.catalina.ha.tcp.SimpleTcpCluster send\nSEVERE: Unable to send message through cluster sender.\norg.apache.catalina.tribes.ChannelException: Operation has timed out(60000 ms.).; Faulty members:tcp://10.160.40.12:4444;\n        at org.apache.catalina.tribes.transport.nio.ParallelNioSender.sendMessage(ParallelNioSender.java:97)\n        at org.apache.catalina.tribes.transport.nio.PooledParallelSender.sendMessage(PooledParallelSender.java:53)\n        at org.apache.catalina.tribes.transport.ReplicationTransmitter.sendMessage(ReplicationTransmitter.java:80)\n        at org.apache.catalina.tribes.group.ChannelCoordinator.sendMessage(ChannelCoordinator.java:76)\n        at org.apache.catalina.tribes.group.ChannelInterceptorBase.sendMessage(ChannelInterceptorBase.java:75)\n        at org.apache.catalina.tribes.group.ChannelInterceptorBase.sendMessage(ChannelInterceptorBase.java:75)\n        at org.apache.catalina.tribes.group.interceptors.TcpFailureDetector.sendMessage(TcpFailureDetector.java:88)\n        at org.apache.catalina.tribes.group.ChannelInterceptorBase.sendMessage(ChannelInterceptorBase.java:75)\n        at org.apache.catalina.tribes.group.ChannelInterceptorBase.sendMessage(ChannelInterceptorBase.java:75)\n        at org.apache.catalina.tribes.group.GroupChannel.send(GroupChannel.java:216)\n        at org.apache.catalina.tribes.group.GroupChannel.send(GroupChannel.java:175)\n        at org.apache.catalina.ha.tcp.SimpleTcpCluster.send(SimpleTcpCluster.java:817)\n        at org.apache.catalina.ha.tcp.SimpleTcpCluster.sendClusterDomain(SimpleTcpCluster.java:791)\n        at org.apache.catalina.ha.tcp.ReplicationValve.send(ReplicationValve.java:553)\n        at org.apache.catalina.ha.tcp.ReplicationValve.sendMessage(ReplicationValve.java:537)\n        at org.apache.catalina.ha.tcp.ReplicationValve.sendSessionReplicationMessage(ReplicationValve.java:519)\n        at org.apache.catalina.ha.tcp.ReplicationValve.sendReplicationMessage(ReplicationValve.java:430)\n        at org.apache.catalina.ha.tcp.ReplicationValve.invoke(ReplicationValve.java:363)\n        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)\n        at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:861)\n        at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:606)\n        at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)\n        at java.lang.Thread.run(Thread.java:662)\n============================================================================\n\n\nAfter this, the web application is not accessible, and we have to manually kill the tomcat process in one node, thereby disabling the cluster.\n\n\nWe are unsure, how all of a sudden this is coming, and disabling application access altogether. If there are any suggestion on remedy, pls provide the same."}, {"count": 1, "tags": [], "bug_id": 56828, "is_private": false, "id": 177025, "creation_time": "2014-08-08T19:31:01Z", "time": "2014-08-08T19:31:01Z", "creator": "markt@apache.org", "text": "What Java version (exactly please) was this running on?\n\nExactly (as precisely as possible - ideally to the second) how long was this cluster up before it failed?", "attachment_id": null}, {"count": 2, "tags": [], "creator": "fhanik@apache.org", "attachment_id": null, "id": 177026, "time": "2014-08-09T01:12:54Z", "bug_id": 56828, "creation_time": "2014-08-09T01:12:54Z", "is_private": false, "text": "faulty member is tcp://10.160.40.12:4444\nis this member not responding to anything?\n\nnow there are ways around this, such as configuring replication to be async. What happens then is that healthy nodes will keep responding to HTTP requests instead of waiting for faulty nodes. But it will mask faulty nodes.\n\nYour scenario here, could be that 10.160.40.12:4444 is experiencing another problem, such as an out of memory error or other serious problem. check for other log errors and the health of the instance itself.\n\nasync message delivery is \n\nchannelSendOptions=8 (fire and forget)\nchannelSendOptions=10 (wait for an ack or resend)\n\nsee http://tomcat.apache.org/tomcat-7.0-doc/config/cluster.html"}, {"count": 3, "tags": [], "creator": "krishna.saran100@gmail.com", "attachment_id": null, "id": 177029, "time": "2014-08-09T07:12:58Z", "bug_id": 56828, "creation_time": "2014-08-09T07:12:58Z", "is_private": false, "text": "Java version 1.6. Update 45\nCluster setup is in perfectly running state for the past 3 months. Couple of times, production setup was restarted, for application patch upgrade. But tomcat settings was not touched upon.\n\nFrom application perspective, there is no out of memory error or any other issue. WEB app is perfectly accessible, after terminating one of the tomcat node, thereby disabling the cluster. \n\nCurrently channelSendOption = 6 for synchronous cluster update."}, {"attachment_id": null, "tags": [], "bug_id": 56828, "is_private": false, "count": 4, "id": 177076, "time": "2014-08-11T15:13:51Z", "creator": "krishna.saran100@gmail.com", "creation_time": "2014-08-11T15:13:51Z", "text": "Planning to optimize cluster config as below, for now : Kindly provide your comments on the same.\n\n\n============NEW=====================\n\n<Cluster className=\"org.apache.catalina.ha.tcp.SimpleTcpCluster\" channelSendOptions=\"6\" channelStartOptions=\"3\">\n                \n<Manager className=\"org.apache.catalina.ha.session.DeltaManager\" expireSessionsOnShutdown=\"false\" notifyListenersOnReplication=\"true\" stateTransferTimeout=\"120\" />\n                \n<Channel className=\"org.apache.catalina.tribes.group.GroupChannel\">\n                        \n<Receiver className=\"org.apache.catalina.tribes.transport.nio.NioReceiver\"\n                                autoBind=\"0\" selectorTimeout=\"60000\" maxThreads=\"30\"\n                                address=\"10.4.9.68\" port=\"4444\" timeout=\"60000\"/>\n<Sender className=\"org.apache.catalina.tribes.transport.ReplicationTransmitter\">\n<Transport className=\"org.apache.catalina.tribes.transport.nio.PooledParallelSender\"\n                                        timeout=\"60000\"\n                                        keepAliveTime=\"120000\" \n/>\n</Sender>\n<Interceptor className=\"org.apache.catalina.tribes.group.interceptors.TcpPingInterceptor\" staticOnly=\"true\"/>\n<Interceptor className=\"org.apache.catalina.tribes.group.interceptors.TcpFailureDetector\" connectTimeout=\"60000\" />\n <Interceptor  className=\"org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor\"/> \n<Interceptor \n className=\"org.apache.catalina.tribes.group.interceptors.ThroughputInterceptor\"/>\n<Interceptor className=\"org.apache.catalina.tribes.group.interceptors.StaticMembershipInterceptor\">\n<Member className=\"org.apache.catalina.tribes.membership.StaticMember\"\n                                        host=\"10.4.9.225\"\n                                        port=\"4444\"\n                                        uniqueId=\"{0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2}\"/>\n</Interceptor>\n</Channel>\n<Valve className=\"org.apache.catalina.ha.tcp.ReplicationValve\" filter=\"\" />\n<Valve className=\"org.apache.catalina.ha.session.JvmRouteBinderValve\" />\n<ClusterListener className=\"org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener\"/>\n<ClusterListener className=\"org.apache.catalina.ha.session.ClusterSessionListener\"/>\n</Cluster>    \n\n\n================================================================="}, {"count": 5, "tags": [], "creator": "markt@apache.org", "attachment_id": null, "id": 177091, "time": "2014-08-11T21:38:54Z", "bug_id": 56828, "creation_time": "2014-08-11T21:38:54Z", "is_private": false, "text": "I don't see any evidence of a Tomcat bug here. There are lots of possibile causes for a cluster node failing to respond and Bugzilla is not the place to explore those. Neither is Bugzilla the place to discuss cluster configuration options or to have configuration reviewed. Please move this to the users mailing list."}]