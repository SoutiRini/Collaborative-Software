[{"count": 0, "tags": [], "text": "I have a Xindice database running embedded, and it ran just fine for days, \nincluding many restarts.  However today every XPath query freezes.\n\nA little investigation shows that it's always hung on line 1129 of \norg.apache.xindice.core.filer.Paged (the line number refers to the current CVS \nhead), which reads:\n\n>    raf.read(data);\n\nThis is in org.apache.xindice.core.filer.Paged.Page.read().  I suspect that the \ndatabase was corrupted in some way, possibly by being brutally shut off at the \nwrong time.  But the use of a blocking read here means that any XPath query \nthat includes the problematic Collection will freeze the application forever.  \nIdeally I'd want the database to heal itself, when possible, to report the \nproblem in any case, and to at least handle the failure gracefully.  In the \ncase of an XPath query, the Collection could be skipped (with a log message) if \nit's one of many, or an exception could be thrown so the database administrator \ncould take corrective action.  Freezing, from the end-user's perspective, is \nnot acceptable, and I think expecting applications to implement watchdog \nthreads every time an XPath query is made is not realistic either.\n\nI moved the entire database directory elsewhere and started with a fresh one, \nwithout changing a line of code, and sure enough it doesn't hang anymore.  So I \nsuppose that if I swapped in the faulty database again, I could reproduce the \nerror easily.  I'll see if I can identify the corrupted file and produce an \nencapsulated test case from it.  If I manage to get something useful I'll post \nit here.", "attachment_id": null, "bug_id": 22775, "id": 43408, "time": "2003-08-27T21:37:33Z", "creator": "mariocormier@sympatico.ca", "creation_time": "2003-08-27T21:37:33Z", "is_private": false}, {"count": 1, "tags": [], "bug_id": 22775, "is_private": false, "text": "I can confirm this \"bug\". It happened to us when we tried to set meta data\ndocuments directly into the meta collection. When we just used setMetaData\nmethods on a clean database, all went well. The stacktrace we got on the\ncorrupted database was the following (it showed repeatedly untill a\nOutOfMemoryError occured):\n\nWARN 2004-09-10 10:54:26,111 [http8080-Processor3] - ignored exception\njava.io.EOFException\n\tat java.io.DataInputStream.readByte(DataInputStream.java:243)\n\tat\norg.apache.xindice.xml.XMLCompressedInput.readSignature(XMLCompressedInput.java:54)\n\tat org.apache.xindice.xml.dom.ElementImpl.loadAttributes(ElementImpl.java:173)\n\tat org.apache.xindice.xml.dom.ElementImpl.<init>(ElementImpl.java:60)\n\tat\norg.apache.xindice.xml.dom.ContainerNodeImpl.loadChildren(ContainerNodeImpl.java:128)\n\tat org.apache.xindice.xml.dom.DocumentImpl.checkLoaded(DocumentImpl.java:133)\n\tat\norg.apache.xindice.xml.dom.ContainerNodeImpl.getChildNodes(ContainerNodeImpl.java:182)\n\tat org.apache.xindice.xml.TextWriter.writeChildren(TextWriter.java:192)\n\tat org.apache.xindice.xml.TextWriter.writeNode(TextWriter.java:88)\n\tat org.apache.xindice.xml.TextWriter.write(TextWriter.java:250)\n\tat org.apache.xindice.xml.TextWriter.toString(TextWriter.java:274)\n\tat org.apache.xindice.core.Collection.getEntry(Collection.java:725)\n\tat org.apache.xindice.core.Collection.getDocument(Collection.java:561)\n\tat org.apache.xindice.core.Collection.getObject(Collection.java:809)\n\tat\norg.apache.xindice.core.MetaSystemCollection.getCollectionMeta(MetaSystemCollection.java:203)\n\tat org.apache.xindice.core.Collection.updateCollectionMeta(Collection.java:1530)\n\tat org.apache.xindice.core.Collection.create(Collection.java:254)\n\tat\norg.apache.xindice.core.CollectionManager.createCollection(CollectionManager.java:132)\n\tat org.apache.xindice.core.Collection.createCollection(Collection.java:264)\n\tat\norg.apache.xindice.server.rpc.messages.CreateCollection.execute(CreateCollection.java:74)\n\tat\norg.apache.xindice.server.rpc.RPCMessageInterface.run(RPCMessageInterface.java:48)\n\tat sun.reflect.GeneratedMethodAccessor47.invoke(Unknown Source)\n\tat\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n\tat java.lang.reflect.Method.invoke(Method.java:585)\n\tat org.apache.xmlrpc.Invoker.execute(XmlRpcServer.java)\n\tat org.apache.xmlrpc.XmlRpcServer$Worker.executeInternal(XmlRpcServer.java)\n\tat org.apache.xmlrpc.XmlRpcServer$Worker.execute(XmlRpcServer.java)\n\tat org.apache.xmlrpc.XmlRpcServer.execute(XmlRpcServer.java)\n\tat org.apache.xmlrpc.XmlRpcServer.execute(XmlRpcServer.java)\n\tat org.apache.xindice.server.XindiceServlet.doPost(XindiceServlet.java:90)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:763)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:856)\n\tat\norg.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:284)\n\tat\norg.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:204)\n\tat\norg.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:257)\n\tat\norg.apache.catalina.core.StandardValveContext.invokeNext(StandardValveContext.java:151)\n\tat org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:564)\n\tat\norg.apache.catalina.core.StandardContextValve.invokeInternal(StandardContextValve.java:245)\n\tat\norg.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:199)\n\tat\norg.apache.catalina.core.StandardValveContext.invokeNext(StandardValveContext.java:151)\n\tat org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:564)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:195)\n\tat\norg.apache.catalina.core.StandardValveContext.invokeNext(StandardValveContext.java:151)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:164)\n\tat\norg.apache.catalina.core.StandardValveContext.invokeNext(StandardValveContext.java:149)\n\tat org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:578)\n\tat\norg.apache.catalina.core.StandardValveContext.invokeNext(StandardValveContext.java:149)\n\tat org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:564)\n\tat\norg.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:156)\n\tat\norg.apache.catalina.core.StandardValveContext.invokeNext(StandardValveContext.java:151)\n\tat org.apache.catalina.core.StandardPipeline.invoke(StandardPipeline.java:564)\n\tat org.apache.catalina.core.ContainerBase.invoke(ContainerBase.java:972)\n\tat org.apache.coyote.tomcat5.CoyoteAdapter.service(CoyoteAdapter.java:206)\n\tat org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:828)\n\tat\norg.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.processConnection(Http11Protocol.java:700)\n\tat org.apache.tomcat.util.net.TcpWorkerThread.runIt(PoolTcpEndpoint.java:584)\n\tat\norg.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:683)\n\tat java.lang.Thread.run(Thread.java:595)", "id": 63346, "time": "2004-09-10T13:05:07Z", "creator": "wouter_de_vaal@hotmail.com", "creation_time": "2004-09-10T13:05:07Z", "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 22775, "text": "Filer can check if file has correct length when opening it and detect if file\nwas truncated. Probably best recourse in such situation is to log this condition\nand keep this collection / index offline to prevent further damage.\n\nAny other ideas?", "count": 2, "id": 101909, "time": "2007-04-18T18:52:04Z", "creator": "vgritsenko@apache.org", "creation_time": "2007-04-18T18:52:04Z", "is_private": false}, {"attachment_id": null, "tags": [], "bug_id": 22775, "text": "(In reply to comment #2)\n> Filer can check if file has correct length when opening it and detect if file\n> was truncated. Probably best recourse in such situation is to log this condition\n> and keep this collection / index offline to prevent further damage.\n> \n> Any other ideas?\n\nWhen loading a page, before attempting to read the data, filer can check if that\npage is within file's limits.", "count": 3, "id": 101965, "time": "2007-04-19T19:13:03Z", "creator": "nshilenkova@gmail.com", "creation_time": "2007-04-19T19:13:03Z", "is_private": false}, {"count": 4, "tags": [], "text": "(In reply to comment #3)\n> When loading a page, before attempting to read the data, filer can check if that\n> page is within file's limits.\n\nHm, why would you do this check every time? Wouldn't one time check at the\nmoment file is opened be enough?", "attachment_id": null, "bug_id": 22775, "id": 101969, "time": "2007-04-19T20:18:46Z", "creator": "vgritsenko@apache.org", "creation_time": "2007-04-19T20:18:46Z", "is_private": false}, {"count": 5, "tags": [], "bug_id": 22775, "attachment_id": null, "is_private": false, "id": 101986, "time": "2007-04-20T06:04:48Z", "creator": "nshilenkova@gmail.com", "creation_time": "2007-04-20T06:04:48Z", "text": "> Hm, why would you do this check every time? Wouldn't one time check at the\n> moment file is opened be enough?\n\nNot necessarily, if \n1) File got corrupted after it has been opened (I'd rather believe that Xindice\nmessed up its own file than it was some evil Xindice-truncating application)\n2) File length and amount of pages are correct, but some pointer to the page got\n garbage in it and points to non-existing page.\n\nBut I agree, it does sound a little paranoid. I'm not sure if it makes sense to\ncheck it at runtime, introduce a tool to check file integrity, or just fix a bug\nthat caused corruption in the first place :)\n\n"}, {"count": 6, "tags": [], "creator": "vgritsenko@apache.org", "text": "(In reply to comment #5)\n> Not necessarily, if \n> 1) File got corrupted after it has been opened\n\nI don't see how it's possible - the file can only grow, IIUC.\n\n\n> 2) File length and amount of pages are correct, but some pointer to the page got\n>  garbage in it and points to non-existing page.\n\nOk that is scary if it is happening.\n\n\n> But I agree, it does sound a little paranoid. I'm not sure if it makes sense to\n> check it at runtime, introduce a tool to check file integrity, or just fix a bug\n> that caused corruption in the first place :)\n\nI would first go with simple one time check on run time (Filer.open() seems to\nbe a good spot), and a tool for integrity check. See also [1] which is related,\nor start a new thread altogether.\n\nhttp://marc.info/?t=114780880000002&r=1", "id": 102584, "time": "2007-04-27T17:58:33Z", "bug_id": 22775, "creation_time": "2007-04-27T17:58:33Z", "is_private": false, "attachment_id": null}, {"count": 7, "attachment_id": null, "bug_id": 22775, "text": "(In reply to comment #6)\n> > Not necessarily, if \n> > 1) File got corrupted after it has been opened\n> \n> I don't see how it's possible - the file can only grow, IIUC.\n\nThis is not completely true. The file is _supposed_ to grow, assuming nothing\ngets out of control, which is not entirely impossible. Just several patches ago\nthe was a problem with truncated index.\n\n> > 2) File length and amount of pages are correct, but some pointer to the page got\n> >  garbage in it and points to non-existing page.\n> \n> Ok that is scary if it is happening.\n\nAgain, another patch was for exactly this situation - Xindice didn't handle\nseveral threads correctly, the file got complete junk in it - causing anything\nfrom BTreeCorruptException to StackOverflowError. That problem is fixed, but\nthere may be something else (I hope not).\n\nAnyway, on more positive side - I don't really think everything is that bad,\nunless there are reports about file corruption I don't see a need for really\ncomplex tool. \n\n", "id": 103353, "time": "2007-05-18T12:51:46Z", "creator": "nshilenkova@gmail.com", "creation_time": "2007-05-18T12:51:46Z", "tags": [], "is_private": false}]