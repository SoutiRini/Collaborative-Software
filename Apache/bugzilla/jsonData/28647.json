[{"count": 0, "tags": [], "text": "New Feature Requested:\nI have used logging extensively for many years and tend to have my programs \nlog alot of information.  When writing to a file this can cause a performance \nimpact due to very frequent disk I/O.  So my own logging libraries I used (in \nC, VB, PL/SQL) always had the ability to configure the level that the log text \nwas flushed to disk.  \n\nI have now extended FileAppender to create this feature.  It simply allows you \nto set the level that flushing occurs.  Whenever a log event is logged for \nthat level or higher, a flush occurs.  i.e. if the FlushLevel is INFO, then \nwhen an INFO, WARN, ERROR or FATAL event is logged the stream will be flushed \nto disk. DEBUG messages will accumulate and not flush until the next INFO \nevent is logged.\n\nJustification:  \n-The performance improvement allows for more detailed logging levels to be \nleft permanently on, or to have less impact when they are on. \n- The logging style in most programs (certainly all mine) finish each major \nprocessing step logging an event at a level higher than (or at least equal to) \nthe previously logged events.  Eg an operation \"createOrder\" may have a number \nof INFO and DEBUG msgs (and soon TRACE!) but would finish on a INFO msg \nlike \"Successfully created order for 1000 ORCL...\".  This pattern guarantees \nthat flush of all log event has occurred when the operation finishes, rather \nthan waiting for some arbitrary point like a 8K buffer being filled.\n-The one downside is that if a program crashes, then any final logged events \nbelow the threshold that occurred after the last threhold level will not \nappear in the file.  This is normally a small price to pay, as you just then \nlower the flush level and rerun so you get all events flushed.  (This assumes \nthe error is repeatable, but with no flushing feature, the lower level events \nwouldnt have been turned on due to the performance hit so you are no worse off \neven if it is not).\nNOTE: I have implemented a shutdown hook to address the last issue - i.e. \nautomatically flush on VM exit, but that is a Java 1.3 method so cannot be \nused in Log4j as I understand it.\n\nCurrent Status:\nI have written a new appender \"LevelFlushedFileAppender\" that extends \nFileAppender that does this job.  This works fine and I am happy to submit \nit.  However I think that it would be better to alter the FileAppender itself \nand add the code directly to this, so it could be inherited in all classes \nextending FileAppender.  I am happy to implement it like this also.\n\nLet me know if the feature is accepted or you want further information, and \nwhat I should do going forward.", "is_private": false, "bug_id": 28647, "id": 56530, "time": "2004-04-28T03:20:14Z", "creator": "sdorrat@jbwere.com.au", "creation_time": "2004-04-28T03:20:14Z", "attachment_id": null}, {"count": 1, "tags": [], "creator": "ceki@apache.org", "is_private": false, "id": 56852, "attachment_id": null, "bug_id": 28647, "creation_time": "2004-05-05T09:09:57Z", "time": "2004-05-05T09:09:57Z", "text": "Hi Simon,\n\nHave you measured the performance improvements?\n\nI'd be interested in the results with 5 threads performing simultaneous \nlogging, of which 80% DEBUGS and 20% INFO. Running the tests on both Windows \nand Linux would be even better."}, {"text": "Performance tests I did previously on Windows XP showed the new method was up \nto 20 times faster.  However this was with 1000 writes per flush.  I will \nretest with the ratio you suggested (much more realistic) and more than 1 \nthread.", "tags": [], "bug_id": 28647, "is_private": false, "count": 2, "id": 56903, "time": "2004-05-06T02:10:20Z", "creator": "sdorrat@jbwere.com.au", "creation_time": "2004-05-06T02:10:20Z", "attachment_id": null}, {"count": 3, "tags": [], "text": "This is where having Appender being an interface would be ideal, because then \none could 'decorate' one appender with another object to provide support code \nsuch as a flushing function.  Sort of like how the InputStream stuff works.\n\nLets assume Appender is an interface.  One could then do something like this in \njava code.  Configuration code of course might be more complex to achieve this, \nbut certainly possible:\n\n Appender a = new FlushingAppender(new FileAppender(.....));\n\nIn the above example the FlushingAppender implements the Appender interface, \nbut for the most part delegates to the internal (file)appender, except for the \nactual append methods where it might buffer events based on some strategy of \nthe implementors choosing.  That way we could mix and match strategies.\n\nThis is how AsyncAppender kinda works, but I think having Appender as an \ninterface is neater.  Large change though.\n\n\n ", "attachment_id": null, "bug_id": 28647, "id": 56904, "time": "2004-05-06T02:19:34Z", "creator": "paul.smith@lawlex.com.au", "creation_time": "2004-05-06T02:19:34Z", "is_private": false}, {"count": 4, "tags": [], "creator": "sdorrat@jbwere.com.au", "text": "Paul,\n\nAppender is an interface!\n\nWould this able to be configured via Property files/XML config files?  (Is \nthis what you referred to as \"more complex config code\"?).  Using a decorator \nseems like a useful approach, as it would not only allow many such features to \nbe mixed and matched, but also potentially allow to be applied to any \nappender. However since this LevelFlushedFileAppender flushes by calling the \nqw.flush() from the WriterAppender class, it could only be applied to classes \nwho are decendants of that class.  To apply to other appenders would require a \nchange to the interface and each appender class to support a \"flush\" method, \nwhich seems to defeat the purpose of a decorator pattern.\n\nWhat do you think?\n", "id": 56905, "time": "2004-05-06T03:32:03Z", "bug_id": 28647, "creation_time": "2004-05-06T03:32:03Z", "is_private": false, "attachment_id": null}, {"text": "You are of course correct... When I looked in the Hierachy view within Eclipse, \nI keep seeing AppenderSkeleton, and forget that there is actually an interface.\n\nSilly me, particularly as a log4j-dev member... 8-|\n\nAnyway. I was thinking that the appender that is wrapped need not have extend \nfrom WriterAppender.  The Wrapping appender (FlushAppender in our example) is \nfree to determine when to 'flush', which really means 'take any currently \nbuffered events and send them to the wrapped appender'.  \n\nThis is more a more generic flushing solution but kind of duplicates the work \nthat WriterAppender would do.  I guess you could have a FlushingWriterAppender \nwrapper that is only designed to wrap a WriterAppender only, and rather than \nstore it's own buffer of events, always writes the event to the internal \nWriterAppender, but waits until the internal strategy determines that a flush \nshould occur, and only at that point calls writerAppender.flush().\n\nDoes that make sense?  ", "tags": [], "bug_id": 28647, "is_private": false, "count": 5, "id": 56906, "time": "2004-05-06T03:41:50Z", "creator": "paul.smith@lawlex.com.au", "creation_time": "2004-05-06T03:41:50Z", "attachment_id": null}, {"count": 6, "tags": [], "text": "It does make sense.  In the first approach however (wrapper buffering events \nthen sending them all at once to the wrapped appender upon flush), you lose \nmost of the advantage of buffering.  This is because the wrapped appender will \nstill execute all events one by one when 'flushed'.  I.e for a file writer it \nwould still be still be one disk i/o per event.\n\nThe second strategy was the one I implemented (though via inheritance rather \nthan as a decorator). Not convinced either way yet.  Will get the performance \ntesting done tonight or tommorow on the current implementation.\n", "is_private": false, "bug_id": 28647, "id": 56907, "time": "2004-05-06T04:24:29Z", "creator": "sdorrat@jbwere.com.au", "creation_time": "2004-05-06T04:24:29Z", "attachment_id": null}, {"count": 7, "tags": [], "bug_id": 28647, "is_private": false, "text": "Yup, this is where the (smarter) FlushingWriterAppender would not actually \nbuffer any events, just write them to the wrapped WriterAppender and \nperiodically call writerAppender.flush() as it deems appropriate.\n\nSo via the decorator approach, you could have a generic flushing appender (akin \nreally to the Async appender), and one optimised to dealing with \nWriterAppenders.\n\nWith the decorator approache you could then do something like:\n\nAppender a = new FlushingAppender(new FlushingWriterAppender(new WriterAppender\n(...), 50), 500);\n\nLets say that in this example:\n\n* FlushingAppender: 500 = # ms to buffer events before flushing to it's \ninternal appender (FlushingWriterAppender)\n\n* FlushingWriterAppender: 50= # of event objects to write before calling \nwriterAppender.flush().\n\nHaving said all of this though, one does need to think about the risks of some \nevents not getting written.  While you may have a JDK hook to listen for a \nshutdown, some applications  won't always exit quite so gracefully.  And this \nis usually when you MOST want to know what was going on......", "id": 56908, "time": "2004-05-06T04:32:30Z", "creator": "paul.smith@lawlex.com.au", "creation_time": "2004-05-06T04:32:30Z", "attachment_id": null}, {"text": "This is why I use the LevelFlushed approach (i.e Flush on level equal to or \nhigher than x).  If the error is trapped prior to shutdown, then the log will \nbe flushed when an ERROR event is logged.  If the error is not trapped, then \nsome low level messages will not be flushed.  But with the existing approach, \nyou wouldnt have low level logging enabled anyway (due to performance hit), so \nno difference.  Thats the rationale behind this.  It enables you to leave a \nlower level on permanently than you otherwise would.  So you get the advantage \nof seeing the low level info in all cases bar catastrophic failure.", "tags": [], "bug_id": 28647, "attachment_id": null, "count": 8, "id": 56909, "time": "2004-05-06T06:16:17Z", "creator": "sdorrat@jbwere.com.au", "creation_time": "2004-05-06T06:16:17Z", "is_private": false}, {"count": 9, "tags": [], "creator": "sdeboy@iname.com", "attachment_id": null, "is_private": false, "id": 56939, "time": "2004-05-06T17:30:53Z", "bug_id": 28647, "creation_time": "2004-05-06T17:30:53Z", "text": "Would it make sense to use something like the new ExpressionFilter in this case\ninstead of only supporting the triggering based on Level?"}, {"count": 10, "attachment_id": null, "creator": "sdorrat@jbwere.com.au", "text": "Not sure what the ExpressionFilter is.  Where can I find info on it? I could \ncertainly imagine that there could be a number of different approaches to \ntriggering the flush that people may want to take, so a flexible framework has \nmerit.", "id": 56959, "time": "2004-05-06T23:33:39Z", "bug_id": 28647, "creation_time": "2004-05-06T23:33:39Z", "tags": [], "is_private": false}, {"text": "See ExpressionFilter here:\nhttp://cvs.apache.org/viewcvs.cgi/logging-log4j/src/java/org/apache/log4j/varia/ExpressionFilter.java?rev=1.3&view=auto\n\nAnd ExpressionRule here:\nhttp://cvs.apache.org/viewcvs.cgi/logging-log4j/src/java/org/apache/log4j/rule/ExpressionRule.java?rev=1.6&view=auto\n\nThe ExpressionFilter is an example of how an ExpressionRule can be used to allow\nor prevent events from being processed by an appender (and ExpressionRule could\nbe used similarly in a flush trigger).\n\nHere is an example of how an ExpressionFilter is used to filter events:\n\n   <appender name=\"STDOUT\" class=\"org.apache.log4j.ConsoleAppender\">\n      <layout class=\"org.apache.log4j.SimpleLayout\"/>\n        <filter class=\"org.apache.log4j.varia.ExpressionFilter\">\n          <param name=\"Expression\" value=\"level > INFO\" />\n          <param name=\"AcceptOnMatch\" value=\"true\"/>\n          <param name=\"ConvertInFixToPostFix\" value=\"true\"/>\n        </filter>\n        <filter class=\"org.apache.log4j.varia.DenyAllFilter\"/>\n   </appender>", "tags": [], "bug_id": 28647, "is_private": false, "count": 11, "id": 56972, "time": "2004-05-07T03:45:58Z", "creator": "sdeboy@iname.com", "creation_time": "2004-05-07T03:45:58Z", "attachment_id": null}, {"text": "Created attachment 11527\nPerformance test results", "tags": [], "bug_id": 28647, "attachment_id": 11527, "count": 12, "id": 57317, "time": "2004-05-13T00:12:12Z", "creator": "sdorrat@jbwere.com.au", "creation_time": "2004-05-13T00:12:12Z", "is_private": false}, {"count": 13, "tags": [], "creator": "sdorrat@jbwere.com.au", "attachment_id": 11528, "is_private": false, "id": 57318, "time": "2004-05-13T00:15:26Z", "bug_id": 28647, "creation_time": "2004-05-13T00:15:26Z", "text": "Created attachment 11528\nJava test harness"}, {"id": 57319, "tags": [], "bug_id": 28647, "attachment_id": null, "count": 14, "text": "Performance test results attached as requested.  Also Java test harness. \nImprovement roughly 25%.  System load and differing threading models and disk \ncaching between XP and Linux made individual tests hard to compare, but it \ncertainly showed a consistent performance improvement.\n", "time": "2004-05-13T00:16:01Z", "creator": "sdorrat@jbwere.com.au", "creation_time": "2004-05-13T00:16:01Z", "is_private": false}, {"text": "Hi all,\n\nI totally aggree with the flushing being tied to the level of the event. This \ntotally makes sense and would be good to have it in the default log4J.\n\nAs Simon, I also use a shutdown hook in my application to address the issue - \ni.e. automatically flush on VM exit.\n\nThe only way I found to flush was to close all the appenders. This is fine as I \nam stopping the application but a way to flush globally all the logs without \nclosing the appenders in a very simple way should also be there.\nLet's imagine I want to flush all the logs using some admin interface to \nexamine them but I don't want to close them even to reopen seconds later (to \nnot loose events and getting error messages everywhere while they are created). \nWhat are my options in this case????\nSo flushing should be present in each appender that could delegate to sub \nappenders if required.\n\nOlivier DUPUY", "tags": [], "bug_id": 28647, "attachment_id": null, "count": 15, "id": 92469, "time": "2006-08-23T13:40:08Z", "creator": "opldupuy@gmail.com", "creation_time": "2006-08-23T13:40:08Z", "is_private": false}, {"count": 16, "tags": [], "text": "\nI think what should be supported is to enhance WriterAppender so that subclasses\ncan specify the flushing behavior.  I don't think it's generally a good idea to\ncode in the policy itself, but it seems fair to allow users to easily extend\nexisting classes to get the behavior they want.\n\nI thought of adding an Interface, such as \"FlushPolicy\" but it seemed like overkill.\n\nI propose the following change:\n \nIndex: C:/src/workspace/log4j/src/java/org/apache/log4j/WriterAppender.java\n===================================================================\n--- C:/src/workspace/log4j/src/java/org/apache/log4j/WriterAppender.java\n(revision 500611)\n+++ C:/src/workspace/log4j/src/java/org/apache/log4j/WriterAppender.java\n(working copy)\n@@ -372,7 +372,7 @@\n         }\n       }\n \n-      if (this.immediateFlush) {\n+      if (shouldFlush(event)) {\n         this.qw.flush();\n       }\n   }\n@@ -426,6 +426,15 @@\n       }\n     }\n   }\n+  \n+  /**\n+   * Returns true if an event should be flushed immediately.\n+   * This method returns the value of {@link #immediateFlush}.\n+   * Subclasses override this behavior to flush only when certain events occur.\n+   */\n+  protected boolean shouldFlush(LoggingEvent event) {\n+    return this.immediateFlush;\n+  }\n \n \n }\n\n \n }\n\nIn response to #15, adding a separate API to \"flush\" appenders really is a\nseparate issue that should be raised in a different bug.", "is_private": false, "bug_id": 28647, "id": 98702, "time": "2007-01-29T11:55:34Z", "creator": "genman@noderunner.net", "creation_time": "2007-01-29T11:55:34Z", "attachment_id": null}, {"count": 17, "tags": [], "bug_id": 28647, "attachment_id": null, "text": "*** Bug 43061 has been marked as a duplicate of this bug. ***", "id": 107126, "time": "2007-08-22T20:25:32Z", "creator": "carnold@apache.org", "creation_time": "2007-08-22T20:25:32Z", "is_private": false}, {"count": 18, "tags": [], "bug_id": 28647, "is_private": false, "text": "I really hope that you will integrate this in 2.0 as in the comment to my RFE below.\nSee my follow up comments for a general way to flush whatever the type of logger or appender.\n\nhttps://issues.apache.org/bugzilla/show_bug.cgi?id=41670\n\nThis is really something important for production systems to have a decent flush mechanism with no performance penalty associated to an ongoing flushing.", "id": 125340, "time": "2009-03-05T08:58:37Z", "creator": "opldupuy@gmail.com", "creation_time": "2009-03-05T08:58:37Z", "attachment_id": null}, {"count": 19, "attachment_id": null, "creator": "markt@apache.org", "text": "Reset assignee", "id": 127822, "time": "2009-06-10T13:21:40Z", "bug_id": 28647, "creation_time": "2009-06-10T13:21:40Z", "tags": [], "is_private": false}, {"count": 20, "tags": [], "creator": "carnold@apache.org", "attachment_id": null, "is_private": false, "id": 131062, "time": "2009-10-10T19:54:37Z", "bug_id": 28647, "creation_time": "2009-10-10T19:54:37Z", "text": "Committed Elias's recommendation in rev 824003."}]