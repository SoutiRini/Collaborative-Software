[{"count": 0, "attachment_id": null, "creator": "ryan.bennitt@the-logic-group.com", "is_private": false, "id": 179711, "time": "2014-12-11T12:44:26Z", "bug_id": 57341, "creation_time": "2014-12-11T12:44:26Z", "tags": [], "text": "While performing a JUnitReport task, our build server started consistently reporting Stack Overflow errors:\n\nbuild.xml:773: The following error occurred while executing this line:\nbuild.xml:923: java.lang.StackOverflowError\n\tat com.sun.org.apache.xml.internal.serializer.ToStream.processDirty(ToStream.java:1571)\n\tat com.sun.org.apache.xml.internal.serializer.ToStream.characters(ToStream.java:1489)\n\tat com.sun.org.apache.xml.internal.serializer.ToHTMLStream.characters(ToHTMLStream.java:1529)\n\tat com.sun.org.apache.xml.internal.serializer.ToStream.characters(ToStream.java:1614)\n\tat com.sun.org.apache.xalan.internal.xsltc.runtime.AbstractTranslet.characters(AbstractTranslet.java:621)\n\tat junit_frames.br$dash$replace()\n\tat junit_frames.br$dash$replace()\n\tat junit_frames.br$dash$replace()\n\t...\n        at junit_frames.br$dash$replace()\n\tx1000\n\nI tested locally and got a slightly different result:\n\nbuild.xml:923: java.lang.OutOfMemoryError: Java heap space\n        at java.util.Arrays.copyOfRange(Arrays.java:2694)\n        at java.lang.String.<init>(String.java:203)\n        at java.lang.String.substring(String.java:1877)\n        at com.sun.org.apache.xalan.internal.xsltc.runtime.BasisLibrary.substring_afterF(BasisLibrary.java:329)\n        at junit_frames.br$dash$replace()\n        at junit_frames.br$dash$replace()\n        at junit_frames.br$dash$replace()\n\t...\n        at junit_frames.br$dash$replace()\n\tx1000\n\nMonitoring the build on my workstation, Java Mission Control showed the memory spiking to over 1.47GB before I got the out of memory error.\n\nI had a look at the br-replace template in the $ANT_HOME/etc/junit-frames.xsl and $ANT_HOME/etc/junit-noframes.xsl files and it is performing a recursive replace of line returns one by one, so as soon as you perform a br-replace on a file with more line returns than your stack limit, you're going to get this error, unless you run out of memory first.\n\nI managed to reimplement the br-replace template to be less stack/heap intensive. After trying unsuccessfully to use the java String.replace/replaceAll and StringUtils.replace functions that are used elsewhere (which seem to have issues, possibly JVM dependent) I went for a plain XSLT 1.0 implementation using a binary-subdivision approach that splits the string approximately evenly on the nearest line break on large strings:\n\n<xsl:template name=\"br-replace\">\n  <xsl:param name=\"word\"/>\n  <xsl:param name=\"splitlimit\">32</xsl:param>\n  <xsl:variable name=\"secondhalflen\" select=\"(string-length($word)+(string-length($word) mod 2)) div 2\"/>\n  <xsl:variable name=\"secondhalfword\" select=\"substring($word, $secondhalflen)\"/>\n  <!-- When word is very big, a recursive replace is very heap/stack expensive, so subdivide on line break after middle of string -->\n  <xsl:choose>\n    <xsl:when test=\"(string-length($word) > $splitlimit) and (contains($secondhalfword, '&#xa;'))\">\n      <xsl:variable name=\"secondhalfend\" select=\"substring-after($secondhalfword, '&#xa;')\"/>\n      <xsl:variable name=\"firsthalflen\" select=\"string-length($word) - $secondhalflen\"/>\n      <xsl:variable name=\"firsthalfword\" select=\"substring($word, 1, $firsthalflen)\"/>\n      <xsl:variable name=\"firsthalfend\" select=\"substring-before($secondhalfword, '&#xa;')\"/>\n      <xsl:call-template name=\"br-replace\">\n        <xsl:with-param name=\"word\" select=\"concat($firsthalfword,$firsthalfend)\"/>\n      </xsl:call-template>\n      <br/>\n      <xsl:call-template name=\"br-replace\">\n        <xsl:with-param name=\"word\" select=\"$secondhalfend\"/>\n      </xsl:call-template>\n    </xsl:when>\n    <xsl:when test=\"contains($word, '&#xa;')\">\n      <xsl:value-of select=\"substring-before($word, '&#xa;')\"/>\n      <br/>\n      <xsl:call-template name=\"br-replace\">\n        <xsl:with-param name=\"word\" select=\"substring-after($word, '&#xa;')\"/>\n      </xsl:call-template>\n    </xsl:when>\n    <xsl:otherwise>\n  <xsl:value-of select=\"$word\"/>\n    </xsl:otherwise>\n  </xsl:choose>\n</xsl:template>\n\nThis implementation is much more heap/stack friendly. JMC only reported a peak of 621MB, compared to the 1.47GB it hit before overflowing."}, {"count": 1, "attachment_id": 32282, "bug_id": 57341, "is_private": false, "id": 179712, "time": "2014-12-11T13:06:14Z", "creator": "ryan.bennitt@the-logic-group.com", "creation_time": "2014-12-11T13:06:14Z", "tags": [], "text": "Created attachment 32282\njunit-frames.xsl fixed br-replace template as described"}, {"count": 2, "tags": [], "bug_id": 57341, "text": "Created attachment 32283\njunit-noframes.xsl fixed br-replace template as described", "id": 179713, "time": "2014-12-11T13:07:16Z", "creator": "ryan.bennitt@the-logic-group.com", "creation_time": "2014-12-11T13:07:16Z", "is_private": false, "attachment_id": 32283}, {"count": 3, "tags": [], "bug_id": 57341, "text": "Just realised these files are in the main ant repository. This probably belongs in core tasks component.", "id": 179714, "time": "2014-12-11T15:30:41Z", "creator": "ryan.bennitt@the-logic-group.com", "creation_time": "2014-12-11T15:30:41Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "bug_id": 57341, "attachment_id": null, "is_private": false, "id": 180015, "time": "2014-12-24T13:19:55Z", "creator": "bodewig@apache.org", "creation_time": "2014-12-24T13:19:55Z", "text": "Ryan, please don't close the issue until the patch has made its way into the official repository. :-)"}, {"count": 5, "attachment_id": null, "creator": "ryan.bennitt@the-logic-group.com", "text": "Oops, cheers.", "id": 180016, "time": "2014-12-24T13:21:17Z", "bug_id": 57341, "creation_time": "2014-12-24T13:21:17Z", "tags": [], "is_private": false}, {"count": 6, "attachment_id": null, "bug_id": 57341, "is_private": false, "id": 180019, "time": "2014-12-24T14:40:14Z", "creator": "bodewig@apache.org", "creation_time": "2014-12-24T14:40:14Z", "tags": [], "text": "I can see how your approach limits the amount of stack being used in certain cases, but am unsure about splitlimit's default.  In a degenerated case where I have a long text with a line break every 72 columns (roughly) I'd get as many recursive calls as before, wouldn't I?\n\nWhat does the big amount of text that causes the stack overflow or OOM in your case look like?  A very long stacktrace?  In my experience individual lines of a stack trace tend to be longer than 32 characters."}, {"count": 7, "tags": [], "bug_id": 57341, "text": "(In reply to Stefan Bodewig from comment #6)\n> I can see how your approach limits the amount of stack being used in certain\n> cases, but am unsure about splitlimit's default.  In a degenerated case\n> where I have a long text with a line break every 72 columns (roughly) I'd\n> get as many recursive calls as before, wouldn't I?\n> \n> What does the big amount of text that causes the stack overflow or OOM in\n> your case look like?  A very long stacktrace?  In my experience individual\n> lines of a stack trace tend to be longer than 32 characters.\n\nIt turned out to be a large XML file in the end. Average line length 55, but with significant variance, very long lines, and some runs of line returns.\n\nThe original implementation would parse the first line and give the rest to the recursive call, which resulted in N-1 + N-2 + N-3... lines being copied and passed down each time, amount of memory required of the order N^2 until you get to the last line and can return all the way back down the N-length stack.\n\nWith this implementation the stack never exceeds log2(N) and memory of the order 2N, until you get down to small chunks of text (of length splitlimit/2) at which point we shouldn't be in any danger of running out of memory. The default splitlimit is a bit arbitrary, you don't want it too large that the remaining text can overflow your stack in the worst case. It just seemed a lot of work to keep splitting text in two at some point, rather than parse the rest in the original recursive manner, especially given expected and best/worst case line lengths. You've also got the added factor that it gives up splitting when it doesn't find a line return in the second half of the chunk of text being processed, at which point it checks for a line return (in the first half) and does the normal recursive replace until there are no line returns left.\n\nBy all means tweak the splitlimit default.", "id": 180020, "time": "2014-12-24T15:11:36Z", "creator": "ryan.bennitt@the-logic-group.com", "creation_time": "2014-12-24T15:11:36Z", "is_private": false, "attachment_id": null}, {"count": 8, "tags": [], "bug_id": 57341, "text": "My mistake, I simply did my calculations on recursion depth wrong.", "id": 180025, "time": "2014-12-26T11:31:16Z", "creator": "bodewig@apache.org", "creation_time": "2014-12-26T11:31:16Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "bug_id": 57341, "attachment_id": null, "is_private": false, "id": 180026, "time": "2014-12-26T12:01:53Z", "creator": "bodewig@apache.org", "creation_time": "2014-12-26T12:01:53Z", "text": "I've just fiddled with whitespace to make the diff smaller:\n\nhttp://git-wip-us.apache.org/repos/asf/ant/commit/f7f5327d\n\nand since the same applies to the stylesheets shipping with AntUnit:\n\nhttp://git-wip-us.apache.org/repos/asf/ant-antlibs-antunit/commit/7396c8b6"}]