[{"count": 0, "tags": [], "bug_id": 31247, "is_private": false, "text": "I'm Running RedHat 9 and I seem to be getting Segmentation Faults in mod_cgi. \nI've seen a lot of intermittent Segmentation Faults in my error logs:\n\n[Wed Sep 15 01:29:24 2004] [notice] child pid 8684 exit signal Segmentation\nfault (11)\n[Wed Sep 15 01:29:28 2004] [notice] child pid 10121 exit signal Segmentation\nfault (11)\n[Wed Sep 15 04:20:56 2004] [notice] child pid 13464 exit signal Segmentation\nfault (11)\n[Wed Sep 15 04:20:58 2004] [notice] child pid 12372 exit signal Segmentation\nfault (11)\n[Wed Sep 15 07:13:50 2004] [notice] child pid 15836 exit signal Segmentation\nfault (11)\n[Wed Sep 15 09:47:34 2004] [error] [client 216.209.83.196] request failed: URI\ntoo long (longer than 8190)\n[Wed Sep 15 10:03:56 2004] [notice] child pid 20783 exit signal Segmentation\nfault (11), possible coredump in /tmp\n[Wed Sep 15 10:03:57 2004] [notice] child pid 18637 exit signal Segmentation\nfault (11)\n\nUpon examing the coredump created at 10:03:56 this morning I got the following\nbacktrace:\n#0  0x40852ce2 in cgi_bucket_read (b=0x8311f10, str=0xbfffdbb8,\n    len=0xbfffdbbc, block=APR_BLOCK_READ) at mod_cgi.c:660\n#1  0x4001d56c in apr_brigade_length (bb=0x74203a65, read_all=1,\n    length=0xbfffdc18) at apr_brigade.c:182\n#2  0x08064141 in ap_byterange_filter (f=0x83143b0, bb=0x831cd00)\n    at http_protocol.c:2925\n#3  0x08071372 in ap_pass_brigade (next=0x40855520, bb=0x831cd68)\n    at util_filter.c:511\n#4  0x401c13ed in send_parsed_content (f=0x8320498, bb=0x831c848)\n    at mod_include.c:3431\n#5  0x08071372 in ap_pass_brigade (next=0x40855520, bb=0x831cd68)\n    at util_filter.c:511\n#6  0x08077ace in default_handler (r=0x8313760) at core.c:3553\n#7  0x08067152 in ap_run_handler (r=0x8313760) at config.c:152\n#8  0x0806766a in ap_invoke_handler (r=0x8313760) at config.c:358\n#9  0x08064a8f in ap_process_request (r=0x8313760) at http_request.c:246\n#10 0x08060b79 in ap_process_http_connection (c=0x830d320) at http_core.c:250\n#11 0x0806f32a in ap_run_process_connection (c=0x830d320) at connection.c:42\n#12 0x08065cd7 in child_main (child_num_arg=1948269157) at prefork.c:609\n#13 0x08065df4 in make_child (s=0x809c010, slot=5) at prefork.c:703\n#14 0x0806603a in perform_idle_server_maintenance (p=0x809a270)\n    at prefork.c:838\n#15 0x080665ce in ap_mpm_run (_pconf=0x0, plog=0x80c4318, s=0x0)\n    at prefork.c:1039\n#16 0x0806b572 in main (argc=3, argv=0xbfffe024) at main.c:617\n#17 0x42015704 in __libc_start_main () from /lib/tls/libc.so.6\n\nSo I far I haven't been able to correlate the segmentation faults with the\ninvocation on any particular cgi scripts, however, they only started to appear\nafter we upgraded from Apache 1.3.\n\nI'm also having a possibly related problem with explosive growth in memory usage\nby Apache.  It's also intermittent, sometimes showing up minutes after Apache is\nrestarted, sometimes showing up hours later.  Over the course of a few seconds\nan apache process will grow from it's normal size of approximately 50 megs to\n500 megs.", "id": 63591, "time": "2004-09-15T15:52:53Z", "creator": "tyler@nas.net", "creation_time": "2004-09-15T15:52:53Z", "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 31247, "is_private": false, "text": "Do you have CGI script which output a lot of data? The byterange filter will\nconsume memory proportional to output for such scripts, bug 29962.\n\nFrom gdb can you:\n\nprint *b\nprint *(struct cgi_bucket_data *)b->data\n\nif you do:\n\nup\nup\nprint *f->r\n\nyou should be able to see which particular CGI script has triggered the segfault.", "id": 63599, "time": "2004-09-15T16:11:11Z", "creator": "jorton@redhat.com", "creation_time": "2004-09-15T16:11:11Z", "attachment_id": null}, {"count": 2, "tags": [], "text": "Output from print *b:\n\n$1 = {link = {next = 0x8311a10, prev = 0x8311d80}, type = 0x40855520,\n  length = 4294967295, start = -1, data = 0x8327440,\n  free = 0x805ea74 <apr_bucket_free>, list = 0x8311720}\n\nOutput from print *(struct cgi_bucket_data *)b->data:\n\n$2 = {pollset = 0x8327448, r = 0x8321968}\n\nThanks for the tip on identifying which script was being run, it turns out it\ndied in an index.html file that uses SSI to include output from two different\nCGI scripts.  However, that page is not seg faulting everytime it is visited. \nAlso it died before the server created a log of the request.", "is_private": false, "id": 63611, "creation_time": "2004-09-15T17:52:20Z", "time": "2004-09-15T17:52:20Z", "creator": "tyler@nas.net", "bug_id": 31247, "attachment_id": null}, {"count": 3, "attachment_id": null, "creator": "jorton@redhat.com", "text": "Thanks.  Can you also do \"print *((struct cgi_bucket_data *)b->data)->r\" from\nthat same scope?  May be significant about SSI being involved, I'll try and\nreproduce like that.", "id": 63618, "time": "2004-09-15T19:59:29Z", "bug_id": 31247, "creation_time": "2004-09-15T19:59:29Z", "tags": [], "is_private": false}, {"count": 4, "tags": [], "text": "print *((struct cgi_bucket_data *)b->data)->r:\n\n$1 = {pool = 0x746e6574, connection = 0x7079542d, server = 0x74203a65,\n  next = 0x2f747865, prev = 0x6c6d7468, main = 0x6863203b,\n  the_request = 0x65737261 <Address 0x65737261 out of bounds>,\n  assbackwards = 1397308788, proxyreq = 943205711, header_only = 825047349,\n  protocol = 0xa0d0a0d <Address 0xa0d0a0d out of bounds>,\n  proto_num = 1735223612,\n  hostname = 0x63727320 <Address 0x63727320 out of bounds>,\n  request_time = 7306916042975945277,\n  status_line = 0x656e2f73 <Address 0x656e2f73 out of bounds>,\n  status = 1869573239, method = 0x65662f6b <Address 0x65662f6b out of bounds>,\n  method_number = 1920300129, allowed = 3275079475987754341,\n  allowed_xmethods = 0x64616568, allowed_methods = 0x672e7265,\n  sent_bodyct = 539125353, bytes_sent = 1685221218,\n  mtime = 738064979063566949, chunked = 1768176650,\n  range = 0x6c632076 <Address 0x6c632076 out of bounds>, clength = 1030976353,\n  remaining = 1634035234, read_length = 1852402804, read_body = 171844203,\n  read_chunked = 1746952508, expecting_100 = 1030120818,\n  headers_in = 0x74746822, headers_out = 0x2f2f3a70,\n  err_headers_out = 0x2e777777, subprocess_env = 0x656d6f68,\n  notes = 0x6b726f77,\n  content_type = 0x2e737265 <Address 0x2e737265 out of bounds>,\n  handler = 0x2f67726f <Address 0x2f67726f out of bounds>,\n  content_encoding = 0x2d696763 <Address 0x2d696763 out of bounds>,\n  content_languages = 0x2f6e6962,\n  vlist_validator = 0x72616573 <Address 0x72616573 out of bounds>,\n  user = 0x672f6863 <Address 0x672f6863 out of bounds>,\n  ap_auth_type = 0x67632e6f <Address 0x67632e6f out of bounds>,\n  no_cache = 1031094121, no_local_copy = 1986290532,\n  unparsed_uri = 0x69666f66 <Address 0x69666f66 out of bounds>,\n  uri = 0x76646f64 <Address 0x76646f64 out of bounds>,\n  filename = 0x61686366 <Address 0x61686366 out of bounds>,\n  canonical_filename = 0x6e7a647a <Address 0x6e7a647a out of bounds>,\n  path_info = 0x70666666 <Address 0x70666666 out of bounds>,\n  args = 0x70666866 <Address 0x70666866 out of bounds>, finfo = {\n    pool = 0x643d6b26, valid = 1718576225, protection = 645097064,\n    filetype = 1030517365, user = 1868981862, group = 2036752742,\n    inode = 1835427939, device = 7600496621405104228, nlink = 2053339491,\n    size = 1852072292, csize = 2054712934, atime = 8753443414512138598,\n    mtime = 8747250956752020324, ctime = 7018993500102620004,\n    fname = 0x787a6968 <Address 0x787a6968 out of bounds>,\n    name = 0x68637066 <Address 0x68637066 out of bounds>,\n    filehand = 0x73646166}, parsed_uri = {\n    scheme = 0x68786664 <Address 0x68786664 out of bounds>,\n    hostinfo = 0x76616963 <Address 0x76616963 out of bounds>,\n    user = 0x6b7a787a <Address 0x6b7a787a out of bounds>,\n    password = 0x6b647864 <Address 0x6b647864 out of bounds>,\n    hostname = 0x633d6226 <Address 0x633d6226 out of bounds>,\n    port_str = 0x636b787a <Address 0x636b787a out of bounds>,\n    path = 0x26706368 <Address 0x26706368 out of bounds>,\n    query = 0x74263d61 <Address 0x74263d61 out of bounds>,\n    fragment = 0x7861633d <Address 0x7861633d out of bounds>,\n    hostent = 0x636d786e, port = 25455, is_initialized = 1, dns_looked_up = 1,\n    dns_resolved = 1}, used_path_info = 1633908846,\n  per_dir_config = 0x617a6170, request_config = 0x573e226e,\n  htaccess = 0x646c756f, output_filters = 0x756f7920,\n  input_filters = 0x766f4c20, proto_output_filters = 0x6f742065,\n  proto_input_filters = 0x726f5720, eos_sent = 1919295595}\n", "is_private": false, "id": 63672, "creation_time": "2004-09-16T17:49:09Z", "time": "2004-09-16T17:49:09Z", "creator": "tyler@nas.net", "bug_id": 31247, "attachment_id": null}, {"count": 5, "attachment_id": null, "creator": "jorton@redhat.com", "text": "Can you give a condensed example of the SSI page which did trigger this?  Just\nto confirm, you are using an unpatched 2.0.50 built directly from source?\n\nThe backtrace is actually quite confusing.  It references functions from the new\nCGI bucket type, but these are only actually used by the CGI handler, not when\nan SSI page invokes CGI scripts directly, so they shouldn't be in the picture at\nall.\n\n", "id": 63983, "time": "2004-09-21T14:50:07Z", "bug_id": 31247, "creation_time": "2004-09-21T14:50:07Z", "tags": [], "is_private": false}, {"count": 6, "tags": [], "bug_id": 31247, "text": "Some updates/corrections:\n\n1) Yes, it's been compiled from source, without any patches.\n\n2) There are two separate cgi scripts on our index page, one does banner\nrotation for a banner, it is included four times (once each for 4 banners), the\nother creates a list of links based on the amount bid for placement, it's\nincluded twice.  The first script uses a text file db, while the second script\nuses MySQL.  Both are included with virtual includes.  Here's a sample of one of\nthe sections with the includes (I can't give you the scripts themselves, they\nwere purchased from someone else).\n\n<!--#include virtual=\"/cgi-bin/ads/run.cgi?id=homeworkersa2\"-->\n<!-- homeworkersa2 -->\n</CENTER>\n<!--#include\nvirtual=\"/cgi-bin/search/include.cgi?keywords=main&desc=1&url=1&cost=1&show=1&include=1\"\n-->\n<CENTER>\n<!--#include virtual=\"/cgi-bin/ads/run.cgi?id=homeworkersa3\"-->\n<IMG SRC=\"/images/spacer.gif\" WIDTH=\"160\" HEIGHT=\"5\">\n<!--#include virtual=\"/cgi-bin/ads/run.cgi?id=homeworkersa4\"-->\n<!-- homeworkersa4 -->\n</CENTER>\n\n<hr class=\"green\">\n\n<!--#include\nvirtual=\"/cgi-bin/search/include.cgi?keywords=main&start=1&bt=10&desc=1&url=1&cost=1&show=9&include=1\"\n-->\n\n3) I tried the advice in bug 29962, it didn't help at all.  I'm still getting\nprocesses that bloat up to a huge size and I don't think it's related to sending\nlarge files through the server.  We only have a two scripts that I know of that\nsend out large files and neither one appears to be accessed as often as these\nprocesses appear (I often have to restart apache multiple times during the day,\nit take as little as 5 minutes or as long as several hours to nearly exhaust all\navailable memory).\n\n4) We've upgraded to 2.0.51 as of this morning, I'm still seeing the memory\nproblem and the segmentation faults.  I'm going to attempt to create another\ncore dump with the new httpd.", "id": 64046, "time": "2004-09-22T14:11:05Z", "creator": "tyler@nas.net", "creation_time": "2004-09-22T14:11:05Z", "is_private": false, "attachment_id": null}, {"count": 7, "tags": [], "creator": "jorton@redhat.com", "attachment_id": 12835, "is_private": false, "id": 64051, "time": "2004-09-22T14:58:57Z", "bug_id": 31247, "creation_time": "2004-09-22T14:58:57Z", "text": "Created attachment 12835\npossible fix"}, {"count": 8, "tags": [], "bug_id": 31247, "text": "OK, I think I see what's happening, but I haven't got a reproduction case, so\ntesting with the above patch would be good.", "id": 64052, "time": "2004-09-22T15:01:09Z", "creator": "jorton@redhat.com", "creation_time": "2004-09-22T15:01:09Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "bug_id": 31247, "is_private": false, "text": "I've applied the patch but I'm still getting Segmentation Faults and the memory\ngrowth, and I haven't been able to produce a core dump to examine yet.", "id": 64191, "time": "2004-09-24T15:46:02Z", "creator": "tyler@nas.net", "creation_time": "2004-09-24T15:46:02Z", "attachment_id": null}, {"count": 10, "tags": [], "bug_id": 31247, "is_private": false, "text": "The patch committed which fixes the issue triggered in the given segfault was:\n\nhttp://cvs.apache.org/viewcvs.cgi/httpd-2.0/server/util_filter.c?r1=1.100&r2=1.101\n\nso if you could try that and still get more segfaults, please try and get new\ncore dumps.  (Please open a new bug for any new issues)\n\nThanks for the report and debugging help.", "id": 64232, "time": "2004-09-26T16:34:05Z", "creator": "jorton@redhat.com", "creation_time": "2004-09-26T16:34:05Z", "attachment_id": null}, {"count": 11, "tags": [], "bug_id": 31247, "is_private": false, "text": "It looks like the fix has worked, I don't seem to be able to generate any more\ncore files, and the number of segmentation faults has dropped significantly. \nInstead of 6-10 per day, we seem to now be averaging 1 a day (probably on an\nunrelated issue).", "id": 64282, "time": "2004-09-27T19:24:11Z", "creator": "tyler@nas.net", "creation_time": "2004-09-27T19:24:11Z", "attachment_id": null}, {"count": 12, "tags": [], "text": "Thanks Tyler.", "is_private": false, "id": 64332, "creation_time": "2004-09-28T16:29:16Z", "time": "2004-09-28T16:29:16Z", "creator": "jorton@redhat.com", "bug_id": 31247, "attachment_id": null}, {"count": 13, "tags": [], "text": "Actually, I think I should be thanking you for the quick fix.  :)", "is_private": false, "id": 64343, "creation_time": "2004-09-28T18:58:37Z", "time": "2004-09-28T18:58:37Z", "creator": "tyler@nas.net", "bug_id": 31247, "attachment_id": null}]