[{"count": 0, "tags": [], "creator": "gus_goose@canada.com", "attachment_id": null, "id": 56320, "time": "2004-04-23T22:00:45Z", "bug_id": 28565, "creation_time": "2004-04-23T22:00:45Z", "is_private": false, "text": "Execute task creates a java.lang.Process object when launching some commands.\nThe STDIN, STDOUT, and STDERR for the process are captured, and given to the\nExecuteStreamHandler. These are represented by an OutputStream, and two\nInputStreams.\n\nIn the most common case (PumpedStreamHandler), there is no explicit close()\ncalled on any of these streams. Thus, until the GC runs, these streams all hold\nOS resources (in particular File Descriptors).\n\nIn perusing the code, I believe that in every instance that the\nPumpedStreamHandler is use, it is safe to close() all the streams in the stop()\nmethod. Further, although I am less certain, I believe it is safe, and probably\nmore desirable to close() each stream after calling the stop() method of the\nExecuteStreamHandler in the execute() method in Execute.\n\nI encountered this problem in a non-standard use of ant, where I have multiple\ntasks all \"executing\" regularly, and repeatedly. Because GC was slow (and at\ntimes I switched it off in the VM), I routinely ran out of file-descriptors\n(ulimit -H -n == 1024).\n\nMy current workaround solution is to implement my own Stream Handler\n(duplicating much of PumpedStreamHandler), which explicitly close()'s the\nStreams in the stop() method.\n\ngus"}, {"count": 1, "tags": [], "creator": "mbenson@apache.org", "attachment_id": null, "id": 56322, "time": "2004-04-23T22:24:04Z", "bug_id": 28565, "creation_time": "2004-04-23T22:24:04Z", "is_private": false, "text": "Gus:  PumpedStreamHandler makes use of StreamPumper objects.  These can be \nconstructed to automatically close the streams or not.  The output streams are \nnot closed by PumpedStreamHandler's use of StreamPumpers, by design.\n\nOne question I have:  what do you mean by Execute task?  Do you mean the \nExecute class (not a task) or the ExecTask class (which is a task)  --?  \nExecTask, for example, uses a Redirector helper object to take care of the \nProcess I/O, and it is in this Redirector's complete() method that the relevant \nstreams are closed.  If you are using the Execute class from your own code, \nthen indeed, yes, you need to close your streams however you see fit, and \ncreating your own ExecuteStreamHandler implementation is certainly one valid \nsolution.  But I'm not going to count any of this as a problem until I see \nevidence that one or more of the core tasks is not closing the stream.  Please \nadd a comment if this is, after all, the case.\n\nThanks,\nMatt"}, {"count": 2, "tags": [], "bug_id": 28565, "attachment_id": null, "text": "Hi Matt, others.\n\nHaving re-visited the code, and been even more diligent with my study, I\nmaintain that there IS a problem with Input/Output streams not being closed. Let\nme show by example:\n\nTake the core class org.apache.tools.ant.taskdefs.AbstractCvsTask (base for 4\nCVS related tasks. It's execute() method calls the runCommand() method (multiple\ntimes). The runCommand() method creates an org.apache.tools.ant.taskdefs.Execute\ninstance using a PumpStreamHandler. After setting the environment, workingdir,\netc, it calls the execute() method of the Execute instance.\n\nThis is where it gets important.\n\nThe execute() method calls the launch() method which returns a java.lang.Process\ninstance. This is the important instance (variable name is \"process\"). The\nfollowing code runs:\n            streamHandler.setProcessInputStream(process.getOutputStream());\n            streamHandler.setProcessOutputStream(process.getInputStream());\n            streamHandler.setProcessErrorStream(process.getErrorStream());\n\nThe Important three streams to follow are:\nprocess.getOutputStream() (I'll call it NB_A)\nprocess.getInputStream() NB_B,\nprocess.getErrorStream() NB_C\n\nEach of these three streams represents a FileDescriptor on Unix OS's.\nexecute() starts the ExecuteStreamHandler(in our example, a PumpStreamHandler)\nexecute() waits for the process to complete, and then stop() the PumpStreamHandler.\n\nIt returns the exit code of the java.lang.Process instance.\n\nNow, NB_A, NB_B, and NB_C are never close()'d in the execute(). If you inspect\nthe PumpStreamHandler, you will note that it only (optionally) close()'s the\nstreams to which it pumps the data to, it does not close() the actual streams\nprovided by the Process (NB_A,NB_B, and NB_C).\n\nThus, the only time the NB_A, NB_B, and NB_C streams are close()'d are when the\nExecuteStreamHandler given to the Execute class explicitly does it. By far the\nmajority of times the Execute class is used, it is used with either the\nPumpStreamHandler, or LogStreamHandler. Neither of these classes close the\nProcess input/output streams. Thus, the vast majority of executions (including\nExtarnalJavac, CVS, VSS, and other Ant tasks leave open file descriptors long\nafter they are discarded in the code (but not yet Garbage Collected).\n\nIn all instances where I have inspected the use of Execute class (19 instances\nso far), I have found that it would be safe to close the three streams NB_A,\nNB_B, and NB_C after calling the stop() method of the ExecuteStreamHandler.\n\nAttached is a small build file (good for Unix environment - correct the location\nfor ksh, and lsof) that shows the problem:\n\n<project name=\"ShowBug\" default=\"bug\">\n\n  <property name=\"ksh\" value=\"/usr/bin/ksh\" />\n  <property name=\"lsof\" value=\"/usr/local/bin/lsof\" />\n\n  <target name=\"pid\">\n    <echo file=\"getpid\" >\n      echo PPID=$PPID\n    </echo>\n    <exec executable=\"${ksh}\" output=\"pidout\" >\n      <arg line=\"getpid \" />\n    </exec>\n    <property file=\"pidout\" />\n    <echo message=\"I am process ${PPID}\" />\n  </target>\n\n  <target name=\"lsofa\" depends=\"pid\" >\n    <exec executable=\"${lsof}\" >\n      <arg line=\" -p ${PPID}\" />\n    </exec>\n  </target>\n\n  <target name=\"lsofb\" >\n    <exec executable=\"${lsof}\" >\n      <arg line=\" -p ${PPID}\" />\n    </exec>\n  </target>\n\n  <target name=\"reproduce\" >\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n  </target>\n\n  <target name=\"bug\" depends=\"lsofa,reproduce,lsofb\">\n  </target>\n</project>\n\n\ngus", "id": 56435, "time": "2004-04-26T20:40:55Z", "creator": "gus_goose@canada.com", "creation_time": "2004-04-26T20:40:55Z", "is_private": false}, {"count": 3, "tags": [], "text": "After having gone to the trouble of locating a precompiled lsof executable \nbecause I couldn't get it to install, I still don't see what this example is \nattempting to prove.  My slightly modified version of your buildfile:\n\n<project name=\"ShowBug\" default=\"bug\">\n\n  <property name=\"ksh\" value=\"/usr/bin/ksh\" />\n  <property name=\"lsof\" value=\"/usr/local/bin/lsof\" />\n\n  <target name=\"pid\">\n    <echo file=\"getpid\" >\n      echo PPID=$PPID\n    </echo>\n    <exec executable=\"${ksh}\" output=\"pidout\" >\n      <arg line=\"getpid \" />\n    </exec>\n    <property file=\"pidout\" />\n    <echo message=\"I am process ${PPID}\" />\n  </target>\n\n  <target name=\"lsofa\" depends=\"pid\">\n    <!-- send these to output files for easy comparison -->\n    <exec executable=\"${lsof}\" output=\"lsofa\">\n      <arg line=\" -p ${PPID}\" />\n    </exec>\n  </target>\n\n  <!-- in a real buildfile, having both targets depend on pid\n       would be okay as long as they are not invoked separately from\n       the commandline, in which case you'd get an insignificant warning -->\n\n  <target name=\"lsofb\" depends=\"pid\">\n    <exec executable=\"${lsof}\" output=\"lsofb\">\n      <arg line=\" -p ${PPID}\" />\n    </exec>\n  </target>\n\n  <target name=\"reproduce\">\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n    <exec executable=\"/bin/true\" />\n  </target>\n\n  <target name=\"bug\" depends=\"lsofa,reproduce,lsofb\" />\n\n  <target name=\"clean\">\n    <delete>\n      <fileset dir=\"${basedir}\" includes=\"lsofa,lsofb\" />\n    </delete>\n  </target>\n\n</project>\n\nWhen I save to showbug.xml and use the following command line:\n\nant -f showbug.xml && wc -l lsofa lsofb\n\nwc tells me:\n\n      75 lsofa\n      75 lsofb\n     150 total\n\nSo if the example is intended to show me that there are more files open after \nthe reproduce target is called, I can't see that it does.  In the case of \n<exec> (ExecTask), its streams are closed when Redirector.complete() is \ncalled.  Inspection of AbstractCVSTask shows that its output and error streams \n(if not null) are closed in a finally block at the end of runCommand(), so this \nexample also does not seem to hold water.\n\nAs you say, in most cases it would be fine to have the PumpStreamHandler's \nStreamPumpers automatically close their streams.  But as long as the job is \ndone somewhere there should be no problem.", "attachment_id": null, "bug_id": 28565, "id": 56439, "time": "2004-04-26T22:28:44Z", "creator": "mbenson@apache.org", "creation_time": "2004-04-26T22:28:44Z", "is_private": false}, {"count": 4, "tags": [], "creator": "gus_goose@canada.com", "attachment_id": 11350, "id": 56470, "time": "2004-04-27T12:42:57Z", "bug_id": 28565, "creation_time": "2004-04-27T12:42:57Z", "is_private": false, "text": "Created attachment 11350\nResults of running ant using build.xml described in comments"}, {"count": 5, "tags": [], "creator": "gus_goose@canada.com", "attachment_id": null, "id": 56471, "time": "2004-04-27T12:43:57Z", "bug_id": 28565, "creation_time": "2004-04-27T12:43:57Z", "is_private": false, "text": "Hi again.\n\nFirstly, have a look again at the finally {} block in\nAbstractCVSTask.runCommand() It is NOT closing the streams created by the\njava.lang.Process class (which are actually InputStreams), but is closing the\nstreams (OutputStreams) to which the contents of the Process's Input streams are\npumped.\n\nSecondly, after further research, I have found that my problem is specific to\nSolaris (I tried Linux at home later). So, I believe it is related to Java bug\n4637504  ( http://developer.java.sun.com/developer/bugParade/bugs/4637504.html )\n\nBasically, for all other OS's, the Process cleans up properly on termination. On\nSolaris, it doesn't.\n\nRegardless, the work-around proposed in the above Java bug is safe for all OS's,\nand it's use should be considered in Ant. It is the same work-around that I have\nfound in my experiments (and suggested first time around), that the three\nProcess Streams (STDERR, STDOUT, and STDIN) should be explicitly closed before\nreturning from Execute.execute().\n\nI am going to leave status as re-opened, but the powers that be may want to\nclose this as too-low-to-worry-about. In that case, feel free to close it\n(again), and I will leave it that way. On the other hand, with JDK1.4.1, on\nSolaris, it is very easy to run out of file descriptors, and a very easy fix in\nAnt will prevent that.\n\nFor the record, attached is the output of the build in \"my\" environment.\n\ngus"}, {"count": 6, "tags": [], "bug_id": 28565, "attachment_id": null, "text": "I think Gus is correct, we only close half of the pipe (if we close anything at\nall).\n", "id": 56474, "time": "2004-04-27T12:58:49Z", "creator": "bodewig@apache.org", "creation_time": "2004-04-27T12:58:49Z", "is_private": false}, {"count": 7, "tags": [], "text": "I think we're finally on the same page.  I will make sure this doesn't impact \nanything and put it in.", "attachment_id": null, "id": 56476, "creator": "mbenson@apache.org", "time": "2004-04-27T13:58:14Z", "bug_id": 28565, "creation_time": "2004-04-27T13:58:14Z", "is_private": false}, {"count": 8, "tags": [], "text": "I have committed a fix for anything invoked via the execute() method, or \nrather, anything that uses the (protected) waitFor(Process) method.  This is in \nCVS HEAD and I will merge it to the 1.6 branch in a few days.  I will also do a \nrecursive grep for anything calling Execute.launch() which returns a Process \nwithout waiting for it.  Finally, anything spawned will not close its streams \nother than the InputStream.  This is probably okay but if it becomes a problem \nwe can always reevaluate.\n\nThanks,\nMatt", "attachment_id": null, "bug_id": 28565, "id": 56482, "time": "2004-04-27T15:28:34Z", "creator": "mbenson@apache.org", "creation_time": "2004-04-27T15:28:34Z", "is_private": false}, {"count": 9, "tags": [], "text": "Hi again all (Matt).\n\nI have just viewed the fix committed to CVS, and I am not sure it is the best\napproach (sorry to be a PITA). I believe that the closes should happen only\nAFTER the stop() method is called on the ExecuteStreamHandler, which means\nmoving them from the waitFor(), and putting tme in the execute(). My concern is\nthat the threads  reading from the streams we close may still be active until\nthe stop() is called, causing IOExceptioons if the read() on the stream when it\nis closed. It would thus be better to close() after the handler is stopped,\nwhere we have more certainty that any reading threads have terminated.\n\ngus", "attachment_id": null, "id": 56499, "creator": "gus_goose@canada.com", "time": "2004-04-27T17:47:59Z", "bug_id": 28565, "creation_time": "2004-04-27T17:47:59Z", "is_private": false}, {"count": 10, "tags": [], "creator": "mbenson@apache.org", "attachment_id": null, "text": "Okay, committed another version.  This should allow us to cleanly take care of \nthe optional Cab task, which uses Execute.launch(), as well.", "id": 56502, "time": "2004-04-27T18:17:13Z", "bug_id": 28565, "creation_time": "2004-04-27T18:17:13Z", "is_private": false}, {"count": 11, "tags": [], "bug_id": 28565, "attachment_id": null, "text": "We found the same problem and developed the exact same fix (having just \nchecked the CVS, it really is). I was comnig in today to submit a bug with the \npatch, but lo and behold, I am too late.  :D\n\nI can add that this particular bug will affect Tomcat users who performance \ntune their JVMs. This is due to the way Tomcat compiles JSPs, actually using \nAnt and (almost always, due to other problems) forking when compiling - hence \nthe use of Execute.\n\nThe underlying problem (of not closing the streams of your Process object) is \nnormally concealed, because Java's Process object closes these streams for you \nin its finalize() method, and the typical garbage collector configuration is \nsubjectively what I would call \"aggressive.\" Processes often don't survive \nlong, and nobody remembers to close the streams on them, but it hardly comes \nup. Even Sun has omitted the requirement to close the Process's streams in the \nAPI documentation for Runtime.exec() and Process, I think because \nnormally, \"the GC will do it for you.\" This runs counter to Sun's own \n(correct) policy: \n\n\"...an example is relying on finalization to close file descriptors, which \nmakes an external resource (descriptors) dependent on GC promptness. Relying \non GC to manage resources other than memory is almost always a bad idea.\" \n(http://java.sun.com/docs/hotspot/gc/)\n\nPower users with big machines, big heaps, and unusual settings, especially \nusing things like the concurrent mark-sweep collector\n(http://java.sun.com/developer/technicalArticles/Programming/turbo/) will find \ntheir objects tend to escape into the old generation and linger much longer. \nThus, \"big\" Tomcat installs where JSPs may be added and changed will find \nthemselves chewing up file descriptors (i.e. dangling PIPEs) and going down \nwhen they hit OS limits... very unpleasant. The change discussed here does fix \nthe problem.  :) \n\nTomcat users impatient for results may substitute a patched ant.jar in their \nTomcat install. We patched ant 1.5.4 with this fix and substituted it in \nTomcat 4.1.24 without trouble. I can't vouch for trying the same with newer \nAnt or Tomcat versions, but it will probably work.", "id": 57659, "time": "2004-05-19T17:59:40Z", "creator": "obsidian@panix.com", "creation_time": "2004-05-19T17:59:40Z", "is_private": false}]