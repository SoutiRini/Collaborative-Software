[{"count": 0, "tags": [], "creator": "mark@faime.demon.co.uk", "is_private": false, "text": "Apache 2.0.45\nPerl CGI.pm (2.93) (where used)\nO/S HP-UX 11 (HP-UX cvhp344 B.11.00 A 9000/782 2000406090 two-user license)\nCompiler CC: HP ANSI C++ B3910B A.03.34\n\nNote: This problem seems to be O/S dependent (HP-UX)\n\nAttached is the summary of a posting to comp.infosystems.www.servers.unix:\n\nI'm having problems uploading large binary files from a web browser\nusing Apache (2.0.45) on HP-UX 11.  It seems that small binary files\n(around 15k) upload OK, but larger files (>15k?) are getting\ntruncated.\n\nWhen using CGI.pm (2.93), this will result in the infamous error\nmessage:\nCGI.pm: Server closed socket during multipart read (client aborted?)\n\nHowever, writing my own CGI client without the CGI Perl module, it\nseems that Apache just stops sending the form data part way through,\ni.e. data is truncated.  This seems to be an Apache problem and the\nclient browser used makes no difference (tested with IE5.0 on NT and\nNetscape 4.8 on HP-UX).\n\nI've not changed any of the tunable Apache directives from defaults,\nhence there should be no throttling based on file size, etc.\n\nRunning the same version of Apache on Linux (x86) doesn't seem to\nexhibit this problem.  I'm wondering if this is something funny with\nHP-UX?   I've spent a couple of days searching Google and it seems a\nfew people have hit the above CGI error with Apache2 on HP-UX,\nalthough there is never a solution.  For what its worth, the files I'm\ntrying to upload are binary Microsoft Excel about 17k in size.\n\nI've had this problem for a while across the last 3 or 4 Apache 2\nbuilds, but I'm getting pushed by my users to get the problem sorted. \nBefore I go digging into the Apache source, has anyone got any ideas?\n\n--\n\nResponding to my own question...\n\nI have had some limited feedback confirming this problem on other\nHP-UX/Apache 2 installations.  Apparently reverting back to Apache 1.3\nresolves the problem.\n\nDigging deeper I have noticed the following:\nin mod_cgi.c within the function cgi_handler(), it seems that the call\nto apr_file_write_full() returns a non-successful return code part way\nthrough writing the form data to the child process.  Apache then\ngobbles up the remaining form data without trying to send it again. \nSome entries in the error log would have been useful here!\n\nIn the function apr_file_write() (unix/readwrite.c), it seems that\nwhen apr_wait_for_io_or_timeout() returns success, Apache tries to\nwrite more data to the fd (why?), which fails with error 11 (EAGAIN). \nI patched the code by returning success (and zero bytes written) after\na successful apr_wait_for_io_or_timeout(), which seems to solve the\nproblem in this instance.\n\nThere may be some #defines or something not setup properly for HP-UX,\nalthough not defining USE_WAIT_FOR_IO at all causes the whole thing to\nbreak on HP-UX.\n\nMark Street.", "id": 37915, "time": "2003-05-28T12:08:12Z", "bug_id": 20295, "creation_time": "2003-05-28T12:08:12Z", "attachment_id": null}, {"count": 1, "tags": [], "text": "btw, are you using mod_cgi or mod_cgid?  mod_cgid's handling of request bodies\nis currently busted on HP-UX because HP-UX doesn't properly implement shutdown()\non Unix sockets...  CGIs don't see EOF on standard input, so only CGIs that read\nthe request body based on Content-Length will work\n\n", "is_private": false, "id": 37916, "creator": "trawick@apache.org", "time": "2003-05-28T12:21:55Z", "bug_id": 20295, "creation_time": "2003-05-28T12:21:55Z", "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 20295, "attachment_id": null, "id": 37923, "time": "2003-05-28T15:05:31Z", "creator": "mark@faime.demon.co.uk", "creation_time": "2003-05-28T15:05:31Z", "is_private": false, "text": "I believe I'm only using the built in mod_cgi.\nI haven't compiled Apache for multithreading and the code in mod_cgi.c is \ndefinitely being called when this problem occurs.\n\nThe problem only seems to occur when there is a large amount of data to be sent \nfrom the server to the child process.  I've had no problems submitting small \namounts of form data over the last few Apache 2 builds on HP-UX.\n"}, {"count": 3, "tags": [], "bug_id": 20295, "text": "Created attachment 6592\nPatch for UNIX readwrite.c", "id": 38150, "time": "2003-06-02T06:53:23Z", "creator": "mark@faime.demon.co.uk", "creation_time": "2003-06-02T06:53:23Z", "is_private": false, "attachment_id": 6592}, {"count": 4, "tags": [], "bug_id": 20295, "attachment_id": null, "id": 38151, "time": "2003-06-02T06:57:20Z", "creator": "mark@faime.demon.co.uk", "creation_time": "2003-06-02T06:57:20Z", "is_private": false, "text": "I have attached a patch file showing the change I made to readwrite.c in order\nto work around the above problem.  There's probably a good reason for the code I\ncommented out that may make sense to the original author.\n"}, {"count": 5, "tags": [], "creator": "trawick@apache.org", "is_private": false, "text": ">In the function apr_file_write() (unix/readwrite.c), it seems that\n>when apr_wait_for_io_or_timeout() returns success, Apache tries to\n>write more data to the fd (why?)\n\napr_wait_for_io_or_timeout() is supposed to return success when it is \nsafe to write to the descriptor again\n\napr_file_write() on a pipe with a timeout is supposed to try to write data once\napr_wait_for_io_or_timeout() returns success...\n\n>, which fails with error 11 (EAGAIN). \n\nif apr_wait_for_io_or_timeout() returns APR_SUCCESS but a subsequent attempt to\nwrite gets EAGAIN, that is bogus\n\nlook in srclib/apr/support/unix/waitio.c...  maybe poll() is reporting that the\ndescriptor is writable when it really isn't?  maybe poll has to be called\ndifferently for a pipe on HP-UX?\n\n>I patched the code by returning success (and zero bytes \n>written) after\n>a successful apr_wait_for_io_or_timeout(), which seems to solve the\n>problem in this instance.\n\nseems to me that doing this just serves to change the timing a little bit... \napr_file_write_full() has to turn around and try to write the same data again...\n", "id": 38177, "time": "2003-06-02T14:39:46Z", "bug_id": 20295, "creation_time": "2003-06-02T14:39:46Z", "attachment_id": null}, {"count": 6, "attachment_id": null, "bug_id": 20295, "text": "Using a binary upload file of approx 17K, the following behaviour seems fairly \nconsistent in this test:\n\n1. apr_file_write() called and writes 8000 bytes to FD ok and returns.\n2. apr_file_write() called and writes 192 bytes to FD ok and returns.\n3. apr_file_write() called, but blocks (11:EAGAIN) on first write() attempt.\napr_wait_for_io_or_timeout() returns APR_SUCCESS.  Second attempt at write is \nsuccessful (8000 bytes on FD).\n4. apr_file_write() called, but blocks (11:EAGAIN) on first write() attempt.\napr_wait_for_io_or_timeout()returns APR_SUCCESS.  Second attempt also blocks \n(11:EAGAIN), which returns a non-successful return code to calling function - \nthus killing upload.\n\nFrom my tests I'm fairly sure that the poll code is correct.  It seems to be \ncalling poll() on the correct FD and revents is being set to POLLOUT (0x0100) \nas expected.  However, this sill results in the following call to write() on \nthe same FD blocking.\n\nMy only thought on this is the following from poll(2) on HP-UX:\n<<\n      The conditions indicated by POLLNORM and POLLOUT are true if and only\n      if at least one byte of data can be read or written without blocking.\n      The exception is regular files, which always poll true for POLLNORM\n      and POLLOUT.  Also, streams return POLLNORM in revents even if the\n      available message is of zero length.\n>>\n\nI'm guessing that poll() is setting POLLOUT to always be true, hence the \nfollowing call to write() may still block.  For the CGI client FD, \npollset.desc_type = APR_POLL_FILE.\n\nMy fix was to return a compliance of success after the initial write() blocks \n(with zero bytes written).  I'm guess that the FD will no longer block when \napr_file_write() is next called (because of slightly longer delay), else it \nblocks and we go around again.\n\nIf the above poll behaviour isn't the answer then I'm stuck at this point.  \nAnother question is whether there are any HP-UX 11 patches available that \naffect poll/write, etc.\n", "id": 38255, "time": "2003-06-03T13:22:12Z", "creator": "mark@faime.demon.co.uk", "creation_time": "2003-06-03T13:22:12Z", "tags": [], "is_private": false}, {"count": 7, "tags": [], "bug_id": 20295, "attachment_id": null, "id": 38264, "time": "2003-06-03T14:46:00Z", "creator": "trawick@apache.org", "creation_time": "2003-06-03T14:46:00Z", "is_private": false, "text": ">I'm guessing that poll() is setting POLLOUT to always be true, hence the \n>following call to write() may still block.  For the CGI client FD, \n>pollset.desc_type = APR_POLL_FILE.\n\nThis may be the problem, though that file descriptor is really a pipe as far as\nthe kernel goes, not a regular file.  (APR uses an apr_file_t representation for\na pipe, hence the APR_POLL_FILE usage.  From APR's perspective, it is a\ndescriptor represented by either an apr_socket_t or an apr_file_t.)\n\nI hope to create a test program that spawns a script that reads from stdin, and\nthen pumps large quantities of data to the script via apr_file_write_full(),\nlike mod_cgi.  It will be great to see if it behaves differently on HP-UX 11.00\nor HP-UX 11i (the two HP-UX platforms I have access to) vs. other Unix-ish\nplatforms.\n"}, {"count": 8, "attachment_id": null, "bug_id": 20295, "text": "You might try a test program I wrote to see if it fails on your system.  It\nspawns a Perl script and uses apr_file_write_file_full() to write a bunch of\ndata to it over a pipe with timeout set.  I don't see problems with it on the\nHP-UX 11.00 and 11i systems I have access to.\n\nIt is in http://www.apache.org/~trawick/PR20295/\n\nThe script bld assumes you build it from a subdirectory of apr (e.g., apr/test).\n\nIf it works on your system, maybe we can determine how it differs from your\nmod_cgi scenario.  If it fails, maybe I have installed a good system update or\nyou have installed a bad one.\n", "id": 38289, "time": "2003-06-03T20:03:33Z", "creator": "trawick@apache.org", "creation_time": "2003-06-03T20:03:33Z", "tags": [], "is_private": false}, {"count": 9, "tags": [], "creator": "mark@faime.demon.co.uk", "is_private": false, "text": "The above test program seems to run fine on my system.  I also tried adding \nsome delays in the Perl program between reads, which results in an initial \nblock on the first write, with the second write attempt always being successful \nonce apr_wait_for_io_or_timeout() returns success.  All seems to be working as \nexpected.\n\nHowever, this test only calls apr_file_write_full() just once with a large \namount of data.  My tests show that in a real system apr_file_write_full() gets \ncalled a number of times with a much smaller amount of data (approx. 8000 bytes \nper iteration) - ref. cgi_handler() in mod_cgi.c\n\nI modified the test program (writefull.c) as follows:\n\n...\n    int size = 8000;\n...\n\tdo\n\t{\n\t    rv = apr_file_write_full(script_out, memory, size, NULL);\n\t    printf(\"rv from file_write_full: %d\\n\", rv);\n//\t\tsleep(1);\n\t}\n\twhile (iteration++<10);\n...\n\ni.e. set data size to 8000 and call apr_file_write_full() multiple times.\nOn my system this successfully reproduces the problem:\n\nrv from file_write_full: 0\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_read: 0/52\nContent-Type: text/plain\n\nlength of data read: 8000\n\nInterestingly, if the data size is increased, say to 1000000 bytes, there seems \nto be no problem???\n\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_read: 0/56\nContent-Type: text/plain\n\nlength of data read: 11000000\n\nHowever, if I reduce the amount of data, say to 2000, the first few writes are \nsuccessful, before subesequent attempts block:\n\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 0\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_write_full: 11\nrv from file_read: 0/52\nContent-Type: text/plain\n\nlength of data read: 8000\n\nIf the sleep() call is uncommented in the above loop, the data is written \nsuccessfully in every test case.\n\nI'm hoping you can reproduce this behaviour on your system with the above test \nprogram modifications.", "id": 38349, "time": "2003-06-04T12:57:18Z", "bug_id": 20295, "creation_time": "2003-06-04T12:57:18Z", "attachment_id": null}, {"count": 10, "tags": [], "creator": "trawick@apache.org", "is_private": false, "text": "great work!\n\nI've updated http://www.apache.org/~trawick/PR20295/writefull.c to take two\noptional arguments: iterations and bytes-per-iteration, and I can see the\nfailure (getting EAGAIN unexpectedly) on both HP-UX 11.00 and 11i.\n\nWith 8000 bytes per iteration I have to run it more than 10 times to see the\nfailure.  There is something about the timing.  If I just do\n\n./a.out 20 8000\n\nI'll rarely see 11, but if I do \n\n./a.out 20 8000 | grep 11\n\nI hit it constantly.\n\nI'd think that requiring the test program to report results to a pipe for every\ncall would give swallow.pl a chance to empty the pipe more often and result in\nthe test program getting EAGAIN less frequently.  Instead, the opposite is true\n:)  (I guess swallow.pl is being deprived of cycles required to empty its side\nof the pipe because of the extra grep).\n\nFor the moment I've changed the product to APR since that is where the problem\nlies.  apr_file_write_full() shouldn't be returning EAGAIN on a pipe that has an\nAPR timeout set. It will be APR's job to remedy the situation.\n\nI've played with writefull.c on Linux so far with no bogosities; I want to try\nit on some other systems with various parameters to get more confidence in the\ntheory that this is HP-UX-specific behavior that needs to be fixed/worked-around\nand not a general problem in APR that happens to show up more readily on HP-UX\nbecause of different kernel pipe buffer sizes or different scheduling behavior\nor whatever.\n\nThanks for the report and for your work in uncovering the root cause!  With any\nluck a straightforward solution with no extra scheduling will be possible.", "id": 38357, "time": "2003-06-04T15:01:03Z", "bug_id": 20295, "creation_time": "2003-06-04T15:01:03Z", "attachment_id": null}, {"count": 11, "tags": [], "bug_id": 20295, "attachment_id": null, "text": "This has been an interesting investigation, and I got to re-learn something\nabout pipes from long ago.  I hit the issue on AIX as well and took the\nopportunity to contact an AIX guru.\n\nwrite() on a pipe for <= PIPE_BUF bytes will either write all of them or none of\nthem.  IOW, for relatively small write sizes, pipes have message behavior\ninstead of stream behavior.\n\nWhen poll() returns \"ready\", it only means that at least 1 byte can be written.\n If, for example, PIPE_BUF is 8192 and when poll() returns only 192 bytes can be\nwritten and we try to write 8000 bytes, we'll get EAGAIN.\n\nWhether we hit this on a given system is related to the amount of data we try to\nwrite and PIPE_BUF and timing.\n\nSo independent of platform, the logic has to accept that sometimes write() will\nreturn EAGAIN/EWOULDBLOCK after poll() says \"ready\".  In this situation, it\nneeds to give up the CPU (use select() or poll() to give up CPU for brief\ninterval) and then try to write() again).\n", "id": 38368, "time": "2003-06-04T16:32:08Z", "creator": "trawick@apache.org", "creation_time": "2003-06-04T16:32:08Z", "is_private": false}, {"count": 12, "tags": [], "bug_id": 20295, "attachment_id": null, "id": 38376, "time": "2003-06-04T17:49:56Z", "creator": "trawick@apache.org", "creation_time": "2003-06-04T17:49:56Z", "is_private": false, "text": "oops, moron alert :)   Somebody pointed this out back in October of 2002 and I\nresponded...  my suggestion then was to drop the atomic support by default\n(i.e., if poll(POLLOUT) says \"ready\", write as much as we can rather than\nwaiting until we can write the entire buffer)\n\nnone of the other APR developers suggested an alternative, but the discussion\ndropped and unfortunately my memory isn't so good\n\nLet's consider the discussion re-opened, and a reasonable solution now\nimplemented in\n\nhttp://www.apache.org/~trawick/PR20295/pipes_are_not_atomic.patch\n\nWith this solution, writes on APR pipes are not necessarily atomic.  (I doubt\nthat we really promised that before).\n\nHere is a truss from AIX showing the behavior with this patch:\n\nkwrite(4, \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\".., 8000)   Err#11 EAGAIN\n\ndarn, we can't write our 8000-byte message, so wait until it will work\n\n_poll(0x2FF22678, 0x00000001, 0x00001F40, 0x00000000, 0x00000000, 0x00000000,\n0xFFFFFFFF, 0xFFFFFFFF) = 0x00000001\n\ncool, we can write now?\n\nkwrite(4, \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\".., 8000)   Err#11 EAGAIN\n\ndarn, you won't gulp all 8000 bytes... try again with half-that\n\nkwrite(4, \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\".., 4000)   Err#11 EAGAIN\n\nouch, try again\n\nkwrite(4, \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\".., 2000)   Err#11 EAGAIN\n\nouch, try again\n\nkwrite(4, \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\".., 1000)   Err#11 EAGAIN\n\nouch, try again\n\nkwrite(4, \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\".., 500)    = 500\n\nfinally we made some progress so apr_file_write() can return\n\nPerhaps nbytes should be divided by 4 every time instead of halved.  Or, perhaps\nafter poll() reports \"ready\" but the first write() fails we should drop down to\n25% of PIPE_BUF.  Shrug.  On my AIX box where I tested the change, this testcase\ngets into the retry logic pretty infrequently, so the current halving technique\ndoesn't seem too expensive.\n"}, {"count": 13, "tags": [], "text": "A fix was committed to APR.  It is the same as the last patch mentioned,\nother than a comment change.  There is also a new testcase in the APR\ntest suite to catch such a problem (at least on systems with large pipe buf\nand/or limited numbers of \"messages\" stashable in the kernel).\n\nThis will be in the next Apache httpd 2.0.x release.\n\n", "attachment_id": null, "bug_id": 20295, "id": 38405, "time": "2003-06-05T02:35:15Z", "creator": "trawick@apache.org", "creation_time": "2003-06-05T02:35:15Z", "is_private": false}, {"count": 14, "tags": [], "text": "*** Bug 29627 has been marked as a duplicate of this bug. ***", "attachment_id": null, "bug_id": 20295, "id": 60527, "time": "2004-07-13T09:34:31Z", "creator": "jorton@redhat.com", "creation_time": "2004-07-13T09:34:31Z", "is_private": false}]