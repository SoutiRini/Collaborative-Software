[{"count": 0, "tags": [], "text": "I believe JMeter support of tracking failed samples can be\nsignificantly improved.\nEach and every manual suggests using \"Aggregate Report\" ([1]) or\nfriends, however it silently returns wrong data without any warning.\n\nFor instance: (sample, response time, status)\nSample1, 9 sec, OK\nSample1, 0 sec, ERR\nSample1, 0 sec, ERR\n\nJMeter would show \"average response time\" as 3 seconds, and same for\npercentiles (median should be 9 seconds, not 0).\nHowever, it is common for failed requests to run much faster.\nIt does not matter very much how fast you can crash, but it does\nmatter how fast the successful responses are.\n\nI see two problems here:\n1) Default configuration averages/computes quantiles for both OK and\nERR responses. So users get wrong values in the report.\n2) There is no easy way to track OK and ERR separately. Well, one can\nadd _two_ copies of AggregateReport (one for success, another one for\nfails), however is that ever suggested in the documentation? Is that a\ngood user experience? One would have to switch back and forth from one\nto another.\n\nThe easiest solution seems to change statistics key from \"sampleLabel\" to \"sampleLabel,success\", so successful and failure cases are computed in different buckets.", "attachment_id": null, "id": 180842, "creator": "sitnikov.vladimir@gmail.com", "time": "2015-02-06T20:46:05Z", "bug_id": 57545, "creation_time": "2015-02-06T20:46:05Z", "is_private": false}, {"count": 1, "tags": [], "text": "Thanks for report.\nWouldn't it be better to ignore samplers in error for metrics related to response time ?\nAlthough this could exclude the ones that timeouted which is a couter example of the reported bug.\n\nSeparating ok/ko as you propose, how would you compute error rate ? or did I misunderstand ?\n\nThanks", "is_private": false, "bug_id": 57545, "id": 180929, "time": "2015-02-10T22:51:34Z", "creator": "p.mouawad@ubik-ingenierie.com", "creation_time": "2015-02-10T22:51:34Z", "attachment_id": null}]