[{"count": 0, "tags": [], "bug_id": 50428, "attachment_id": null, "id": 142470, "time": "2010-12-07T18:03:37Z", "creator": "dgoldenberg@attivio.com", "creation_time": "2010-12-07T18:03:37Z", "is_private": false, "text": "We're dealing with a scenario where very large MS Office files are being processed, with a tight limit on the heap size to be 100MB.\n\nThis causes OutOfMemoryError's in RawDataBlockList.\n\njava.lang.OutOfMemoryError: KERNEL-10 : Java heap space\nat org.apache.poi.poifs.storage.RawDataBlock.<init>(RawDataBlock.java:68)\nat org.apache.poi.poifs.storage.RawDataBlockList.<init>(RawDataBlockList.java:53)\nat org.apache.poi.poifs.filesystem.POIFSFileSystem.<init>(POIFSFileSystem.java:155)\n\nRawDataBlockList loads all the blocks till end of file. Is there any way to limit this, perhaps having there be an optional \"sliding window\"-ful of blocks which gets repopulated on demand?\n\nAs a quicker fix, it'd be sufficient to have a way to ascertain whether a given Office file is Excel, Word, or PPT. The way we do this is, once we know it's an Office doc, by examining the magic bytes, we try to read the 'application name' within the POI fs:\n\n  public boolean isRecognized(DocumentPayload payload) {\n    String application = null;\n\n    try {\n      application = getApplicationName(payload.getContentStream(), payload.getDocId());\n    } catch (Exception ex) {\n      log.warn(TextExtractionError.ERROR, ex, \"NON-FATAL error (proceeding with text extraction). Failed to determine application for document. Payload: %s.\", payload);\n    }\n\n    return (application == null) ? false : application.toLowerCase().contains(EXCEL) && application.toLowerCase().contains(MICROSOFT);\n  }\n\nWhere\n\nprotected String getApplicationName(InputStream is, String docId) throws IOException {\n    String application = null;\n\n    try {\n      POIFSFileSystem filesystem = new POIFSFileSystem(is);\n\n      // First, try to extract the application name from the metadata\n      SummaryInformation si = null;\n      PropertySet ps2 = getPropertySet(filesystem, SummaryInformation.DEFAULT_STREAM_NAME, docId);\n      if (ps2 instanceof SummaryInformation) {\n        si = (SummaryInformation) ps2;\n      }\n      application = (si == null) ? null : StringUtils.trim(si.getApplicationName());\n\n      // Unfortunately, the app name may not be present in the document metadata.\n\n      // If that is the case, see if the file system has an entry by which we can tell\n      // that the document matches the type.\n      if (StringUtils.isEmpty(application) && hasDistinguishedEntry(filesystem)) {\n        application = getDefaultApplicationName();\n      }\n\n    } finally {\n      is.close();\n    }\n\n    return application;\n  }\n\nAnd 'hasDistinguishedName' is as follows, e.g. for Excel\n\nprotected boolean hasDistinguishedEntry(POIFSFileSystem filesystem) {\n    boolean hasIt = true;\n\n    // See if the Workbook entry is there\n    try {\n      filesystem.getRoot().getEntry(\"Workbook\");\n    } catch (FileNotFoundException fe) {\n\n      // Try the upper case form\n      try {\n        filesystem.getRoot().getEntry(\"WORKBOOK\");\n      } catch (FileNotFoundException wfe) {\n\n        // Try Book\n        try {\n          filesystem.getRoot().getEntry(\"Book\");\n        } catch (FileNotFoundException wfee) {\n          hasIt = false;\n        }\n      }\n    }\n\n    return hasIt;\n  }\n\nIf we can avoid doing all this, then the OutOfMemory issue becomes less significant. Otherwise we need a way to curtail the memory consumption on the blocklist side and still be able to have access to properties and entries.\n\nAny advise/recommendations?"}, {"count": 1, "tags": [], "text": "It's blocking a customer patch here. Would greatly appreciate your help!", "attachment_id": null, "bug_id": 50428, "id": 142471, "time": "2010-12-07T18:04:54Z", "creator": "dgoldenberg@attivio.com", "creation_time": "2010-12-07T18:04:54Z", "is_private": false}, {"count": 2, "tags": [], "text": "For now you'll just have to bump up the heap size\n\nThere have been discussions on the dev list over the years about ways to reduce the memory footprint of POIFS. However, as yet no-one has been willing to sponsor the work for it.\n\nIf all you want is the names of the streams in the file, then you might be able to cheat a bit to get them. It'd mean some NIO work, and taking advantage of the FAT entries being special so you ought to be able to find them via the header without touching the main data parts. It'd still take some work though", "is_private": false, "bug_id": 50428, "id": 142472, "time": "2010-12-07T19:19:52Z", "creator": "apache@gagravarr.org", "creation_time": "2010-12-07T19:19:52Z", "attachment_id": null}, {"count": 3, "tags": [], "text": "Try NIO Reading using NPOIFSFileSystem, see \"http://poi.apache.org/poifs/how-to.html\" on  http://poi.apache.org/poifs/how-to.html\n\nIt should be more efficient in terms of memory consumption.\n\nYegor", "attachment_id": null, "bug_id": 50428, "id": 147282, "time": "2011-06-20T16:53:23Z", "creator": "yegor@dinom.ru", "creation_time": "2011-06-20T16:53:23Z", "is_private": false}]