[{"count": 0, "tags": [], "bug_id": 51210, "attachment_id": null, "text": "So far, we had no problems transforming *.fo files with FOP 1.0 to PDF. Now, we get OutOfMemoryErrors for *.fo files of about 150 MB and bigger. We tried the 64 Bit JVM with -Xmx2048m and still get OutOfMemoryError after a while.\n\nDuring the long period of PDF transformation we noticed that the destination *.pdf file is not increasing in size but stays at 0 KB! Therefore, it seems that FOP/Transform is trying to generate the PDF completely in RAM!?\n\nMy transformation method:\n\n--------------------------------------------------------------\n    /**\n     * Transform XSL-FO.\n     * \n     * @param nameOfInputFile Name of input FO file (e.g. \"Test.fo\").\n     * @param nameOfOutputFile Name of output PDF file (e.g. \"Test.pdf\").\n     * @param mimeType MIME type for the output format (e.g. MimeConstants.MIME_PDF).\n     * @return The generated PDF file or null if failed.\n     * @throws Exception on error.\n     * @since 4.15.0\n     * @see <a href=\"http://svn.apache.org/viewvc/xmlgraphics/fop/trunk/examples/embedding/java/embedding/ExampleFO2PDF.java?view=markup\">convertFO2PDF()</a>\n     */\n    @SuppressWarnings(\"unchecked\")\n    public final File transformFO(final String nameOfInputFile, final String nameOfOutputFile, final String mimeType) throws Exception {\n        File result = null;\n        \n        OutputStream os = null;\n        try {\n            final File fileOutput = new File(nameOfOutputFile);\n            os = new BufferedOutputStream(new FileOutputStream(fileOutput));\n\n            final Fop fop = fopFactory.newFop(mimeType, foUserAgent, os);\n            final StreamSource ssFO = new StreamSource(new File(nameOfInputFile));\n            final Transformer transformer = factory.newTransformer(); \n            \n            transformer.setErrorListener(new ErrorListener() {\n                @Override\n                public void error(TransformerException exception) throws TransformerException {\n                    LOGGER.severe(\"transformFO(\"+nameOfInputFile+\"): \"+exception.getMessage(), exception);\n                }//error()\n\n                @Override\n                public void fatalError(TransformerException exception) throws TransformerException {\n                    LOGGER.severe(\"transformFO(\"+nameOfInputFile+\"): \"+exception.getMessage(), exception);\n                }//fatalError()\n\n                @Override\n                public void warning(TransformerException exception) throws TransformerException {\n                    LOGGER.warning(\"transformFO(\"+nameOfInputFile+\"): \"+exception.getMessage(), exception);\n                }//warning()\n            });\n            \n            final Result res = new SAXResult(fop.getDefaultHandler());\n            transformer.transform(ssFO, res);\n            \n            if (LOGGER.isLoggable(Level.FINE)) {\n                final FormattingResults foResults = fop.getResults();\n                LOGGER.fine(\"Generated \" + foResults.getPageCount() + \" PDF pages in total:\");\n                final List<PageSequenceResults> pss = foResults.getPageSequences();\n                for (final PageSequenceResults psr : pss) {\n                    LOGGER.fine(\"PageSequence \" + (String.valueOf(psr.getID()).length() > 0 ? psr.getID() : \"<no id>\") + \" generated \" + psr.getPageCount() + \" pages.\");\n                }\n            }\n\n            result = fileOutput;\n        } finally {\n            if (os != null) { os.close(); }\n        }\n        \n        return result;\n    }//transformFO()\n--------------------------------------------------------------------------", "id": 146373, "time": "2011-05-17T10:20:27Z", "creator": "mhilpert@gmx.de", "creation_time": "2011-05-17T10:20:27Z", "is_private": false}, {"count": 1, "tags": [], "bug_id": 51210, "attachment_id": null, "text": "(In reply to comment #0)\n> During the long period of PDF transformation we noticed that the destination\n> *.pdf file is not increasing in size but stays at 0 KB! Therefore, it seems\n> that FOP/Transform is trying to generate the PDF completely in RAM!?\n\nYes and no.\n\nThe entire content would only be in memory if any of the following conditions are met:\n* all content is placed inside a single fo:page-sequence\n* the document contains forward references to the last fo:page-sequence (typically: \"page x of y\" requirements, or TOCs at the start of a huge document)\n\nThe former can currently only be resolved by splitting up the input, which means altering the stylesheet code, and an unavoidable trade-off of a forced page break, but is considered better practice anyway. A monolithic page-sequence (as its correlate: paragraph) is a typographical monstrosity.\nThe impact of the latter can be reduced by calling foUserAgent.setConserveMemoryPolicy(true);. That will result in finished pages with unresolved references being serialized to disk.\n\nIn other cases, if a page-sequence can be rendered, it will be. I am not 100% sure, but I even think that, if the output stream can be written to disk, it will be. Ultimately, that is also a decision of the JVM/OS.\n\nMarking this as a duplicate of bug #1063. Until that is resolved: see above.\n\n*** This bug has been marked as a duplicate of bug 1063 ***", "id": 146608, "time": "2011-05-24T21:45:50Z", "creator": "adelmelle@apache.org", "creation_time": "2011-05-24T21:45:50Z", "is_private": false}, {"count": 2, "tags": [], "bug_id": 51210, "text": "batch transition to closed for remaining resolved bugs", "id": 156374, "attachment_id": null, "creator": "gadams@apache.org", "creation_time": "2012-04-01T13:42:42Z", "time": "2012-04-01T13:42:42Z", "is_private": false}]