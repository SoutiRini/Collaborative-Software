[{"count": 0, "tags": [], "text": "JDBCSampler (and I presume other samplers) store all the output received from\ntheir test action. example:\n\nData data = getDataFromResultSet(rs);\t\t\t\t\t\nres.setResponseData(data.toString().getBytes());\n\nThis is poor software design because the data could be arbitrarily large and\nfill memory. It is causing OutOfMemoryErrors for us, even with not very many\nthreads. This is major or even critical because it prevents JMeter from being\nused to generate significant load. All samplers should be rewritten to just\nbuild an MD5 hash iteratively. The hash should be updated one buffer or row at a\ntime instead of in bulk.", "attachment_id": null, "id": 100743, "creator": "nbryant@optonline.net", "time": "2007-03-21T10:29:40Z", "bug_id": 41921, "creation_time": "2007-03-21T10:29:40Z", "is_private": false}, {"attachment_id": null, "tags": [], "bug_id": 41921, "is_private": false, "count": 1, "id": 100746, "time": "2007-03-21T10:59:04Z", "creator": "sebb@apache.org", "creation_time": "2007-03-21T10:59:04Z", "text": "The full sample results are needed for some purposes - e.g. the Tree View \nListener can display the results of an HTTP Sample, and Assertions need the \nresponse to be present - so it would not make sense to _always_ throw away the \nresponse data.\n\nAnd the data needs to be retrieved, otherwise the sample time will not be \nrepresentative.\n\nHowever sometimes it is not ideal to store all the response data.\n\nAs a work-round you could perhaps do one of the following:\n* change the query to limit the data returned\n* add a BeanShell Post-Processor to zap the responseData field.\n\nAs to how to fix this: there could be an option to limit the size of the stored \ndata. That should be fairly easy to do."}, {"count": 2, "tags": [], "text": "An MD5 or similar hash would be preferable over just storing part of the data,\nfor people who are using the data for functional testing. Then they could\ncompare everything for identity at least. I'm not doing functional testing so I\ndon't care, but I would recommend adding a configuration checkbox for an MD5 mode.", "attachment_id": null, "id": 100750, "creator": "nbryant@optonline.net", "time": "2007-03-21T11:47:00Z", "bug_id": 41921, "creation_time": "2007-03-21T11:47:00Z", "is_private": false}, {"count": 3, "tags": [], "creator": "sebb@apache.org", "text": "I've been looking into how to add hashing to the JDBC sampler.\n\nIt would be easy enough to collect all the response data and convert it to a hash just before storing it. Would that be enough for your tests? The disadvantage of this approach is that JMeter would need enough memory to store the whole response - but at least it would be only temporary.\n\nA better solution would be to hash the data as it is retrieved. However this is not  particularly easy to do, as the data is all fetched and then formatted into lines and columns.\n\nAlso, is it important that the hash is the same as the one that would be obtained by hashing the result data after download? Or does it just need to contain all the response data in a predictable order? This would be easier to do, as there would be no need for the second formatting stage.\n\nAny other suggestions for how to process the JDBC data are welcome...\n", "id": 115376, "time": "2008-04-07T08:49:44Z", "bug_id": 41921, "creation_time": "2008-04-07T08:49:44Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "text": "For my own curiosity, what magnitude of data is being dealt with here?  Are we talking hundreds of megabytes? Gigabytes?  Tens or hundreds of gigabytes?  The reason I ask is because my first thought was to simply have the user increase the maximum heap size of the JVM.  What is the user currently using as the maximum heap size?", "attachment_id": null, "id": 128112, "creator": "kagbusiness@yahoo.com", "time": "2009-06-19T12:59:55Z", "bug_id": 41921, "creation_time": "2009-06-19T12:59:55Z", "is_private": false}, {"count": 5, "tags": [], "creator": "p.mouawad@ubik-ingenierie.com", "attachment_id": null, "id": 151463, "creation_time": "2011-11-14T12:12:14Z", "time": "2011-11-14T12:12:14Z", "bug_id": 41921, "text": "Still missing in 2.5.1", "is_private": false}, {"count": 6, "tags": [], "bug_id": 41921, "attachment_id": null, "is_private": false, "id": 160239, "time": "2012-06-25T15:43:25Z", "creator": "evanamc@gmail.com", "creation_time": "2012-06-25T15:43:25Z", "text": "Gregg: Increasing the JVM memory does not help.  The order of magnitude is gigabytes of data for me, but it doesn't really matter, because the application just ramps up memory until it runs out.  I should be able to run a test for an arbitrarily long amount of time if I don't need to store the result data.\n\nFor my use case, I want to test the maximum throughput of a large select statement from my webserver to my database, but the application caps out its memory before I can get any useful data.  If I don't have any listeners that need the response data, it should not be cached.\n\nI am having this issue running 2.7 r1342410 on Windows Server 2008."}]