[{"count": 0, "tags": [], "bug_id": 19799, "attachment_id": null, "is_private": false, "id": 36983, "time": "2003-05-09T15:26:36Z", "creator": "akelley@ecsplus.com", "creation_time": "2003-05-09T15:26:36Z", "text": "I was experiencing this problem in Tomcat 4.1.18 and found bug number 18229\n(http://nagoya.apache.org/bugzilla/show_bug.cgi?id=18229).  The bug recommended\nupgrading to Tomcat 4.1.24 to fix the problem.  I upgraded the code, but I still\nseem to have the error after a day or two of running.  The site is moderately\nused.  The error message can be found below.  Any help would be appreciated.\n\nMay 7, 2003 1:52:37 PM org.apache.tomcat.util.threads.ThreadPool logFull\nSEVERE: All threads are busy, waiting. Please increase maxThreads or check the\nservlet status75 75"}, {"count": 1, "tags": [], "bug_id": 19799, "attachment_id": null, "is_private": false, "id": 36989, "time": "2003-05-09T15:58:54Z", "creator": "remm@apache.org", "creation_time": "2003-05-09T15:58:54Z", "text": "Since this is the first such report with 4.1.24, I recommend you double check\nyour stuff and investigate. I'll close the report with works for me in a few\ndays if you can't find anything conclusive (and fail to provide some\ninformation, there's zero to work on here)."}, {"count": 2, "tags": [], "creator": "akelley@ecsplus.com", "is_private": false, "text": "I can attach a catalina.out file if that would help (showing the errors).  I can\nalso do a full re-install of Tomcat (before I upgraded by just changing the\ncontents of the Tomcat folder on the server, but the catalina.out list the\ncorrect version as 4.1.24).  Not sure what else I can give you... Any ideas?", "id": 36991, "time": "2003-05-09T16:03:05Z", "bug_id": 19799, "creation_time": "2003-05-09T16:03:05Z", "attachment_id": null}, {"count": 3, "tags": [], "text": "Try to be imaginative. You know, far fetched stuff like config information (ok,\ngreat, so we know that you're alledgedly using 4.1.24). The most useful could be\nsome thread stack dumps, so I could see deadlocked threads (if any).\nSince nobody else reported the issue, and it may be hard to reproduce, you could\nhave to investigate and debug it yourself.", "attachment_id": null, "id": 36998, "creator": "remm@apache.org", "time": "2003-05-09T17:03:06Z", "bug_id": 19799, "creation_time": "2003-05-09T17:03:06Z", "is_private": false}, {"count": 4, "tags": [], "creator": "akelley@ecsplus.com", "attachment_id": null, "id": 37005, "time": "2003-05-09T20:37:39Z", "bug_id": 19799, "creation_time": "2003-05-09T20:37:39Z", "is_private": false, "text": "I will spend some time thinking about it and see where I can get.  Just so you\nknow, this problem has appeared at two different client sites with the same\napplication (both running Linux).  The problem appeared after changing the\ndatabase pool we are using (may or may not be related).  I have experienced this\nproblem with the following versions of Tomcat:\n\n4.1.12\n4.1.18\n4.1.24\n\nMore info to come hopefully."}, {"count": 5, "tags": [], "bug_id": 19799, "attachment_id": null, "is_private": false, "id": 37450, "time": "2003-05-19T19:34:20Z", "creator": "akelley@ecsplus.com", "creation_time": "2003-05-19T19:34:20Z", "text": "One more thought I had, the problem seemed to occur when I change my database\npool.  I changed it to use RP Database Pool\n(http://www.richardsonpublications.com/dbpool/index.jsp).  I still think it may\nbe a Tomcat issue, but thought I would point that out."}, {"count": 6, "tags": [], "text": "I am resolving this bug as INVALID since I think it is a connection pool issue.\n From my research:\n\nA more likely scenario would be that the connections obtained from the pool are\nnot being returned to the pool properly.  It may take the site some time to show\nthis problem depending on the number of max connections you allow the pool to\nopen.  \n\nIf the connections are not being returned properly, subsequent calls to the\ngetConnection method of the pool will wait for a connection to be returned.  If\nno connections ever get returned, the method call to getConnection will either\nwait until the app server is brought down, or timeout, which could be causing\nthe problem you describe in your message.  Since I don't believe Tomcat has a\ntimeout, and since I believe the default max thread for Tomcat is 75, the server\nwould stop accepting requests at the point when the 75th call was made to\ngetConnection after all of the available connections were taken.\n\nSo after finding one connection that may not have been returned properly, it\nseems to work now.  The problem was that the old connection pool was specific\nwhen connections were not being closed.  This one did not give any real errors.", "attachment_id": null, "bug_id": 19799, "id": 37686, "time": "2003-05-23T18:42:46Z", "creator": "akelley@ecsplus.com", "creation_time": "2003-05-23T18:42:46Z", "is_private": false}, {"count": 7, "tags": [], "text": "We are experiencing this problem in the Tomcat 4.1.24 release. We set \nmaxProcessors to 150 threads and still this happens after running the server \nfor some time. Not sure why it uses up all threads and requests more.\n\n", "attachment_id": null, "id": 40296, "creator": "srau@netflix.com", "time": "2003-07-09T20:52:38Z", "bug_id": 19799, "creation_time": "2003-07-09T20:52:38Z", "is_private": false}, {"count": 8, "tags": [], "bug_id": 19799, "attachment_id": null, "is_private": false, "id": 40297, "time": "2003-07-09T20:55:22Z", "creator": "srau@netflix.com", "creation_time": "2003-07-09T20:55:22Z", "text": "We are experiencing this problem in the Tomcat 4.1.24 release. We set \nmaxProcessors to 150 threads and still this happens after running the server \nfor some time. Not sure why it uses up all threads and requests more.\n\nI will try to get some thread dumps and post it. "}, {"count": 9, "tags": [], "bug_id": 19799, "attachment_id": null, "is_private": false, "id": 40299, "time": "2003-07-09T21:03:49Z", "creator": "remm@apache.org", "creation_time": "2003-07-09T21:03:49Z", "text": "You can get a thread dump by doing a kill -3 on the Java process on Unix, or\nusing CTRL+BREAK on Windows. That should help see what the threads are doing,\nand see where the problem is coming from."}, {"count": 10, "tags": [], "creator": "andy@xadra.com", "attachment_id": null, "id": 41279, "time": "2003-07-24T11:50:30Z", "bug_id": 19799, "creation_time": "2003-07-24T11:50:30Z", "is_private": false, "text": "We are seeing this same issue as well with 4.1.24 and 5.0.4alpha. We have a \nload test program that sends a high volume of concurrent requests to Tomcat \nand it consistenly refuses connections at around the 75th connection attempt. \nAfter a bit, it begins accepting connections again.\n\nWe have verified that both minProcessors and maxProcessors really seem to have \nno effect. If you set minProcessors to say 50 or 100 and then perform a thread \ndump, you will see that there are not 50 pre-allocated threads. If you set \nmaxProcessors to say 1000, you will still see failures around the 75 \nconnection. It's also unclear why the acceptCount is limited to 128 pending \nconnections.\n\nWe have generated thread dumps and there are no deadlocks. All available \nthreads are currently processing valid requests. The pool is simply out of \nthreads and."}, {"count": 11, "tags": [], "creator": "remm@apache.org", "is_private": false, "text": "Your test program is sending HTTP/1.1 requests, and not closing the connection,\nso your load tester program is bad. So until the connection timeout occurs, the\nprocessors will wait for subsequent requests. You can either:\n- increase the processor count to a higher value\n- decrease the connection timeout\n- set the maxKeepAliveRequests attribute to \"1\" on the connector, which will\ndisable connection keepalive (that hurts performance a lot)", "id": 41281, "time": "2003-07-24T12:01:42Z", "bug_id": 19799, "creation_time": "2003-07-24T12:01:42Z", "attachment_id": null}, {"count": 12, "tags": [], "creator": "tagunov@motor.ru", "attachment_id": null, "id": 41591, "time": "2003-07-27T17:02:37Z", "bug_id": 19799, "creation_time": "2003-07-27T17:02:37Z", "is_private": false, "text": "Okya, but why is the 75 limit being imposed regardless of the setting of\nmaxProcessors ?"}, {"count": 13, "tags": [], "text": "The load program mentioned earlier by someone else is quite valid when you think\nin a SOAP context.\n\nSame problem here with tc-4.1.24 and tc-4.1.27 (i did not try 5.0.x), jdk-1.4.2,\nRH8.0, using SOAP-like messages over persistent HTTP1.1 connections, no matter\nwhich client http library I use (commons-httpclient, innovation httpclient).\n\nThe SOAP-like client and server exchange MANY (perhaps tens of thousands) serial\nmessages over the same persistent connection (there is only one client in this\ntest, so scalability should be straightforward),and around 74 or 75 messages TC\nhangs, with luck it will recover after some tens of secs, to allow one more\nmessage, then hang for some more tens of secs to allow for some 20 more\nmessages, then hang forever (with close to 100% CPU).\n\n> - increase the processor count to a higher value\n\nis not an option with ten thousand serial messages\n\n> - decrease the connection timeout\n\nmakes no noticable difference\n- set the maxKeepAliveRequests attribute to \"1\" on the connector, which will\n\n> disable connection keepalive (that hurts performance a lot)\n\nMakes no difference either!?\n\nAs an aside, I noticed that the AXIS folks disabled persistent connections in\ntheir client API, perhaps for some related reason...", "attachment_id": null, "id": 42650, "creator": "whoschek@lbl.gov", "time": "2003-08-13T01:33:48Z", "bug_id": 19799, "creation_time": "2003-08-13T01:33:48Z", "is_private": false}, {"count": 14, "attachment_id": null, "bug_id": 19799, "is_private": false, "id": 42662, "time": "2003-08-13T07:18:52Z", "creator": "remm@apache.org", "creation_time": "2003-08-13T07:18:52Z", "tags": [], "text": "Please submit a test case. If what you say is true, and is caused by Tomcat,\nthen it should be reproduceable."}, {"count": 15, "tags": [], "bug_id": 19799, "attachment_id": null, "id": 42665, "time": "2003-08-13T08:02:28Z", "creator": "remm@apache.org", "creation_time": "2003-08-13T08:02:28Z", "is_private": false, "text": "BTW (for the one hundredth time), if Tomcat locks up and uses 100% of the CPU,\nyou can prove your point (and likely isolate the problem) by getting a thread\ndump for the VM (CTRL + BREAK on Windows, kill -3 on Unix) - which thread is\nactually using the CPU should be quite easy to isolate.\nFor now, I have to consider this invalid (no test case, and can't reproduce)."}, {"count": 16, "tags": [], "bug_id": 19799, "is_private": false, "id": 42790, "creation_time": "2003-08-15T08:00:59Z", "time": "2003-08-15T08:00:59Z", "creator": "mvdijken@madocke.nl", "text": "Created attachment 7830\ncatalina.out with full thread dump. Snipped to remove earlier startups and System.out.printlns", "attachment_id": 7830}, {"count": 17, "tags": [], "bug_id": 19799, "attachment_id": null, "id": 42791, "time": "2003-08-15T08:01:53Z", "creator": "mvdijken@madocke.nl", "creation_time": "2003-08-15T08:01:53Z", "is_private": false, "text": "Bingo, the problem seems to be in a deadlock on JspServletWrappers somehow. I've\nattached the log of the kill -3. This was dumped inside catalina.out, and it\nmight be interesting to notice that there had been quite a few warnings about\nRESETs.\n\nLeave it up to Remy to decide to reopen or not..."}, {"count": 18, "tags": [], "creator": "tfohrer@t-online.de", "is_private": false, "text": "Created attachment 7832\nThread dump  - reduced to 3 threads (jsp compiler,unix process,waiting jsp wrapper)", "id": 42798, "time": "2003-08-15T11:01:36Z", "bug_id": 19799, "creation_time": "2003-08-15T11:01:36Z", "attachment_id": 7832}, {"count": 19, "tags": [], "bug_id": 19799, "attachment_id": null, "is_private": false, "id": 42822, "time": "2003-08-15T20:07:59Z", "creator": "remm@apache.org", "creation_time": "2003-08-15T20:07:59Z", "text": "That's a sync point which occurs when Jasper is in dev mode (on each access,\nJasper checks for recompilation). Please read the Jasper docs (set the\n\"development\" init param to \"false\" in $CATALINA_HOME/conf/web.xml).\nI'll examine the stacktrace for a deadlock, but this particular configuration\nshould never be put in production (it has terrible performance).\n\nThread dumps like this are very useful info to debug contention, deadlocks,\ninfinite loops, etc.\n"}]