[{"count": 0, "tags": [], "text": "When serving big files (> 150Mo) with PHP or cgi shell scripts, the child \nprocess memory size grows proportionnaly to the amount of data sent.\n\nConfig :\nLinux RedHat 9.0, P200 with 256M\nApache is configured to use prefork MPM.", "is_private": false, "id": 45011, "creator": "jf.cuinet@bgpartners.fr", "time": "2003-10-02T13:35:28Z", "bug_id": 23567, "creation_time": "2003-10-02T13:35:28Z", "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 23567, "attachment_id": null, "id": 45340, "time": "2003-10-10T12:18:45Z", "creator": "trawick@apache.org", "creation_time": "2003-10-10T12:18:45Z", "is_private": false, "text": "It sounds like there is a filter that is holding on to data when it shouldn't.\n\nCould you please provide a scenario to reproduce the problem?  This would\ninclude\n+ simple CGI that does whatever is required\n+ set of changes to make to default Apache config to see the problem\n+ what request should be sent to this simple CGI\n\nThanks!"}, {"count": 2, "tags": [], "bug_id": 23567, "attachment_id": null, "is_private": false, "id": 45367, "time": "2003-10-10T14:09:03Z", "creator": "nd@perlig.de", "creation_time": "2003-10-10T14:09:03Z", "text": "Maybe deflate? There was something fixed recently."}, {"count": 3, "tags": [], "bug_id": 23567, "attachment_id": null, "id": 45374, "time": "2003-10-10T14:54:53Z", "creator": "trawick@apache.org", "creation_time": "2003-10-10T14:54:53Z", "is_private": false, "text": "Ah, yes!  Jean-Fran\u00e7ois, please see my recent update to PR 23065\n(http://nagoya.apache.org/bugzilla/show_bug.cgi?id=23065) pointing to a fix for\na bug that could result in symptoms like you describe.\n\nThis assumes, of course, that you have the DEFLATE filter active.\n\nIf this does not turn out to be the cause, information requested early on how to\nreproduce the problem would be much appreciated.\n"}, {"count": 4, "tags": [], "text": "I think that DEFLATE filter is not active (SetOutputFilter is not present in \nfile httpd.conf)\n\nProblem also noted with Apache 2.047 on AIX5L or Linux RedHat 9.0\n\nExample of cgi shell script for reproduce the problem :\n\n#!/bin/sh                                                \n                                                         \necho Content-type: text/plain                            \necho                                                     \n                                                         \ni=150000                                                 \nuntil test $i -eq 0                                      \ndo                                                       \n  # 50 * 20 lines                                        \n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  echo 01234567890123456789012345678901234567890123456789\n  i=`expr $i - 1`                                        \ndone                                                     \n", "is_private": false, "bug_id": 23567, "id": 45383, "time": "2003-10-10T17:21:08Z", "creator": "jf.cuinet@bgpartners.fr", "creation_time": "2003-10-10T17:21:08Z", "attachment_id": null}, {"count": 5, "tags": [], "bug_id": 23567, "is_private": false, "text": "I spent some time last week-end investigating this.  Hopefully this info can\nhelp whoever has time to look for a solution.\n\nThe only memory leak I was able to find is caused by an endless number of\ncleanups registered against the request pool by content-length filter and then\nkilled by the core output filter.  A cleanup is registered during\napr_brigade_split(), as the content-length filter separates out the data already\nread from the CGI in order to send it to the client.  When the content-length\nfilter is able to read a bit more from the CGI, the same thing happens again.\n\nThis same pattern could occur with most any other filter.  Other filter code\nthat could do the pipe bucket read is going to have to do the same thing --\nbrigade-split and pass-brigade -- before waiting for more output from the CGI.\n", "id": 45915, "time": "2003-10-20T10:58:41Z", "creator": "trawick@apache.org", "creation_time": "2003-10-20T10:58:41Z", "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 23567, "is_private": false, "count": 6, "id": 59351, "time": "2004-06-16T19:22:25Z", "creator": "wrowe@apache.org", "creation_time": "2004-06-16T19:22:25Z", "text": "\n  Just a footnote - I'd heard similar responses on another application, a web\n  server attempting to feed unlimited streams of data (e.g. audio/video) through\n  an HTTP proxy.  One would expect it to reach steady-state, but throughout\n  a long connection to mod_proxy the memory footprint continued to grow.\n"}, {"count": 7, "tags": [], "creator": "mh@nadir.org", "is_private": false, "id": 59432, "attachment_id": null, "bug_id": 23567, "creation_time": "2004-06-17T17:18:39Z", "time": "2004-06-17T17:18:39Z", "text": "an additional comment on this bug that might be helpful: bug 29528 is similar, but\nI wasn't getting the increased mem. usage proportional to the amount of data sent. \n29528 had to do with the \"Range\" header. If download with a client that does not\nuse the range header, no memory leak occured. This bug happens without any range\nheader. The one difference between the 2 is that this cgi sends text/plain data\nwhile mine sent audio (audio/mpeg, mp3) data. Obviously something is being\nhandled differently for the various content types."}, {"count": 8, "tags": [], "text": "I'm not sure whether bug 29962 and this bug are actually different or not.  I\nhad a php script that pulled a huge amount of data into memory (800 megabytes),\nbut Apache 2.0 didn't release the memory afterwards.  None of the data was sent\nto the end user.  It was just loaded into memory.  It looks to me like there's a\nmajor problem with Apache 2.0 releasing memory once it's claimed it.\n\nThis was eventually causing our server to thrash itself to death.  As more and\nmore processes grew to consome all available memory.", "is_private": false, "bug_id": 23567, "id": 64643, "time": "2004-10-05T19:43:34Z", "creator": "tyler@nas.net", "creation_time": "2004-10-05T19:43:34Z", "attachment_id": null}, {"count": 9, "tags": [], "creator": "nd@perlig.de", "attachment_id": null, "is_private": false, "id": 64644, "time": "2004-10-05T20:02:28Z", "bug_id": 23567, "creation_time": "2004-10-05T20:02:28Z", "text": "Good question: Did apache not release it or mod_php?"}, {"count": 10, "tags": [], "text": "Just brain-dumping, the design issue here is, per Jeff's analysis and subsequent\ndiscussion:\n\n1. brigades are allocated out of pools\n2. every call to apr_brigade_split allocates a new brigade\n3. every time a FLUSH bucket it sent down the filter stack, it causes at least\none call to apr_brigade_split\n\nfixes for this could be either:\n\nfix (1), allocate brigades out of the bucket-allocator so that they can really\nbe free'd (very intrusive since many filters presume brigades are never really\ndestroyed)\n\nfix (3), adjust all filters to ensure that they don't allocate a number of\nbrigades per request (and hence, memory allocated) which is proportional to\nnumber of FLUSH buckets sent.\n", "is_private": false, "id": 69585, "creator": "jorton@redhat.com", "time": "2005-01-12T11:33:40Z", "bug_id": 23567, "creation_time": "2005-01-12T11:33:40Z", "attachment_id": null}, {"count": 11, "tags": [], "bug_id": 23567, "attachment_id": null, "id": 79555, "time": "2005-09-07T17:31:44Z", "creator": "jorton@redhat.com", "creation_time": "2005-09-07T17:31:44Z", "is_private": false, "text": "*** Bug 34589 has been marked as a duplicate of this bug. ***"}, {"count": 12, "tags": [], "bug_id": 23567, "attachment_id": null, "is_private": false, "id": 107322, "time": "2007-08-28T02:11:49Z", "creator": "wrowe@apache.org", "creation_time": "2007-08-28T02:11:49Z", "text": "*** Bug 43223 has been marked as a duplicate of this bug. ***"}, {"attachment_id": null, "tags": [], "bug_id": 23567, "is_private": false, "count": 13, "id": 107358, "time": "2007-08-28T12:51:05Z", "creator": "rpluem@apache.org", "creation_time": "2007-08-28T12:51:05Z", "text": "(In reply to comment #10)\n> Just brain-dumping, the design issue here is, per Jeff's analysis and subsequent\n> discussion:\n> \n> 1. brigades are allocated out of pools\n> 2. every call to apr_brigade_split allocates a new brigade\n> 3. every time a FLUSH bucket it sent down the filter stack, it causes at least\n> one call to apr_brigade_split\n> \n> fixes for this could be either:\n> \n> fix (1), allocate brigades out of the bucket-allocator so that they can really\n> be free'd (very intrusive since many filters presume brigades are never really\n> destroyed)\n> \n> fix (3), adjust all filters to ensure that they don't allocate a number of\n> brigades per request (and hence, memory allocated) which is proportional to\n> number of FLUSH buckets sent.\n\nWhat about an apr_brigade_split_ex that takes an additional brigade as\nparameter? This brigade could be used instead of creating a new one and could\nbe stored in the context of the filter for subsequent recyling (like we do in\nother places). So something like:\n\nAPU_DECLARE(apr_bucket_brigade *) apr_brigade_split_ex(apr_bucket_brigade *b,\n                                                       apr_bucket *e\n                                                       apr_bucket_brigade *a)\n{\n    apr_bucket *f;\n\n    if (!a) {\n        a = apr_brigade_create(b->p, b->bucket_alloc);\n    }\n    else if (!APR_BRIGADE_EMPTY(a)) {\n        apr_brigade_cleanup(a);\n    }\n    /* Return an empty brigade if there is nothing left in\u00b7\n     * the first brigade to split off\u00b7\n     */\n    if (e != APR_BRIGADE_SENTINEL(b)) {\n        f = APR_RING_LAST(&b->list);\n        APR_RING_UNSPLICE(e, f, link);\n        APR_RING_SPLICE_HEAD(&a->list, e, f, apr_bucket, link);\n    }\n\n    APR_BRIGADE_CHECK_CONSISTENCY(a);\n    APR_BRIGADE_CHECK_CONSISTENCY(b);\n\n    return a;\n}\n\nAPU_DECLARE(apr_bucket_brigade *) apr_brigade_split(apr_bucket_brigade *b,\n                                                       apr_bucket *e)          \n                                    \n{\n   return apr_brigade_split_ex(b, e, NULL);\n}"}, {"attachment_id": null, "tags": [], "bug_id": 23567, "is_private": false, "count": 14, "id": 131692, "time": "2009-11-04T09:12:55Z", "creator": "rpluem@apache.org", "creation_time": "2009-11-04T09:12:55Z", "text": "Is this still an issue in trunk with r814807, r821471, r821477 committed?"}, {"attachment_id": null, "tags": [], "bug_id": 23567, "is_private": false, "count": 15, "id": 136922, "time": "2010-05-17T17:24:51Z", "creator": "sf@sfritsch.de", "creation_time": "2010-05-17T17:24:51Z", "text": "(In reply to comment #14)\n> Is this still an issue in trunk with r814807, r821471, r821477 committed?\n\nNo, this is now fixed.\n\nSome other relevant commits are:\nr924452 r910326 r821481 r821486"}, {"count": 16, "tags": [], "creator": "sf@sfritsch.de", "attachment_id": null, "is_private": false, "id": 154168, "time": "2012-02-26T16:29:12Z", "bug_id": 23567, "creation_time": "2012-02-26T16:29:12Z", "text": "fixed in 2.4.1"}]