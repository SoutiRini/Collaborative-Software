[{"count": 0, "tags": [], "creator": "Colek01@hotmail.com", "text": "I would like to ask that a new internet standard be given.  Not only to save \nbandwidth and load times but to make the open source community really show \nit's mastery and abilities.\n\nI am proposing that apache begins running an HTML compression technique where \nas html tags and string data is compressed / compiled and then the \nmozilla /any browser will decompress/parse the data as if it was real html \ntext.\n\nReason:\nToday we send over a terrabyte of html websites/html code over the internet, \nif the pages were compressed by reducing and removing some of the quite un-\nnessessary tags such as the <HTML> tag or using a 2 byte notation for the \n<BODY> tag the internet could substantially use around 1gb of bandwidth \ninstead of 1 terrabyte of bandwidth.\n\nCompanies would be very interested in saving money and/or using the bandwidth \nthey have on other things like downloads or other such things.\n\nOpen source software may be free to use for hosting but the bandwidth is \nalways going to cost the end user alot more.\n\nDon't believe me that this will be a good idea?\njust look at what netzero is doing with their html/web compression they \nmanaged to fake out a 56k line to be able to load amazon.com in 4.3 seconds \nrather than 13 or so.\n\nI believe this is a fundamental idea and in order to actually get it started \nyou need to get a bunch of people devoted to working on software that is used \nby many companies.", "id": 49414, "time": "2003-12-19T06:09:08Z", "bug_id": 25640, "creation_time": "2003-12-19T06:09:08Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 25640, "attachment_id": null, "id": 49432, "time": "2003-12-19T14:12:25Z", "creator": "slive@apache.org", "creation_time": "2003-12-19T14:12:25Z", "is_private": false, "text": "See mod_deflate, which solves most of this problem in a much more general way."}]