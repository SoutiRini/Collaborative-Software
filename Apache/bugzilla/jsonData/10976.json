[{"count": 0, "tags": [], "creator": "patrickl@ihm.gov.mo", "text": "Hi all\n\nI have refined the Unicode support for sheetname patch.  Including in this patch\nare refactoring of  SSTDeserializer & UnicodeString class to bring more code\nrelating to BIFF8 format from the former class to the latter class where it\nshould belong to. Please review it and consider for inclusion into the project\n\nThanks\nPatrick Lee\n\n\n\n\nIndex: jakarta-poi/src/java/org/apache/poi/hssf/record/BoundSheetRecord.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/java/org/apache/poi/hssf/record/BoundSheetRecord.java,v\nretrieving revision 1.4\ndiff -u -r1.4 BoundSheetRecord.java\n--- jakarta-poi/src/java/org/apache/poi/hssf/record/BoundSheetRecord.java\t1 Mar 2002 13:27:10 -0000\t1.4\n+++ jakarta-poi/src/java/org/apache/poi/hssf/record/BoundSheetRecord.java\t19 Jul 2002 07:00:22 -0000\n@@ -54,7 +54,7 @@\n  */\n \n package org.apache.poi.hssf.record;\n-\n+import org.apache.poi.util.BinaryTree;\n import org.apache.poi.util.LittleEndian;\n import org.apache.poi.util.StringUtil;\n \n@@ -117,6 +117,16 @@\n         }\n     }\n \n+    /**\n+     *  lifted from SSTDeserializer\n+     */\n+\n+    private void arraycopy( byte[] src, int src_position,\n+                            byte[] dst, int dst_position,\n+                            int length )\n+    {\n+        System.arraycopy( src, src_position, dst, dst_position, length );\n+    }\n     protected void fillFields(byte [] data, short size, int offset)\n     {\n         field_1_position_of_BOF         = LittleEndian.getInt(data,\n@@ -125,8 +135,24 @@\n                 4 + offset);\n         field_3_sheetname_length        = data[ 6 + offset ];\n         field_4_compressed_unicode_flag = data[ 7 + offset ];\n-        field_5_sheetname               = new String(data, 8 + offset,\n-                LittleEndian.ubyteToInt( field_3_sheetname_length));\n+\n+        int length = LittleEndian.ubyteToInt( field_3_sheetname_length);\n+        if ((field_4_compressed_unicode_flag & 0x01)==1) {\n+            UnicodeString ucs =new\nUnicodeString(data,(short)length,6+offset,(short)1);\n+            field_5_sheetname = ucs.getString();\n+        }\n+        else {\n+          try {\n+            // should get the codepage from the excel workbook record\n+            // instead of hard coded \"ISO-8859-1\" here.\n+            field_5_sheetname =   new String(data, 8 + offset,\n+            LittleEndian.ubyteToInt( field_3_sheetname_length),\"ISO-8859-1\");\n+          }\n+          catch (Exception e){\n+            e.printStackTrace();\n+          }\n+        }\n+        System.out.println(\"f_5_sn is \"+field_5_sheetname);\n     }\n \n     /**\n@@ -175,13 +201,63 @@\n     }\n \n     /**\n+     * Check if String use 16-bit encoding character\n+     * Lifted from SSTRecord.addString\n+     */\n+    public boolean is16bitString(String string)\n+    {\n+            // scan for characters greater than 255 ... if any are\n+            // present, we have to use 16-bit encoding. Otherwise, we\n+            // can use 8-bit encoding\n+            boolean useUTF16 = false;\n+            int strlen = string.length();\n+\n+            for ( int j = 0; j < strlen; j++ )\n+            {\n+                if ( string.charAt( j ) > 255 )\n+                {\n+                    useUTF16 = true;\n+                    break;\n+                }\n+            }\n+            return useUTF16 ;\n+   }\n+    /**\n+     * Check if String use all 8-bit (outside ASCII 7 bit range) to\n+     * encoding character\n+     * Lifted from SSTRecord.addString\n+     */\n+    public boolean is8bitString(String string)\n+    {\n+            // scan for characters greater than 255\n+            //  ... if any are present then return false\n+            boolean use8bit = true;\n+            int strlen = string.length();\n+\n+            for ( int j = 0; j < strlen; j++ )\n+            {\n+                if ( string.charAt( j ) > 255 )\n+                {\n+                    use8bit = false;\n+                    break;\n+                }\n+            }\n+            return use8bit ;\n+   }\n+\n+    /**\n      * Set the sheetname for this sheet.  (this appears in the tabs at the bottom)\n      * @param sheetname the name of the sheet\n      */\n \n     public void setSheetname(String sheetname)\n     {\n+        boolean is16bit = is16bitString(sheetname);\n+        setSheetnameLength((byte) sheetname.length() );\n+        setCompressedUnicodeFlag((byte ) (is16bit?1:0));\n         field_5_sheetname = sheetname;\n+\n+\n     }\n \n     /**\n@@ -263,20 +339,34 @@\n     {\n         LittleEndian.putShort(data, 0 + offset, sid);\n         LittleEndian.putShort(data, 2 + offset,\n-                              ( short ) (0x08 + getSheetnameLength()));\n+                              ( short ) (0x08 + getSheetnameLength()*\n(getCompressedUnicodeFlag()==0?1:2)));\n         LittleEndian.putInt(data, 4 + offset, getPositionOfBof());\n         LittleEndian.putShort(data, 8 + offset, getOptionFlags());\n         data[ 10 + offset ] = getSheetnameLength();\n         data[ 11 + offset ] = getCompressedUnicodeFlag();\n \n-        // we assume compressed unicode (bein the dern americans we are ;-p)\n-        StringUtil.putCompressedUnicode(getSheetname(), data, 12 + offset);\n+        if (getCompressedUnicodeFlag()==0){\n+          // we assume compressed unicode (bein the dern americans we are ;-p)\n+          StringUtil.putCompressedUnicode(getSheetname(), data, 12 + offset);\n+        }\n+        else {\n+          try {\n+            StringUtil.putUncompressedUnicode(getSheetname(), data, 12 + offset);\n+  //          String unicodeString = new\nString(getSheetname().getBytes(\"Unicode\"),\"Unicode\");\n+  //          StringUtil.putUncompressedUnicode(unicodeString, data, 12 + offset);\n+          }\n+          catch (Exception e){\n+            System.out.println(\"encoding exception in\nBoundSheetRecord.serialize!\");\n+          }\n+\n+\n+        }\n         return getRecordSize();\n     }\n \n     public int getRecordSize()\n     {\n-        return 12 + getSheetnameLength();\n+        return 12 + getSheetnameLength()* (getCompressedUnicodeFlag()==0?1:2);\n     }\n \n     public short getSid()\nIndex: jakarta-poi/src/java/org/apache/poi/hssf/record/SSTDeserializer.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/java/org/apache/poi/hssf/record/SSTDeserializer.java,v\nretrieving revision 1.4\ndiff -u -r1.4 SSTDeserializer.java\n--- jakarta-poi/src/java/org/apache/poi/hssf/record/SSTDeserializer.java\t12 Jun 2002 09:10:04 -0000\t1.4\n+++ jakarta-poi/src/java/org/apache/poi/hssf/record/SSTDeserializer.java\t19 Jul 2002 07:00:25 -0000\n@@ -204,24 +204,13 @@\n     private int processString( final byte[] data, final int dataIndex, final\nint characters )\n     {\n \n-        // length is the length we store it as.  not the length that is read.\n-        int length = SSTRecord.STRING_MINIMAL_OVERHEAD + calculateByteCount(\ncharacters );\n-        byte[] unicodeStringBuffer = new byte[length];\n-\n-        int offset = 0;\n-\n-        // Set the length in characters\n-        LittleEndian.putUShort( unicodeStringBuffer, offset, characters );\n-        offset += LittleEndianConsts.SHORT_SIZE;\n-        // Set the option flags\n-        unicodeStringBuffer[offset] = data[dataIndex + offset];\n-        // Copy in the string data\n-        int bytesRead = unicodeStringBuffer.length -\nSSTRecord.STRING_MINIMAL_OVERHEAD;\n-        arraycopy( data, dataIndex + stringHeaderOverhead(),\nunicodeStringBuffer, SSTRecord.STRING_MINIMAL_OVERHEAD, bytesRead );\n-        // Create the unicode string\n-        UnicodeString string = new UnicodeString( UnicodeString.sid,\n-                (short) unicodeStringBuffer.length,\n-                unicodeStringBuffer );\n+        // use the new UnicodeString constructor\n+\n+        int bytesRead =calculateByteCount( characters );\n+        UnicodeString string = new UnicodeString( data,\n+          (short)(bytesRead +stringHeaderOverhead()),\n+           dataIndex, stringHeaderOverhead()-SSTRecord.STRING_MINIMAL_OVERHEAD\n+           ,(short)UnicodeString.CHARCOUNTSIZE_DOUBLEBYTE );\n \n         if ( isStringFinished() )\n         {\n@@ -339,7 +328,9 @@\n         LittleEndian.putShort( unicodeStringData, 0, (short)\ngetContinuationExpectedChars() );\n \n         // write the options flag\n-        unicodeStringData[LittleEndianConsts.SHORT_SIZE] = createOptionByte(\nwideChar, richText, extendedText );\n+//        Can't deal with richtext or Far-East Info.\n+//        unicodeStringData[LittleEndianConsts.SHORT_SIZE] = createOptionByte(\nwideChar, richText, extendedText );\n+        unicodeStringData[LittleEndianConsts.SHORT_SIZE] = createOptionByte(\nwideChar, false,false );\n \n         // copy the bytes/words making up the string; skipping\n         // past all the overhead of the str_data array\n@@ -348,9 +339,14 @@\n                 unicodeStringData.length - SSTRecord.STRING_MINIMAL_OVERHEAD );\n \n         // use special constructor to create the final string\n-        UnicodeString string = new UnicodeString( UnicodeString.sid,\n-                (short) unicodeStringData.length, unicodeStringData,\n-                unfinishedString );\n+//        UnicodeString string = new UnicodeString( UnicodeString.sid,\n+//                (short) unicodeStringData.length, unicodeStringData,\n+//                unfinishedString );\n+        UnicodeString string = new UnicodeString( unicodeStringData,\n+                (short) unicodeStringData.length,\n+                unfinishedString , UnicodeString.CHARCOUNTSIZE_DOUBLEBYTE );\n+\n+\n         Integer integer = new Integer( strings.size() );\n \n         addToStringTable( strings, integer, string );\n@@ -411,8 +407,9 @@\n \n         LittleEndian.putShort( unicodeStringData, (byte) 0, (short)\ncalculateCharCount( dataLengthInBytes ) );\n         arraycopy( record, 0, unicodeStringData, LittleEndianConsts.SHORT_SIZE,\nrecord.length );\n-        UnicodeString ucs = new UnicodeString( UnicodeString.sid, (short)\nunicodeStringData.length, unicodeStringData );\n-\n+        //UnicodeString ucs = new UnicodeString( UnicodeString.sid, (short)\nunicodeStringData.length, unicodeStringData );\n+        UnicodeString ucs = new UnicodeString( unicodeStringData,\n+            (short)\nunicodeStringData.length,UnicodeString.CHARCOUNTSIZE_DOUBLEBYTE );\n         unfinishedString = unfinishedString + ucs.getString();\n         setContinuationExpectedChars( getContinuationExpectedChars() -\ncalculateCharCount( dataLengthInBytes ) );\n     }\nIndex: jakarta-poi/src/java/org/apache/poi/hssf/record/SeriesTextRecord.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/java/org/apache/poi/hssf/record/SeriesTextRecord.java,v\nretrieving revision 1.2\ndiff -u -r1.2 SeriesTextRecord.java\n--- jakarta-poi/src/java/org/apache/poi/hssf/record/SeriesTextRecord.java\t19 May 2002 15:55:12 -0000\t1.2\n+++ jakarta-poi/src/java/org/apache/poi/hssf/record/SeriesTextRecord.java\t19 Jul 2002 07:00:25 -0000\n@@ -169,7 +169,7 @@\n         LittleEndian.putShort(data, 4 + offset, field_1_id);\n         data[ 6 + offset ] = field_2_textLength;\n         data[ 7 + offset ] = field_3_undocumented;\n-        StringUtil.putUncompressedUnicodeHigh(field_4_text, data, 8 + offset);\n+        StringUtil.putUncompressedUnicode(field_4_text, data, 8 + offset);\n \n         return getRecordSize();\n     }\nIndex: jakarta-poi/src/java/org/apache/poi/hssf/record/UnicodeString.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/java/org/apache/poi/hssf/record/UnicodeString.java,v\nretrieving revision 1.5\ndiff -u -r1.5 UnicodeString.java\n--- jakarta-poi/src/java/org/apache/poi/hssf/record/UnicodeString.java\t26 Jun 2002 12:25:44 -0000\t1.5\n+++ jakarta-poi/src/java/org/apache/poi/hssf/record/UnicodeString.java\t19 Jul 2002 07:00:28 -0000\n@@ -56,6 +56,7 @@\n package org.apache.poi.hssf.record;\n \n import org.apache.poi.util.LittleEndian;\n+import org.apache.poi.util.LittleEndianConsts;\n import org.apache.poi.util.StringUtil;\n \n /**\n@@ -74,10 +75,17 @@\n     extends Record\n     implements Comparable\n {\n+    /**  character count field size in byte */\n+    static final short CHARCOUNTSIZE_SINGLEBYTE = LittleEndianConsts.BYTE_SIZE;\n+    static final short CHARCOUNTSIZE_DOUBLEBYTE = LittleEndianConsts.SHORT_SIZE;\n+\n+\n     public final static short sid = 0xFFF;\n     private short             field_1_charCount;     // = 0;\n     private byte              field_2_optionflags;   // = 0;\n     private String            field_3_string;        // = null;\n+    private byte              field_4_ccAdjust =1;   // charCount size adjustment\n+                                                     // default to 1 i.e.\ncharCount as short\n     private final int RICH_TEXT_BIT = 8;\n     private final int EXT_BIT = 4;\n \n@@ -85,7 +93,6 @@\n     {\n     }\n \n-\n     public int hashCode()\n     {\n         int stringHash = 0;\n@@ -114,6 +121,7 @@\n                 && field_3_string.equals(other.field_3_string));\n     }\n \n+\n     /**\n      * construct a unicode string record and fill its fields, ID is ignored\n      * @param id - ignored\n@@ -127,6 +135,50 @@\n     }\n \n     /**\n+     * construct a unicode string record and fill its fields, ID is ignored\n+     * @param data - the bytes of the string/fields\n+     * @param size - size of the data\n+     * @param ccSize - the size (in byte) of the charCount field\n+     */\n+\n+    public UnicodeString(byte [] data, short size,  short ccSize )\n+    {\n+        super();\n+        field_4_ccAdjust =  (byte)((ccSize == (short) 2)?1:0) ;\n+        fillFields(data, size);\n+    }\n+\n+    /**\n+     * construct a unicode string record and fill its fields, ID is ignored\n+     * @param data - the bytes of the string/fields\n+     * @param size - size of the data\n+     * @param offset - offset of the record\n+     * @param ccSize - the size (in byte) of the charCount field\n+     */\n+\n+    public UnicodeString(byte [] data, short size, int offset , short ccSize )\n+    {\n+        super();\n+        //UnicodeString us = new UnicodeString();\n+        field_4_ccAdjust =  (byte)((ccSize == (short) 2)?1:0) ;\n+        fillFields(data, size,offset);\n+\n+    }\n+    /**\n+     * construct a unicode string from a string fragment + data with an\n+     * additional offset for extended(Far East and Rich Text) info and\n+     * the size (in byte) of the charCount field given as last parameter\n+     */\n+    public UnicodeString(byte [] data, short size, int offset ,int extOffset,\n+                         short ccSize )\n+    {\n+        super();\n+        //UnicodeString us = new UnicodeString();\n+        field_4_ccAdjust =  (byte)((ccSize == (short) 2)?1:0) ;\n+        fillFields(data, size,offset,extOffset);\n+    }\n+\n+    /**\n      * construct a unicode string from a string fragment + data\n      */\n \n@@ -138,36 +190,67 @@\n     }\n \n     /**\n-     * NO OP\n+     * construct a unicode string from a string fragment + data with the size\n+     * (in byte) of the charCount field given as last parameter\n      */\n \n-    protected void validateSid(short id)\n+    public UnicodeString( byte [] data, short size, String prefix,\n+                         short ccSize)\n     {\n+        super();\n+        field_4_ccAdjust =  (byte)((ccSize == (short) 2)?1:0) ;\n+        fillFields(data,  size, 0);\n+        field_3_string = prefix + field_3_string;\n+        setCharCount();\n+    }\n+\n+    /**\n+     * construct a unicode string from a string fragment + data with the size\n+     * (in byte) of the charCount field given as last parameter\n+     */\n+\n+    public UnicodeString( byte [] data, short size, int offset, String prefix,\n+                         short ccSize)\n+    {\n+        super();\n+        field_4_ccAdjust =  (byte)((ccSize == (short) 2)?1:0) ;\n+        fillFields(data,  size, offset);\n+        field_3_string = prefix + field_3_string;\n+        setCharCount();\n \n-        // included only for interface compliance\n     }\n \n-    protected void fillFields(byte [] data, short size)\n+    /**\n+     * construct a unicode string from a string fragment + data with an\n+     * additional offset for extended(Far East and Rich Text) info and the size\n+     * (in byte) of the charCount field given as last parameter\n+     */\n+\n+    public UnicodeString( byte [] data, short size, int offset, int extOffset,\n+                           String prefix, short ccSize)\n+    {\n+/*\n+        super();\n+        field_4_ccAdjust =  (byte)((ccSize == (short) 2)?1:0) ;\n+        fillFields(data,  size, offset);\n+        field_3_string = prefix + field_3_string;\n+        setCharCount();\n+*/\n+\n+    }\n+\n+\n+    /**\n+     * NO OP\n+     */\n+\n+    protected void validateSid(short id)\n     {\n-        field_1_charCount   = LittleEndian.getShort(data, 0);\n-        field_2_optionflags = data[ 2 ];\n-        if ((field_2_optionflags & 1) == 0)\n-        {\n-            field_3_string = new String(data, 3, getCharCount());\n-        }\n-        else\n-        {\n-            char[] array = new char[ getCharCount() ];\n \n-            for (int j = 0; j < array.length; j++)\n-            {\n-                array[ j ] = ( char ) LittleEndian.getShort(data,\n-                                                            3 + (j * 2));\n-            }\n-            field_3_string = new String(array);\n-        }\n+        // included only for interface compliance\n     }\n \n+\n     /**\n      * get the number of characters in the string\n      *\n@@ -286,6 +369,7 @@\n             .append(Integer.toHexString(getOptionFlags())).append(\"\\n\");\n         buffer.append(\"    .string          = \").append(getString())\n             .append(\"\\n\");\n+        buffer.append(\"    .extOffset       =\n\").append(field_4_ccAdjust).append(\"\\n\");\n         buffer.append(\"[/UNICODESTRING]\\n\");\n         return buffer.toString();\n     }\n@@ -300,8 +384,14 @@\n         }\n \n         // byte[] retval = new byte[ 3 + (getString().length() * charsize)];\n-        LittleEndian.putShort(data, 0 + offset, getCharCount());\n-        data[ 2 + offset ] = getOptionFlags();\n+        if ( field_4_ccAdjust == 1) {\n+          LittleEndian.putShort(data, 0 + offset, getCharCount());\n+        }\n+        else {\n+          data[ offset]= (byte)getCharCount();\n+        }\n+\n+        data[ 1+ field_4_ccAdjust+ offset ] = getOptionFlags();\n \n //        System.out.println(\"Unicode: We've got \"+retval[2]+\" for our option\nflag\");\n         try {\n@@ -309,25 +399,25 @@\n String(getString().getBytes(\"Unicode\"),\"Unicode\");\n             if (getOptionFlags() == 0)\n             {\n-                StringUtil.putCompressedUnicode(unicodeString, data, 0x3 +\n-offset);\n+                StringUtil.putCompressedUnicode(unicodeString, data,\n+                  0x2 + field_4_ccAdjust + offset);\n             }\n             else\n             {\n                 StringUtil.putUncompressedUnicode(unicodeString, data,\n-                                                    0x3 + offset);\n+                  0x2 + field_4_ccAdjust + offset);\n             }\n         }\n         catch (Exception e) {\n             if (getOptionFlags() == 0)\n             {\n-                StringUtil.putCompressedUnicode(getString(), data, 0x3 +\n-                                                offset);\n+                StringUtil.putCompressedUnicode(getString(), data,\n+                  0x2 + field_4_ccAdjust + offset);\n             }\n             else\n             {\n                 StringUtil.putUncompressedUnicode(getString(), data,\n-                                                  0x3 + offset);\n+                  0x2 +field_4_ccAdjust + offset);\n             }\n         }\n         return getRecordSize();\n@@ -341,7 +431,8 @@\n     public int getRecordSize()\n     {\n         int charsize = isUncompressedUnicode() ? 2 : 1;\n-        return 3 + (getString().length() * charsize);\n+        return  2 + field_4_ccAdjust +\n+        (getString().length() * charsize);\n     }\n \n     public short getSid()\n@@ -349,6 +440,11 @@\n         return this.sid;\n     }\n \n+    protected void fillFields(byte [] data, short size)\n+    {\n+        fillFields(data,  size, 0);\n+    }\n+\n     /**\n      * called by the constructor, should set class level fields.  Should throw\n      * runtime exception for bad/icomplete data.\n@@ -360,6 +456,85 @@\n \n     protected void fillFields(byte [] data, short size, int offset)\n     {\n+      fillFields(data, size,  offset,0);\n+/*\n+        if ( field_4_ccAdjust == 1) {// CharCount field is 2 bytes\n+          field_1_charCount   = LittleEndian.getShort(data, offset);\n+        }\n+        else {\n+          field_1_charCount   = (short)LittleEndian.getUnsignedByte(data, offset);\n+        }\n+\n+        field_2_optionflags = data[ offset+ 1+field_4_ccAdjust ];\n+        if ((field_2_optionflags & 1) == 0)\n+        {\n+            field_3_string = new String(data,offset + 2+field_4_ccAdjust,\ngetCharCount());\n+        }\n+        else\n+        {\n+            char[] array = new char[ getCharCount() ];\n+\n+            for (int j = 0; j < array.length; j++)\n+            {\n+                array[ j ] = ( char ) LittleEndian.getShort(data,offset+\n+                                      2+field_4_ccAdjust + (j * 2));\n+            }\n+            field_3_string = new String(array);\n+        }\n+*/\n+    }\n+\n+    /**\n+     * called by the constructor, should set class level fields.  Should throw\n+     * runtime exception for bad/icomplete data.\n+     *\n+     * @param data raw data\n+     * @param size size of data\n+     * @param offset of the records data (provided a big array of the file)\n+     * @param extOffset skip additional offset after header and before string start\n+     */\n+\n+    protected void fillFields(byte [] data, short size, int offset,int extOffset)\n+    {\n+\n+        field_2_optionflags = data[ offset+ 1+field_4_ccAdjust ];\n+        short charByteSize = (short)(size - stringHeaderOverhead());\n+\n+        if ( field_4_ccAdjust == 1) {// CharCount field is 2 bytes\n+          field_1_charCount   = LittleEndian.getShort(data, offset);\n+        }\n+        else {\n+          field_1_charCount   = (short)LittleEndian.getUnsignedByte(data, offset);\n+        }\n+\n+        if ((field_2_optionflags & 1) == 0) // 8bit char\n+        {\n+          if ( field_1_charCount  > charByteSize) { // string in this record is\nbroken over continuation\n+            field_1_charCount  = charByteSize;\n+          }\n+          try {\n+            field_3_string = new String(data,offset + 2 + field_4_ccAdjust +\n+                              extOffset , getCharCount(),\"ISO-8859-1\");\n+          }\n+          catch (Exception e){\n+            e.printStackTrace();\n+          }\n+\n+        }\n+        else // 16bit char\n+        {\n+            if ( field_1_charCount  >( charByteSize / 2)) { // string in this\nrecord is broken over continuation\n+              field_1_charCount  = (short) (charByteSize / 2) ;\n+            }\n+            char[] array = new char[ getCharCount() ];\n+\n+            for (int j = 0; j < array.length; j++)\n+            {\n+                array[ j ] = ( char ) LittleEndian.getShort(data,offset+\n+                                      2+field_4_ccAdjust + extOffset  + (j * 2));\n+            }\n+            field_3_string = new String(array);\n+        }\n     }\n \n     public int compareTo(Object obj)\n@@ -380,13 +555,13 @@\n \n         if (isUncompressedUnicode())\n         {\n-            int proposedStringLength = proposedBrokenLength - 3;\n+            int proposedStringLength = proposedBrokenLength - (2 +\nfield_4_ccAdjust);\n \n             if ((proposedStringLength % 2) == 1)\n             {\n                 proposedStringLength--;\n             }\n-            rval = proposedStringLength + 3;\n+            rval = proposedStringLength + 2 + field_4_ccAdjust;\n         }\n         return rval;\n     }\n@@ -394,6 +569,15 @@\n     public boolean isExtendedText()\n     {\n         return (getOptionFlags() & EXT_BIT) != 0;\n+    }\n+\n+    private short stringHeaderOverhead()\n+    {\n+        return  (short)(2 + field_4_ccAdjust +\n+                 + ( ((field_2_optionflags & RICH_TEXT_BIT) != 0)?\n+                     LittleEndianConsts.SHORT_SIZE : 0 )\n+                 + (  ((field_2_optionflags & EXT_BIT) != 0)?\n+                     LittleEndianConsts.INT_SIZE : 0 )  );\n     }\n \n }\nIndex: jakarta-poi/src/java/org/apache/poi/util/StringUtil.java\n===================================================================\nRCS file: /home/cvspublic/jakarta-poi/src/java/org/apache/poi/util/StringUtil.java,v\nretrieving revision 1.2\ndiff -u -r1.2 StringUtil.java\n--- jakarta-poi/src/java/org/apache/poi/util/StringUtil.java\t19 May 2002 17:54:07 -0000\t1.2\n+++ jakarta-poi/src/java/org/apache/poi/util/StringUtil.java\t19 Jul 2002 07:00:28 -0000\n@@ -74,7 +74,7 @@\n      */\n     private StringUtil() { }\n \n-    \n+\n     /**\n      *  given a byte array of 16-bit unicode characters, compress to 8-bit and\n      *  return a string\n@@ -113,8 +113,8 @@\n         }\n         return new String(bstring);\n     }\n-    \n-    \n+\n+\n \n     /**\n      *  given a byte array of 16-bit unicode characters, compress to 8-bit and\n@@ -227,12 +227,12 @@\n             char c = input.charAt(k);\n \n             output[offset + (2 * k)] = (byte) (c >> 8);\n-            output[offset + (2 * k)] = (byte) c;\n+            output[offset + (2 * k)+1] = (byte) c;\n         }\n     }\n-    \n-    \n-    \n+\n+\n+\n \n     /**\n      *  Description of the Method\nIndex:\njakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSSTRecordSizeCalculator.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSSTRecordSizeCalculator.java,v\nretrieving revision 1.3\ndiff -u -r1.3 TestSSTRecordSizeCalculator.java\n--- jakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSSTRecordSizeCalculator.java\t17 Jul 2002 14:18:03 -0000\t1.3\n+++ jakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSSTRecordSizeCalculator.java\t19 Jul 2002 07:00:30 -0000\n@@ -186,7 +186,10 @@\n         int offset = LittleEndianConsts.SHORT_SIZE;\n         unicodeStringBuffer[offset++] = 0;\n         System.arraycopy( s.getBytes(), 0, unicodeStringBuffer, offset,\ns.length() );\n-        return new UnicodeString( UnicodeString.sid, (short)\nunicodeStringBuffer.length, unicodeStringBuffer );\n+//        return new UnicodeString( UnicodeString.sid, (short)\nunicodeStringBuffer.length, unicodeStringBuffer );\n+        return new UnicodeString(  unicodeStringBuffer,(short)\nunicodeStringBuffer.length,\n+                    UnicodeString.CHARCOUNTSIZE_DOUBLEBYTE     );\n+\n     }\n \n }\nIndex:\njakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSeriesTextRecord.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSeriesTextRecord.java,v\nretrieving revision 1.1\ndiff -u -r1.1 TestSeriesTextRecord.java\n--- jakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSeriesTextRecord.java\t18 May 2002 15:56:21 -0000\t1.1\n+++ jakarta-poi/src/testcases/org/apache/poi/hssf/record/TestSeriesTextRecord.java\t19 Jul 2002 07:00:30 -0000\n@@ -83,7 +83,7 @@\n             throws Exception\n     {\n         SeriesTextRecord record = new SeriesTextRecord((short)0x100d,\n(short)data.length, data);\n-        \n+\n \n         assertEquals( (short)0, record.getId());\n \n@@ -118,5 +118,15 @@\n         assertEquals(recordBytes.length - 4, data.length);\n         for (int i = 0; i < data.length; i++)\n             assertEquals(\"At offset \" + i, data[i], recordBytes[i+4]);\n+    }\n+    public static void main(String[] args)\n+        throws Exception\n+    {\n+      TestSeriesTextRecord t = new TestSeriesTextRecord (\"test instance\");\n+      //t.setUp();\n+      //t._test_file_path =\n+      //\"J:\\\\poi-cvs\\\\jakarta-poi\\\\src\\\\testcases\\\\org\\\\apache\\\\poi\\\\HSSF\\\\data\";\n+      t.testLoad();\n+      t.testStore();\n     }\n }\nIndex: jakarta-poi/src/testcases/org/apache/poi/util/TestStringUtil.java\n===================================================================\nRCS file:\n/home/cvspublic/jakarta-poi/src/testcases/org/apache/poi/util/TestStringUtil.java,v\nretrieving revision 1.2\ndiff -u -r1.2 TestStringUtil.java\n--- jakarta-poi/src/testcases/org/apache/poi/util/TestStringUtil.java\t11 Feb 2002 04:23:11 -0000\t1.2\n+++ jakarta-poi/src/testcases/org/apache/poi/util/TestStringUtil.java\t19 Jul 2002 07:00:31 -0000\n@@ -103,7 +103,7 @@\n      * Test more complex form of getFromUnicode\n      */\n \n-    public void testComplexGetFromUnicode()\n+  public void testComplexGetFromUnicode()\n     {\n         byte[] test_data = new byte[ 32 ];\n         int    index     = 0;\n@@ -172,8 +172,13 @@\n             ( byte ) 'o', ( byte ) ' ', ( byte ) 'W', ( byte ) 'o',\n             ( byte ) 'r', ( byte ) 'l', ( byte ) 'd', ( byte ) 0xAE\n         };\n-        String input           = new String(expected_output);\n-\n+        String input =new String(\"\");\n+        try {\n+          input           = new String(expected_output,\"ISO-8859-1\");\n+        }\n+        catch (Exception e){\n+            e.printStackTrace();\n+        }\n         StringUtil.putCompressedUnicode(input, output, 0);\n         for (int j = 0; j < expected_output.length; j++)\n         {", "id": 19843, "time": "2002-07-19T07:11:28Z", "bug_id": 10976, "creation_time": "2002-07-19T07:11:28Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 10976, "text": "Please resubmit this using \"create new attachment\"  I can't apply patches that\nare pasted in the file because they wrap.\n\nread last paragraph: http://jakarta.apache.org/poi/getinvolved/index.html\n\nThanks,\n\nAndy", "id": 19906, "time": "2002-07-21T03:23:07Z", "creator": "poi-support@buni.org", "creation_time": "2002-07-21T03:23:07Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 10976, "text": "(see previous comments - reopen when submitteD)", "id": 19907, "time": "2002-07-21T03:23:44Z", "creator": "poi-support@buni.org", "creation_time": "2002-07-21T03:23:44Z", "is_private": false, "attachment_id": null}, {"count": 3, "tags": [], "creator": "patrickl@ihm.gov.mo", "is_private": false, "text": "Created attachment 2431\nAttachment of  Unicode Support for sheetname , refactor SSTDeserializer & UnicodeString class", "id": 19948, "time": "2002-07-22T04:29:34Z", "bug_id": 10976, "creation_time": "2002-07-22T04:29:34Z", "attachment_id": 2431}, {"count": 4, "tags": [], "creator": "poi-support@buni.org", "attachment_id": null, "id": 20193, "time": "2002-07-25T12:23:50Z", "bug_id": 10976, "creation_time": "2002-07-25T12:23:50Z", "is_private": false, "text": "Sorry I didn't notice it.  You didn't reopen the bug.  (I may sound silly or \npedantic, I'm just busy, I scan the list of bugs for [PATCH] and open status\nwhen reviewing).  I'll review this shortly.  Right now, I have to go to work."}, {"count": 5, "tags": [], "text": "Hi.  I tried to apply this but the unit tests were failing so I'm going to look\nat it later along with that bug.", "is_private": false, "bug_id": 10976, "id": 20292, "time": "2002-07-27T01:24:38Z", "creator": "poi-support@buni.org", "creation_time": "2002-07-27T01:24:38Z", "attachment_id": null}, {"count": 6, "tags": [], "text": "Could it be due to the newly commited changed to the TestBoundSheetRecord.java\n\nglens       2002/07/26 18:45:44\n\n  Added:       src/testcases/org/apache/poi/hssf/record\n                        TestBoundSheetRecord.java\n  Log:\n  Test case for bound sheet record... it seems okay.\n  \n  Revision  Changes    Path\n  1.1                  jakarta-\npoi/src/testcases/org/apache/poi/hssf/record/TestBoundSheetRecord.java\n\nThanks for looking at it\n\nPatrick Lee", "is_private": false, "id": 20294, "creator": "patrickl@ihm.gov.mo", "time": "2002-07-27T10:34:32Z", "bug_id": 10976, "creation_time": "2002-07-27T10:34:32Z", "attachment_id": null}, {"count": 7, "attachment_id": null, "creator": "poi-support@buni.org", "is_private": false, "id": 20336, "time": "2002-07-28T23:24:16Z", "bug_id": 10976, "creation_time": "2002-07-28T23:24:16Z", "tags": [], "text": "Class org.apache.poi.hssf.record.TestBoundSheetRecord\nName Tests Errors Failures Time(s)\nTestBoundSheetRecord 2 0 1 0.581\nTests\n\nName Status Type Time(s)\ntestRecordLength Success 0.020\ntestWideRecordLength Failure 2 + 2 + 4 + 2 + 1 + 1 + len(str) * 2 expected:<24>\nbut was:<18>\n\njunit.framework.AssertionFailedError: 2 + 2 + 4 + 2 + 1 + 1 + len(str) * 2\nexpected:<24> but was:<18>\nat\norg.apache.poi.hssf.record.TestBoundSheetRecord.testWideRecordLength(TestBoundSheetRecord.java:93)\n0.020\n\n\nFix this and I'll apply it."}, {"count": 8, "tags": [], "text": "Hi Andy, Sergei and all \n\nI have checked the following unit test failure: \n\nClass org.apache.poi.hssf.record.TestBoundSheetRecord\nName Tests Errors Failures Time(s)\nTestBoundSheetRecord 2 0 1 0.581\nTests\n\nName Status Type Time(s)\ntestRecordLength Success 0.020\ntestWideRecordLength Failure 2 + 2 + 4 + 2 + 1 + 1 + len(str) * 2 expected:<24>\nbut was:<18>\n\njunit.framework.AssertionFailedError: 2 + 2 + 4 + 2 + 1 + 1 + len(str) * 2\nexpected:<24> but was:<18>\nat\norg.apache.poi.hssf.record.TestBoundSheetRecord.testWideRecordLength(TestBoundSheetRecord.java:93)\n0.020\n\nThe test is as follow: \n\n    public void testWideRecordLength()\n            throws Exception\n    {\n        BoundSheetRecord record = new BoundSheetRecord();\n        record.setCompressedUnicodeFlag((byte)0x01);\n        record.setSheetname(\"Sheet1\");\n        record.setSheetnameLength((byte)6);\n\n        assertEquals(\" 2  +  2  +  4  +   2   +    1     +    1    + len(str) *\n2\", 24, \n\nrecord.getRecordSize());\n    }\n\nThe setSheetname of BoundSheetRecord is as follow:\n\n    public void setSheetname(String sheetname)\n    {\n        boolean is16bit = is16bitString(sheetname);\n        setSheetnameLength((byte) sheetname.length() );\n        setCompressedUnicodeFlag((byte ) (is16bit?1:0));\n        field_5_sheetname = sheetname;\n    }\n\nThe unit test failed because the setSheetname use autodetection in deciding\nwhether the sheetname can be represented in excel compressed unicode format.  If\nyes, than it set the CompressedUnicodeFlag to 0 i.e. 8 bit representation.  It\nsimply ignore the following statement in testWideRecordLength():\n        record.setCompressedUnicodeFlag((byte)0x01);\n\nWhen I submitted the patch, the test was not there yet.  So now, the question is\nwhether we want autodetection in the setSheetname( and later, in the cell\nsetCellValue).  The following are some pro and cons :\n\nIt seems for the current situation,  the programmer (the user of the POI API)has\nto do more work by setting \n        record.setCompressedUnicodeFlag((byte)0x01);\nfor sheetname or \n        cell.setEncoding(org.apache.poi.hssf.usermodel.HSSFCell.ENCODING_UTF_16);\nfor cell value.\n\nAnd in case the programmer make a inconsistence mistake, ex. set for \n   \ncell.setEncoding(org.apache.poi.hssf.usermodel.HSSFCell.ENCODING_COMPRESSED_UNICODE\n);\nand then\n\tsetCellValue(\"\\u0422\\u0435\\u0441\\u0442\\u043E\\u0432\\u0430\\u044F\");\nWhat exception should be thrown?\n\nIf autodetection is used, the programmer code less, and consistence checking is\navoided.\n\nPlease conside each alternative and I will change the code accordingly \n\nPatrick Lee", "is_private": false, "bug_id": 10976, "id": 20350, "time": "2002-07-29T08:59:38Z", "creator": "patrickl@ihm.gov.mo", "creation_time": "2002-07-29T08:59:38Z", "attachment_id": null}, {"count": 9, "tags": [], "text": "I think we decided against autodetection because it doesn't work with russian\nand other langauges anyhow.  The default should be 8-bit and using 16-bit should\nbe optional.  ", "is_private": false, "bug_id": 10976, "id": 20355, "time": "2002-07-29T11:48:40Z", "creator": "poi-support@buni.org", "creation_time": "2002-07-29T11:48:40Z", "attachment_id": null}, {"count": 10, "tags": [], "creator": "patrickl@ihm.gov.mo", "is_private": false, "text": "Hi Andy, Sergei and all \n\n  Sergei, I haven't heard from you since I send you back your modified test \nprogram about setting a russian sheetname.  Do you have any success with it?\n\nPatrick Lee", "id": 20373, "time": "2002-07-29T16:31:16Z", "bug_id": 10976, "creation_time": "2002-07-29T16:31:16Z", "attachment_id": null}, {"count": 11, "tags": [], "creator": "sergeikozello@mail.ru", "attachment_id": null, "id": 20381, "time": "2002-07-29T19:23:20Z", "bug_id": 10976, "creation_time": "2002-07-29T19:23:20Z", "is_private": false, "text": "I have a succes and wrote it back to you vai e-mail, but juxt forgot, that it \nsucceded on my changes. %)\n\nAnd have took a look on my changes. As I see it is a very good idea to put the \ncode of using in the Records UnicodeString class.\n\nLet's merge our work on the unicode getting and putting we have into the \nUnicodeString. \nCould you see at the code at BoundSheetRecord, when I have refined you step: \nusing only StringUtil without SSTSerializer?\n\nWhat do you think about putting it into the UnicodeSrting, so we can benefit on \nusing this class and instantiating it in any record we need Unicode?\n\n"}, {"count": 12, "tags": [], "creator": "patrickl@ihm.gov.mo", "is_private": false, "text": "Hi Andy, Sergei and all \n\n>I have a succes and wrote it back to you vai e-mail, but juxt forgot, that it \n>succeded on my changes. %)\n\n\n>And have took a look on my changes. As I see it is a very good idea to put the \n>code of using in the Records UnicodeString class.\n\nGreat! can you send me a copy of the final code that works for you.  \n\n>Let's merge our work on the unicode getting and putting we have into the \n>UnicodeString. \n\nSure. Let fix this bug together.  I have some planning on futher\nrefactor/complete the UnicodeString \n\nclass.  Lets collaborate on this issue.\n\n>Could you see at the code at BoundSheetRecord, when I have refined you step: \n>using only StringUtil without SSTSerializer?\nPlease check \nhttp://nagoya.apache.org/bugzilla/show_bug.cgi?id=10976\nfor [Patch] Unicode Support for sheetname , refactor SSTDeserializer &\nUnicodeString class\nas it refactor code regarding BIFF8 format from SSTDeserializer to UnicodeString\nclass.  What do you \n\nthink of this idea.\n\n>What do you think about putting it into the UnicodeSrting, so we can benefit on \n>using this class and instantiating it in any record we need Unicode?\n\nDo you mean code described in?\nhttp://nagoya.apache.org/bugzilla/showattachment.cgi?attach_id=2422\n\nI am really interesting in working on this together.\nThanks \n\nPatrick Lee", "id": 20392, "time": "2002-07-30T04:03:30Z", "bug_id": 10976, "creation_time": "2002-07-30T04:03:30Z", "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 10976, "is_private": false, "count": 13, "id": 21089, "time": "2002-08-15T14:16:29Z", "creator": "poi-support@buni.org", "creation_time": "2002-08-15T14:16:29Z", "text": "What is the status of this work?  I'd like to get this in ASAP."}, {"count": 14, "tags": [], "text": "I was away from online for a last week. :(\n\nThe work on this bug is depends on bug #11010. As I have wrote, I think there \nis no bug in the patch you have rolled back.\nPlease, look at the last posts on this bug.\n\nAbout more Unicode support: while offline I have done unicode support for \nFormatRecord.\n\nAlso I have some questions on NameRecord. I have made the implemetation for it \nfor Page Titles, but I am not sure in the way I have done it.\n\nPlease look at the bug #11010, because the Unicode changes depend on it.", "is_private": false, "bug_id": 10976, "id": 21097, "time": "2002-08-15T18:37:50Z", "creator": "sergeikozello@mail.ru", "creation_time": "2002-08-15T18:37:50Z", "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 10976, "text": "sorry I missed the copy of the factory file...  (*nudge* *nudge* probably\nbecause it wasn't a patch).. . \n\nLooks like you nailed it. Thanks!", "count": 15, "id": 21102, "time": "2002-08-15T19:57:30Z", "creator": "poi-support@buni.org", "creation_time": "2002-08-15T19:57:30Z", "is_private": false}, {"count": 16, "tags": [], "creator": "poi-support@buni.org", "attachment_id": null, "id": 21104, "creation_time": "2002-08-15T20:15:41Z", "time": "2002-08-15T20:15:41Z", "bug_id": 10976, "text": "Okay I had more time to review this.  I like the idea but I hate the\nimplementation.  (no offense).  My objection:  EVERY method that says \"lifted\nfrom...\" ...  Lets fight this code rot right now.  Move those to common utility\nfunctions (perhaps StringUtility for instance) and remove them from any classes\nthey originate from (SSTRecord for instance).  Cutting and pasting is not a good\nthing.  I don't want to fix string functions everywhere, I want one authorative\nroutine for EACH way excel handles them.  Do that and comment it liberally and\nI'll reapply it..\n\nthe \"arraycopy\" function seems silly to me since it just calls to\nSystem.arraycopy... . . why do we have that?  \n\nOnce you've fixed it, please reattach and reopen this bug.... \n\nThanks,\n\nAndy", "is_private": false}]