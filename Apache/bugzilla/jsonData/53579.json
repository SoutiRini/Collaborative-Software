[{"count": 0, "tags": [], "creator": "yrd_us@yahoo.com", "text": "httpd shows 3 defunct children and is unable to serve any further requets. A lelnet connection to port 80 is successful though.\n\nVersion output \n\nhttpd -V\nServer version: Apache/2.2.22 (Unix)\nServer built:   Jun 27 2012 23:19:33\nServer's Module Magic Number: 20051115:30\nServer loaded:  APR 1.4.5, APR-Util 1.4.1\nCompiled using: APR 1.4.5, APR-Util 1.4.1\nArchitecture:   64-bit\nServer MPM:     Prefork\n  threaded:     no\n    forked:     yes (variable process count)\nServer compiled with....\n -D APACHE_MPM_DIR=\"server/mpm/prefork\"\n -D APR_HAS_SENDFILE\n -D APR_HAS_MMAP\n -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n -D APR_USE_SYSVSEM_SERIALIZE\n -D APR_USE_PTHREAD_SERIALIZE\n -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n -D APR_HAS_OTHER_CHILD\n -D AP_HAVE_RELIABLE_PIPED_LOGS\n -D DYNAMIC_MODULE_LIMIT=128\n -D HTTPD_ROOT=\"/opt/tms\"\n -D SUEXEC_BIN=\"/opt/tms/bin/suexec\"\n -D DEFAULT_PIDLOG=\"logs/httpd.pid\"\n -D DEFAULT_SCOREBOARD=\"logs/apache_runtime_status\"\n -D DEFAULT_LOCKFILE=\"logs/accept.lock\"\n -D DEFAULT_ERRORLOG=\"logs/error_log\"\n -D AP_TYPES_CONFIG_FILE=\"conf/mime.types\"\n -D SERVER_CONFIG_FILE=\"conf/httpd.conf\"\n\n\n\nhttpd -l\nCompiled in modules:\n  core.c\n  mod_authn_file.c\n  mod_authn_default.c\n  mod_authz_host.c\n  mod_authz_groupfile.c\n  mod_authz_user.c\n  mod_authz_default.c\n  mod_auth_basic.c\n  mod_filter.c\n  mod_deflate.c\n  mod_log_config.c\n  mod_env.c\n  mod_headers.c\n  mod_version.c\n  mod_ssl.c\n  prefork.c\n  http_core.c\n  mod_mime.c\n  mod_autoindex.c\n  mod_cgi.c\n  mod_dir.c\n  mod_actions.c\n  mod_alias.c\n  mod_rewrite.c\n  mod_so.c\n\nConfig file snippet\n\nTimeout 3600\nKeepAlive On\nMaxKeepAliveRequests 100\nKeepAliveTimeout 15\n\nStartServers         1\nMinSpareServers      1\nMaxSpareServers      2\nMaxClients          16\nMaxRequestsPerChild  0\n\nListen 80\nListen 443\n\n\n\nFollowing is the output of netstat and status of the httpd\n\n# netstat -nt | grep \":80\"\ntcp      296      0 ::ffff:10.0.1.233:80        ::ffff:10.18.3.14:62429     CLOSE_WAIT\ntcp      287      0 ::ffff:10.0.1.233:80        ::ffff:10.18.0.233:51590    CLOSE_WAIT\ntcp      304      0 ::ffff:10.0.1.233:80        ::ffff:10.18.0.233:51284    CLOSE_WAIT\ntcp      304      0 ::ffff:10.0.1.233:80        ::ffff:10.18.0.233:51576    CLOSE_WAIT\ntcp      296      0 ::ffff:10.0.1.233:80        ::ffff:10.18.3.14:58146     CLOSE_WAIT\ntcp      287      0 ::ffff:10.0.1.233:80        ::ffff:10.18.0.233:51783    CLOSE_WAIT\ntcp      287      0 ::ffff:10.0.1.233:80        ::ffff:10.18.0.233:51761    CLOSE_WAIT\n\n# ps -ef | grep httpd\nadmin    11463 19173  0 21:53 pts/0    00:00:00 grep httpd\nadmin    12084 24519  0 Jun29 ?        00:00:19 /usr/sbin/httpd -D NO_DETACH -f /etc/opt/tms/output/httpd.conf\napache   21089 12084  0 Jul05 ?        00:00:00 [httpd] <defunct>\napache   31445 12084  0 Jul05 ?        00:00:00 [httpd] <defunct>\napache   31596 12084  0 Jul05 ?        00:00:00 [httpd] <defunct>\n\ngdb -p 12084 /usr/sbin/httpd shows that the top level process is here:\n\n(gdb) where\n#0  0x00007f638884e470 in __write_nocancel () from /lib64/libpthread.so.0\n#1  0x0000000000483c87 in apr_file_write ()\n#2  0x00000000004273af in ap_mpm_pod_signal ()\n#3  0x000000000045f3c3 in ap_mpm_run ()\n#4  0x000000000040a664 in main ()\n\nApparently, it is getting stuck writing something to a file. \nap_mpm_pod_signal() effectively just called apr_file_write(), where it is\ngetting stuck.\n\nUsing an httpd built with -g , the stack trace from gdb looks like this:\n\n(gdb) where\n#0  0x00007f638884e470 in __write_nocancel () from /lib64/libpthread.so.0\n#1  0x0000000000483c87 in apr_file_write (thefile=0x19314b0, \n    buf=0x7fffb849709f, nbytes=0x7fffb8497090) at file_io/unix/readwrite.c:188\n#2  0x00000000004273af in pod_signal_internal (pod=0x1931420)\n    at mpm_common.c:630\n#3  ap_mpm_pod_signal (pod=0x1931420) at mpm_common.c:726\n#4  0x000000000045f3c3 in perform_idle_server_maintenance (\n    _pconf=<value optimized out>, plog=<value optimized out>, \n    s=<value optimized out>) at prefork.c:867\n#5  ap_mpm_run (_pconf=<value optimized out>, plog=<value optimized out>, \n    s=<value optimized out>) at prefork.c:1107\n#6  0x000000000040a664 in main (argc=5, argv=0x7fffb8497448) at main.c:753\n\nthefile is as follows:\n\n(gdb) frame 1\n#1  0x0000000000483c87 in apr_file_write (thefile=0x19314b0, \n    buf=0x7fffb849709f, nbytes=0x7fffb8497090) at file_io/unix/readwrite.c:188\n188     file_io/unix/readwrite.c: No such file or directory.\n        in file_io/unix/readwrite.c\n(gdb) print thefile\n$1 = (apr_file_t *) 0x19314b0\n(gdb) print *thefile\n$2 = {\n  pool = 0x18fa138, \n  filedes = 8, \n  fname = 0x0, \n  flags = 0, \n  eof_hit = 0, \n  is_pipe = 1, \n  timeout = -1, \n  buffered = 0, \n  blocking = BLK_ON, \n  ungetchar = 0, \n  buffer = 0x0, \n  bufpos = 0, \n  bufsize = 0, \n  dataRead = 0, \n  direction = 0, \n  filePtr = 0, \n  thlock = 0x0\n}\n(gdb) \n\nIn other words, it is writing to a pipe (thefile->ispipe == 1).\n\nNote that line 188 of file_io/unix/readwrite.c is this:\n\n187         do {\n188             rv = write(thefile->filedes, buf, *nbytes);\n189         } while (rv == (apr_size_t)-1 && errno == EINTR);", "id": 160768, "time": "2012-07-20T23:20:48Z", "bug_id": 53579, "creation_time": "2012-07-20T23:20:48Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "text": "Hmmm, parent blocked writing to a full pipe with no readers...  Unclear if the parent needs to use a timeout, or it is writing too many times, or ???\n\nDo you have an easy way to reproduce this?  Does this happen at about the same time that the error log shows other issues?", "is_private": false, "bug_id": 53579, "id": 160771, "time": "2012-07-21T14:21:00Z", "creator": "trawick@apache.org", "creation_time": "2012-07-21T14:21:00Z", "attachment_id": null}, {"count": 2, "tags": [], "creator": "yrd_us@yahoo.com", "text": "Not very easy to reproduce, happens after around 48 hours of normal testing. The error log has the following errors.\n\nconnect to listener on [::]:443\n[Thu Jul 05 00:00:01 2012] [warn] (101)Network is unreachable: connect to listener on [::]:443\n[Thu Jul 05 00:00:01 2012] [warn] (101)Network is unreachable: connect to listener on [::]:443\n[Thu Jul 05 00:00:01 2012] [notice] Graceful restart requested, doing restart\n[Thu Jul 05 00:00:01 2012] [warn] (101)Network is unreachable: connect to listener on [::]:443\n\nThe Network unreachable message is seen continous for few hours, above are the last messages in the error log\n\nFollowing are the last messages in the access log\n\nproduct.js?v=1a95dd38c7ca8035134db9ac4aa167f6 HTTP/1.1\" 304 - (259 us)\n10.0.3.45 - - [05/Jul/2012:00:02:46 -0700] \"GET /rollup.css?v=1a95dd38c7ca8035134db9ac4aa167f6 HTTP/1.1\" 304 - (91 us)\n10.0.3.45 - - [05/Jul/2012:00:02:46 -0700] \"GET /rollup-product.css?v=1a95dd38c7ca8035134db9ac4aa167f6 HTTP/1.1\" 304 - (155 us)\n10.0.3.45 - - [05/Jul/2012:00:02:47 -0700] \"POST /mgmt/xmldata?p=dynamicStatus HTTP/1.1\" 200 138 (10943 us)", "id": 160842, "attachment_id": null, "bug_id": 53579, "creation_time": "2012-07-23T18:19:38Z", "time": "2012-07-23T18:19:38Z", "is_private": false}, {"count": 3, "tags": [], "creator": "yrd_us@yahoo.com", "attachment_id": null, "id": 160909, "time": "2012-07-25T18:26:44Z", "bug_id": 53579, "creation_time": "2012-07-25T18:26:44Z", "is_private": false, "text": "I suspect this has something to do with graceful restart from the logrotate. We did not see this problem before , but it is more prominent once we started getting the warning \n[warn] (101)Network is unreachable: connect to listener on [::]:443\nwhich is repeated frequently in the log file."}, {"count": 4, "tags": [], "bug_id": 53579, "attachment_id": null, "text": "Could reproduce it again. Basically it is writing to the pod (pipe of death) and is stuck in it forever. All the child processes are in defunct state. httpd is no more able to server any further requests.. Can someone please respond. I am increasing the severity to blocker as it stops serving any requests and is practically not usable.\n\nPlease let me know if any more info is needed as I still have the system in this state.", "id": 161078, "time": "2012-08-03T02:48:21Z", "creator": "yrd_us@yahoo.com", "creation_time": "2012-08-03T02:48:21Z", "is_private": false}, {"count": 5, "tags": [], "bug_id": 53579, "attachment_id": null, "is_private": false, "id": 163132, "time": "2012-11-01T18:37:30Z", "creator": "gcmoga@gmail.com", "creation_time": "2012-11-01T18:37:30Z", "text": "(In reply to comment #4)\n> Could reproduce it again. Basically it is writing to the pod (pipe of death)\n> and is stuck in it forever. All the child processes are in defunct state.\n> httpd is no more able to server any further requests.. Can someone please\n> respond. I am increasing the severity to blocker as it stops serving any\n> requests and is practically not usable.\n\nPlease let me know if any more info\n> is needed as I still have the system in this state.\n\nI am bumping into the exact same problem, but I cannot reproduce it.\nCould you please let me know how did you reproduce this problem?\nThank you\n\n\nBacktrace:\n\n(gdb) #0  0xb7cd330e in write () from /lib/libpthread.so.0\n(gdb) #1  0x080e1947 in apr_file_write ()\n(gdb) #2  0x08080147 in ap_mpm_pod_signal ()\n(gdb) #3  0x080b1aa1 in ap_mpm_run ()\n(gdb) #4  0x08067ef2 in main ()\n\nAll child processes are <defunct>\n\n\nServer version: Apache/2.2.3\nServer built:   Oct  6 2011 18:06:51\nServer's Module Magic Number: 20051115:3\nServer loaded:  APR 1.2.7, APR-Util 1.2.7\nCompiled using: APR 1.2.7, APR-Util 1.2.7\nArchitecture:   32-bit\nServer MPM:     Prefork\n  threaded:     no\n    forked:     yes (variable process count)\nServer compiled with....\n -D APACHE_MPM_DIR=\"server/mpm/prefork\"\n -D APR_HAS_SENDFILE\n -D APR_HAS_MMAP\n -D APR_HAVE_IPV6 (IPv4-mapped addresses enabled)\n -D APR_USE_SYSVSEM_SERIALIZE\n -D APR_USE_PTHREAD_SERIALIZE\n -D SINGLE_LISTEN_UNSERIALIZED_ACCEPT\n -D APR_HAS_OTHER_CHILD\n -D AP_HAVE_RELIABLE_PIPED_LOGS\n -D DYNAMIC_MODULE_LIMIT=128\n -D HTTPD_ROOT=\"/\"\n -D SUEXEC_BIN=\"//bin/suexec\"\n -D DEFAULT_PIDLOG=\"/var/run/apache2.pid\"\n -D DEFAULT_SCOREBOARD=\"logs/apache_runtime_status\"\n -D DEFAULT_LOCKFILE=\"var/run/accept.lock\"\n -D DEFAULT_ERRORLOG=\"logs/error_log\"\n -D AP_TYPES_CONFIG_FILE=\"etc/apache/mime.types\"\n -D SERVER_CONFIG_FILE=\"etc/apache/httpd.conf\"\n\nCompiled in modules:\n  core.c\n  mod_authn_file.c\n  mod_authn_default.c\n  mod_authz_host.c\n  mod_authz_groupfile.c\n  mod_authz_user.c\n  mod_authz_default.c\n  mod_auth_basic.c\n  mod_include.c\n  mod_filter.c\n  mod_log_config.c\n  mod_env.c\n  mod_setenvif.c\n  mod_ssl.c\n  prefork.c\n  http_core.c\n  mod_mime.c\n  mod_status.c\n  mod_autoindex.c\n  mod_asis.c\n  mod_cgi.c\n  mod_negotiation.c\n  mod_dir.c\n  mod_actions.c\n  mod_userdir.c\n  mod_alias.c\n  mod_so.c"}, {"count": 6, "tags": [], "text": "After looking at the source code and doing some more testing, here are the results:\n\n-This problem kicks in when the pipe-of-death becomes full (64 kbytes on a Linux system). When this happens, then the httpd parent process is stuck in a write() call, since the pod is blocking (?!) \n-The pipe-of-death is written to by the httpd parent process, one byte at a time, in its main loop, as long as the number or httpd child processes exceeds the \"MaxSpareServers\" setting in the httpd.conf file.\n-The pipe-of death is read by the httpd child processes, in their main loop, as long as there are HTTP requests sent to the server.\n-If the httpd server is idle for a long time (5 days or so), then the child processes are sleeping, either pending on a semaphore or in a system epoll_wait() call with a very long timeout (100 days ?!).\n-If the number of child processes exceeds the MaxSpareServers setting at the time the httpd server becomes idle, then with only the httpd parent process spinning, the pipe-of-death is constantly written to and no one is reading from it.\n-When the parent httpd process writes to the pipe-of-death, it also sends a \"dummy\" HTTP request to the child processes, making a TCP connection to the system loopback interface on the httpd listener port.\n-If for some reason the loopback interface and/or listener port are blocked by the Linux firewall for example, then this \"dummy\" HTTP request fails and never wakes the child processes up.\n-When, after the pipe-of-death becomes full, the first external HTTP request comes in, the httpd child processes wake up, process the requests, read the pipe-of-death and go <defunct>.\n-The parent httpd process cannot collect the <defunct> child processes, since it it blocked in the write() system call.\n\nIn conclusion this problem is caused by a combination of:\n\ninternal httpd design:\n-pipe-of-death blocks in write().\n-child httpd epoll_wait() call does not timeout.\n\nsystem problems:\n-httpd listener port on the loopback interface is blocked.", "is_private": false, "bug_id": 53579, "id": 163489, "time": "2012-11-16T20:26:41Z", "creator": "gcmoga@gmail.com", "creation_time": "2012-11-16T20:26:41Z", "attachment_id": null}, {"count": 7, "tags": [], "creator": "loic.etienne@tech.swisssign.com", "text": "We could also observe the problem with 2.2.14-5ubuntu8.12\n\nReading (with cat) from the affected file descriptor (pipe of death) actually made the parent process stop blocking on write. The affected application was a test instance, with little traffic. This experimentally confirms the the analysis above.", "id": 175684, "attachment_id": null, "bug_id": 53579, "creation_time": "2014-06-05T15:35:52Z", "time": "2014-06-05T15:35:52Z", "is_private": false}, {"count": 8, "tags": [], "creator": "loic.etienne@tech.swisssign.com", "text": "We observed that some processes try to read from the pipe of death from the file descriptor 0 (instead of 7 on our system, from which other processes read the pipe of death).\n\ndummy request read from file descriptor 0\ndummy request fails (no ssl)\nfile descriptor 0 closed\nread from file descriptor 0 (instead of pipe of death), error bad file descriptor\nloop to the next connection\n\nNote that the correct file descriptor 7 is open in the child process in question, but the variable supposed to store it contains 0 instead of 7.\n\nWe also observed that all our processes are gradually affected by this problem, but we have no hypothesis what event triggers this dysfunction.", "id": 175711, "time": "2014-06-06T16:57:07Z", "bug_id": 53579, "creation_time": "2014-06-06T16:57:07Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "bug_id": 53579, "attachment_id": null, "text": "Any updates on this issue? Still running into it on 2.4.10... Any ideas on how to force recreation? Looks like there needs to be a way to verify that the pod writes are being consumed? How would I do that?", "id": 182219, "time": "2015-04-01T18:08:14Z", "creator": "mark_a_evans@dell.com", "creation_time": "2015-04-01T18:08:14Z", "is_private": false}, {"count": 10, "tags": [], "creator": "mahudees@gmail.com", "text": "Able to see the issue in 2.2.31 as well, Did any one manage to find any workaround to overcome this issue or any resolution on this. Is there any concrete repro steps that would lead to this issue always.\n\nFor me most of the logs and scenarios matched exactly as given here.", "id": 188463, "time": "2016-02-16T11:13:06Z", "bug_id": 53579, "creation_time": "2016-02-16T11:13:06Z", "is_private": false, "attachment_id": null}, {"count": 11, "tags": [], "text": "I could observe this issue with 2.4.6 (default httpd package on CentOS 7).", "attachment_id": null, "id": 191697, "creation_time": "2016-06-15T20:04:51Z", "time": "2016-06-15T20:04:51Z", "creator": "a.leofreddi@vleo.net", "bug_id": 53579, "is_private": false}]