[{"count": 0, "tags": [], "creator": "rajjain@lucent.com", "text": "When I am parsing a XML file using xerces version 1.4.2 as well as 1.4.3 at certain point new line is automatically inserted.\nSay if withing a tag i have value as SUBNETWORK, XML parser breaks it into SU and BNETWORK and gives me as two parameters.\n\nIts happening with both 1.4.2 and 1.4.3 but at different locations.", "id": 9538, "time": "2002-01-10T21:07:37Z", "bug_id": 5801, "creation_time": "2002-01-10T21:07:37Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 5801, "attachment_id": null, "text": "can u attatch  the XML file that can produce this problem ? can u also try it \nusing xerces2 beta4 and see what is the outcome ?\n\nthanks\nNeeraj\n", "id": 9543, "time": "2002-01-11T05:41:17Z", "creator": "neeraj.bajaj@sun.com", "creation_time": "2002-01-11T05:41:17Z", "is_private": false}, {"count": 2, "tags": [], "bug_id": 5801, "attachment_id": null, "is_private": false, "id": 9550, "time": "2002-01-11T06:29:29Z", "creator": "gmarcy@us.ibm.com", "creation_time": "2002-01-11T06:29:29Z", "text": "I doubt that Xerces is adding a newline character, so if one appears it is \nlikely to be in the handler code.  In particular, if the handler is thinking \nthat contiguous character data in the document is always going to be reported \nusing a single characters() callback that would be an error.  SAX parsers are \nfree to break character data into multiple callbacks, which is what I am \nguessing is the case here.  In the case of Xerces, if the character data \nhappens to be split across \"buffers\" the parser will generate multiple \ncallbacks.  This behavior is documented in the SAX API and applications must \nprovide code in the handlers to deal with merging the \"adjacent\" characters() \ncallbacks if they require such.\n"}, {"count": 3, "tags": [], "bug_id": 5801, "is_private": false, "text": "Hi,\n After going through the source code and additional debugging , I came to\nconclusion that Parser is not attaching the new line but what is happening is\nsomething like this. Xerces covnerts that input XML file into linked list of\nchunks with the size of each chunk being 16k and the input file I am using is\nmore that 50K in size. While processing this XML file, if for any XML tag if the\ndata is located in the multiple chunks say for XML tag PARAM with value as\nSUBNETWORK, if SUB is in CHUNK1 and and NETWORK in CHUNK2, then while giving me\nthe value of tag PARAM using call back function Characters, the parse returns me\nthe value of the tag PARAM as NETWORK rather than SUB. So whats is happening is\nwhen the value of a particular tag is distributed across the chunks the value\nwhich is available in the last chunk for a given XML tag is only returned but in\nactual scnerio or expected result is that parser should combine the values\nacross the chunks and should return the combined value as the value of the XML\ntag.\n\nI found out that problem is in the file\norg/apache/xerces/readers/AbstractCharReader.java in the function\ncallCharDataHandler where first part of function handles the case when data is\nin the single chunk and second part covers the data spead across the chunks. \nIn the second part in this function , instead of calling\nfCharDataHandler.processCharacters(dataChunk.toCharArray(), index,\n nbytes); for each chunk in the linked list what should be done is create a\ntemporary Char [] and get all the data spead across the chunk into this\ntemporary Char [] and then call this line \nfCharDataHandler.processCharacters(dataChunk.toCharArray(), index,\n nbytes); \n\nafter the  do {} while (count >0); loop is over in function callCharDataHandler.\n\n\nWith the use of temporary Char [] in the source code of Xerces I am able to fix\nmy problem temporarily.\n\nI just want to clarify that combining of this characters across the 16K chunk is\nparsers responsibility or that application that is using the parser.\n\nIf its first one then its really bug and if its second one then its expected\nbehaviour but still I feel that parser should be the one who would be taking\ncare of merging and giving me the single value for a given tag.\n\nOriginal Code:\n\nprivate void callCharDataHandler(int offset, int endOffset, boolean\nisWhitespace) throws Exception\n\n       //\n        // The data is spread across chunks.\n        //\n                int i=0;\n        int count = length;\n        int nbytes = CharDataChunk.CHUNK_SIZE - index;\n        if (isWhitespace)\n            fCharDataHandler.processWhitespace(dataChunk.toCharArray(), index,\nnbytes);\n        else\n        {\n            fCharDataHandler.processCharacters(dataChunk.toCharArray(), index,\nnbytes)\n;\n        }\n        count -= nbytes;\n\n        //\n        // Use each Chunk in turn until we are done.\n        //\n        do {\n            dataChunk = dataChunk.nextChunk();\n            if (dataChunk == null) {\n                throw new RuntimeException(new\nImplementationMessages().createMessage(nu\nll, ImplementationMessages.INT_DCN, 0, null));\n            }\n            nbytes = count <= CharDataChunk.CHUNK_SIZE ? count :\nCharDataChunk.CHUNK_SIZ\nE;\n            if (isWhitespace)\n                fCharDataHandler.processWhitespace(dataChunk.toCharArray(), 0,\nnbytes);\n            else\n                        {\n                fCharDataHandler.processCharacters(dataChunk.toCharArray(), 0,\nnbytes)\n;\n                        }\n            count -= nbytes;\n        } while (count > 0);\n \n    }\n\n\n\n\n\nModified Code: (temporary fix)\nprivate void callCharDataHandler(int offset, int endOffset, boolean\nisWhitespace) throws Exception\n\n       //\n        // The data is spread across chunks.\n        //\n                char [] myChar1=new char[CharDataChunk.CHUNK_SIZE];\n                char [] myChar2=new char[length+1];\n                int i=0;\n        int count = length;\n        int nbytes = CharDataChunk.CHUNK_SIZE - index;\n        if (isWhitespace)\n            fCharDataHandler.processWhitespace(dataChunk.toCharArray(), index,\nnbytes);\n        else\n        {\n            //fCharDataHandler.processCharacters(dataChunk.toCharArray(), index,\nnbytes)\n;\n                          myChar1=dataChunk.toCharArray();\n                          for(i=0;i<nbytes;i++)\n                                myChar2[i]=myChar1[i+index];\n\n                }\n        count -= nbytes;\n\n        //\n        // Use each Chunk in turn until we are done.\n        //\n        do {\n            dataChunk = dataChunk.nextChunk();\n            if (dataChunk == null) {\n                throw new RuntimeException(new\nImplementationMessages().createMessage(nu\nll, ImplementationMessages.INT_DCN, 0, null));\n            }\n            nbytes = count <= CharDataChunk.CHUNK_SIZE ? count :\nCharDataChunk.CHUNK_SIZ\nE;\n            if (isWhitespace)\n                fCharDataHandler.processWhitespace(dataChunk.toCharArray(), 0,\nnbytes);\n            else\n                        {\n                //fCharDataHandler.processCharacters(dataChunk.toCharArray(), 0,\nnbytes)\n;\n                                char[] myChar3=dataChunk.toCharArray();\n                                for(int j=0;j<nbytes;j++,i++)\n                                        myChar2[i]=myChar3[j];\n                        }\n            count -= nbytes;\n        } while (count > 0);\n               fCharDataHandler.processCharacters(myChar2, 0, i);\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": 9639, "time": "2002-01-14T21:25:32Z", "creator": "rajjain@lucent.com", "creation_time": "2002-01-14T21:25:32Z", "attachment_id": null}, {"count": 4, "tags": [], "creator": "gmarcy@us.ibm.com", "attachment_id": null, "is_private": false, "id": 9677, "time": "2002-01-15T16:29:26Z", "bug_id": 5801, "creation_time": "2002-01-15T16:29:26Z", "text": "As I pointed out in my response, the parser is doing exactly what it is supposed \nto.  If the parser were to do as you suggest, then even more people would be \nincorrectly thinking that parsers are supposed to do this, which they are not.  \nThis will lead to erroneous bug reports like this one being filed against every \nother SAX parser by people that think that the Xerces behavior is correct and \nthat therefore every other parser is broken.  You should not be depending upon \nthis behavior, and we certainly should not be changing Xerces to slow down and \ncheck for this case and allocate memory and/or copy characters across data \nchunks.  If you are still not convinced, imagine an XML document that contains a \nmegabyte of character data with only a start tag at the front and an end tag at \nthe end.  We would be copying the data 32k at a time trying to build up a single \npiece of memory with the entire character data run in a contiguous piece of \nmemory.  Given the fact that most users of SAX do not care if the data is \ncontiguous or not, which is why SAX doesn't require it, we would be spending all \nour time slinging strings around instead of parsing XML.\n\nYou should fix your handlers to work when the character data is split into \nseveral calls.  This is a requirement of using SAX."}]