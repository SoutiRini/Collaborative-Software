[{"count": 0, "tags": [], "bug_id": 52203, "attachment_id": null, "is_private": false, "id": 151584, "time": "2011-11-17T09:27:28Z", "creator": "vanlooon@126.com", "creation_time": "2011-11-17T09:27:28Z", "text": "I try to read .xlsx file of 1 million rows by using usermodel api, the file size is 11.2 MB, the jvm throw Exception :\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:2786)\n\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94)\n\tat org.apache.poi.openxml4j.util.ZipInputStreamZipEntrySource$FakeZipEntry.<init>(ZipInputStreamZipEntrySource.java:115)\n\tat org.apache.poi.openxml4j.util.ZipInputStreamZipEntrySource.<init>(ZipInputStreamZipEntrySource.java:55)\n\tat org.apache.poi.openxml4j.opc.ZipPackage.<init>(ZipPackage.java:82)\n\tat org.apache.poi.openxml4j.opc.OPCPackage.open(OPCPackage.java:220)\n\tat SXSSFWorkbookTest.test2(SXSSFWorkbookTest.java:51)\n\tat SXSSFWorkbookTest.main(SXSSFWorkbookTest.java:37)\n\nTo resolve the issue, i use the eventmodel api, that is ok!.\nBut i want to know why the usermodel api take so much memory when parseing huge rows file???"}, {"count": 1, "tags": [], "bug_id": 52203, "attachment_id": null, "id": 151585, "time": "2011-11-17T09:34:43Z", "creator": "vanlooon@126.com", "creation_time": "2011-11-17T09:34:43Z", "is_private": false, "text": "(In reply to comment #0)\n> I try to read .xlsx file of 1 million rows by using usermodel api, the file\n> size is 11.2 MB, the jvm throw Exception :\ncode:\n                InputStream inp = new FileInputStream(\"100w.xlsx\");\n\t\tWorkbook wb = WorkbookFactory.create(inp);\nexception:\n> Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n>     at java.util.Arrays.copyOf(Arrays.java:2786)\n>     at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94)\n>     at\n> org.apache.poi.openxml4j.util.ZipInputStreamZipEntrySource$FakeZipEntry.<init>(ZipInputStreamZipEntrySource.java:115)\n>     at\n> org.apache.poi.openxml4j.util.ZipInputStreamZipEntrySource.<init>(ZipInputStreamZipEntrySource.java:55)\n>     at org.apache.poi.openxml4j.opc.ZipPackage.<init>(ZipPackage.java:82)\n>     at org.apache.poi.openxml4j.opc.OPCPackage.open(OPCPackage.java:220)\n>     at SXSSFWorkbookTest.test2(SXSSFWorkbookTest.java:51)\n>     at SXSSFWorkbookTest.main(SXSSFWorkbookTest.java:37)\n> To resolve the issue, i use the eventmodel api, that is ok!.\n> But i want to know why the usermodel api take so much memory when parseing huge\n> rows file???"}, {"count": 2, "tags": [], "creator": "apache@gagravarr.org", "is_private": false, "text": "As discussed many times on the list, the usermodel loads everything into memory, so you need lots of memory available to hold everything. The event model just does one little bit at a time, so is much lower memory footprint (but you can't do random access)", "id": 151590, "time": "2011-11-17T11:34:05Z", "bug_id": 52203, "creation_time": "2011-11-17T11:34:05Z", "attachment_id": null}]