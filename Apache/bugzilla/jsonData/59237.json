[{"count": 0, "tags": [], "bug_id": 59237, "text": "I have found that when using HTTP2 in Apache 2.4.18 mod_authnz_external will break after a few (5-20) requests* even though it worked fine for those first ones. Suddenly some request is unauth. 401 and re-auth does not work anymore (using correct password!). Tested using Opera and Firefox. It does not happen when using HTTP1.1 (disable in Apache or use IE) or when using Apache builtin auth (e.g. Digest). It appears to happen when a lot of requests are made by the browser (maybe additional h2 streams are opened or some other pipelining causing race conditions?).\n\n    Protocols h2 http/1.1 # h2 breaks ext. auth - http1.1 OR builtin auth digest works\n    DefineExternalAuth unixuser pipe /usr/sbin/pwauth\n    AuthType Basic\n    AuthName blah\n    AuthBasicProvider external\n    AuthExternal unixuser\n    Require valid-user", "id": 189728, "time": "2016-03-25T22:36:31Z", "creator": "karim.scheik@prisma-solutions.at", "creation_time": "2016-03-25T22:36:31Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 59237, "is_private": false, "text": "*\n[Fri Mar 25 23:18:16.121542 2016] [auth_basic:error] [pid 8506:tid 139833380353792] [client :14641] AH01617: user k: authentication failure for \"/ /\": Password Mismatch\n[Fri Mar 25 23:18:16.121498 2016] [authnz_external:error] [pid 8506:tid 139833489458944] [client :14641] External authenticator died on signal 15, referer: \n[Fri Mar 25 23:18:16.121511 2016] [authnz_external:error] [pid 8506:tid 139833380353792] [client :14641] AuthExtern unixuser [/usr/sbin/pwauth]: Failed (-2) for user k, referer:", "id": 189729, "time": "2016-03-25T22:41:45Z", "creator": "karim.scheik@prisma-solutions.at", "creation_time": "2016-03-25T22:41:45Z", "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 59237, "text": "Hi, thanks for your report.\n\nI had a quick look at mod_auth_external code and, to my understanding, it starts in your configuration the 'pwauth' script for every request, be it a http/1.1 or h2 request. As far as I know, there is no principal difference how this is invoked.\n\nFrom your log I can see that pwauth receives a SIGTERM. This is the timeout handler that tries to stop pwauth when it takes too long. So, it seems that the script, for some reason, is hanging, maybe trying to access PAM? \n\nIf you run pwauth as a root user, and give its input username/password, do you see timely behavior?", "count": 2, "id": 190127, "time": "2016-04-11T08:54:31Z", "creator": "stefan@eissing.org", "creation_time": "2016-04-11T08:54:31Z", "is_private": false}, {"count": 3, "tags": [], "bug_id": 59237, "is_private": false, "id": 193431, "attachment_id": null, "creator": "stefan@eissing.org", "creation_time": "2016-08-31T13:59:39Z", "time": "2016-08-31T13:59:39Z", "text": "If no additional information is available, I will soon close this report."}, {"count": 4, "text": "I recently experienced the same symptoms as Karim (Apache 2.4.25, mod_authnz_external 3.3.2) when enabling HTTP2: basic auth fails randomly.\n\nThis doesn't look like a timeout on the pwauth subprocess. I can run it in a continuous loop for as long as I want. Each execution consistently takes ~0.03s of wallclock.\n\n[jwm@boost:pts/9 ~> while :; do echo -e 'some-user\\nsome-password' | time sudo pwauth; if [ $? -ne 0 ]; then echo $?; fi; done\n0.02user 0.00system 0:00.03elapsed 87%CPU (0avgtext+0avgdata 3712maxresident)k\n0inputs+0outputs (0major+574minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 93%CPU (0avgtext+0avgdata 3576maxresident)k\n0inputs+0outputs (0major+574minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 80%CPU (0avgtext+0avgdata 3720maxresident)k\n0inputs+0outputs (0major+575minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 90%CPU (0avgtext+0avgdata 3724maxresident)k\n0inputs+0outputs (0major+577minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 93%CPU (0avgtext+0avgdata 3708maxresident)k\n0inputs+0outputs (0major+576minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 90%CPU (0avgtext+0avgdata 3728maxresident)k\n0inputs+0outputs (0major+578minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 90%CPU (0avgtext+0avgdata 3664maxresident)k\n0inputs+0outputs (0major+571minor)pagefaults 0swaps\n0.02user 0.00system 0:00.03elapsed 90%CPU (0avgtext+0avgdata 3668maxresident)k\n0inputs+0outputs (0major+575minor)pagefaults 0swaps\n[...]\n\nOTOH, it looks like the Apache worker is killing the pwauth child before it's had a chance to do anything at all:\n\n[pid 13021] <... clone resumed> child_stack=NULL, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0x7f17728969d0) = 14222\n[pid 13020] <... wait4 resumed> 0x7ffff3893bac, WNOHANG|WSTOPPED, NULL) = 0\nstrace: Process 14222 attached\n[pid 13020] kill(14222, SIGTERM <unfinished ...>\n\nThe backtrace (breakpointed on apr_proc_kill()) shows:\n\n#0  apr_proc_kill (proc=0x7fffdc6faac0, signum=signum@entry=15)\n    at ./threadproc/unix/signals.c:36\n#1  0x00007ffff7725e0b in free_proc_chain (procs=0x7fffdbe2f068)\n    at ./memory/unix/apr_pools.c:2464\n#2  0x00007ffff7726b90 in apr_pool_destroy (pool=0x7fffdbe30028)\n    at ./memory/unix/apr_pools.c:817\n#3  0x00007ffff3e35f0c in h2_blist_cleanup (bl=bl@entry=0x7fffec21d2a8)\n    at h2_bucket_beam.c:400\n#4  0x00007ffff3e35ff7 in beam_send_cleanup (data=0x7fffec21d278) at h2_bucket_beam.c:455\n#5  0x00007ffff7726b36 in run_cleanups (cref=0x7fffdbe36098)\n    at ./memory/unix/apr_pools.c:2352\n#6  apr_pool_destroy (pool=0x7fffdbe36028) at ./memory/unix/apr_pools.c:804\n#7  0x00007ffff3e41246 in task_destroy (m=0x7fffec2252d0, task=0x7fffdbe320a0,\n    called_from_master=<optimized out>) at h2_mplx.c:394\n#8  0x00007ffff3e41460 in stream_done (m=m@entry=0x7fffec2252d0,\n    stream=stream@entry=0x7fffec21d0a0, rst_error=0) at h2_mplx.c:460\n#9  0x00007ffff3e4279d in h2_mplx_stream_done (m=0x7fffec2252d0,\n    stream=stream@entry=0x7fffec21d0a0) at h2_mplx.c:654\n#10 0x00007ffff3e4a057 in h2_session_stream_done (session=0x7fffec2250a0,\n    stream=0x7fffec21d0a0) at h2_session.c:85\n#11 0x00005555555a5ce6 in remove_empty_buckets (bb=bb@entry=0x7ffff7e088c0)\n    at core_filters.c:720\n#12 0x00005555555a6112 in send_brigade_nonblocking (s=s@entry=0x7ffff7e080a0,\n    bb=bb@entry=0x7ffff7e088c0, bytes_written=bytes_written@entry=0x7fffec22f318,\n    c=c@entry=0x7ffff7e08290) at core_filters.c:710\n#13 0x00005555555a6e41 in send_brigade_blocking (c=0x7ffff7e08290,\n    bytes_written=0x7fffec22f318, bb=0x7ffff7e088c0, s=0x7ffff7e080a0)\n    at core_filters.c:733\n#14 ap_core_output_filter (f=0x7fffec22f148, new_bb=0x7ffff7e088c0) at core_filters.c:542\n#15 0x00007fffed751c23 in ssl_io_filter_output (f=0x7ffff7e08878, bb=0x7fffec22f3c8)\n    at ssl_engine_io.c:1716\n#16 0x00007fffed74edce in ssl_io_filter_coalesce (f=0x7ffff7e08850, bb=0x7fffec22f3c8)\n    at ssl_engine_io.c:1663\n#17 0x00007ffff3e3a58c in pass_output (io=io@entry=0x7fffec2250e8, flush=flush@entry=1,\n    session_eoc=session_eoc@entry=0x0) at h2_conn_io.c:296\n#18 0x00007ffff3e3aa5c in h2_conn_io_flush (io=io@entry=0x7fffec2250e8)\n    at h2_conn_io.c:327\n#19 0x00007ffff3e4a4aa in h2_session_ev_no_io (msg=0x0, arg=0, session=0x7fffec2250a0)\n    at h2_session.c:1840\n#20 dispatch_event (session=session@entry=0x7fffec2250a0,\n    ev=ev@entry=H2_SESSION_EV_NO_IO, arg=arg@entry=0, msg=msg@entry=0x0)\n    at h2_session.c:1993\n#21 0x00007ffff3e4e125 in h2_session_process (session=0x7fffec2250a0,\n    async=async@entry=0) at h2_session.c:2239\n#22 0x00007ffff3e39aca in h2_conn_run (ctx=ctx@entry=0x7fffec22f2d0,\n    c=c@entry=0x7ffff7e08290) at h2_conn.c:212\n#23 0x00007ffff3e3f9fb in h2_h2_process_conn (c=0x7ffff7e08290) at h2_h2.c:658\n#24 0x00005555555b54f0 in ap_run_process_connection (c=c@entry=0x7ffff7e08290)\n    at connection.c:42\n#25 0x00005555555b5a40 in ap_process_connection (c=c@entry=0x7ffff7e08290,\n    csd=<optimized out>) at connection.c:226\n#26 0x00007ffff2f236bf in child_main (child_num_arg=child_num_arg@entry=0,\n    child_bucket=child_bucket@entry=0) at prefork.c:723\n#27 0x00007ffff2f238f2 in make_child (s=0x7ffff7fbf4a0, slot=slot@entry=0,\n    bucket=bucket@entry=0) at prefork.c:767\n#28 0x00007ffff2f24e37 in prefork_run (_pconf=<optimized out>, plog=0x7ffff7fbc028,\n    s=0x7ffff7fbf4a0) at prefork.c:979\n#29 0x000055555558edde in ap_run_mpm (pconf=0x7ffff7fed028, plog=0x7ffff7fbc028,\n    s=0x7ffff7fbf4a0) at mpm_common.c:94\n#30 0x0000555555587a1d in main (argc=<optimized out>, argv=<optimized out>) at main.c:783\n\n(gdb) print *proc\n$2 = {pid = 8950, in = 0x7fffdbe24d60, out = 0x0, err = 0x0}\n\nPID 8950 is indeed pwauth:\n\nroot          8950  8950  0.0  0.0      0     0 pts/1 Z    -            17:31 [pwauth] <defunct>\n\nI don't know enough about the Apache 2.4 process model to say much more. It looks like each prefork worker now has two threads. In this case, one of the worker's threads clone()s to prepare the child process, but it's the worker's *other* thread that kills the child process immediately.\n\nHow can I help debug this further?", "bug_id": 59237, "attachment_id": null, "id": 199223, "time": "2017-06-15T21:52:40Z", "creator": "jwm@horde.net", "creation_time": "2017-06-15T21:52:40Z", "tags": [], "is_private": false}]