[{"count": 0, "tags": [], "text": "DOCParser class: \n\npackage resumecrawler.utils.parser;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.io.StringWriter;\nimport java.util.logging.Level;\nimport java.util.logging.Logger;\nimport org.apache.lucene.document.Document;\nimport org.apache.lucene.document.Field;\nimport org.apache.poi.hdf.extractor.WordDocument;\n\n/**\n *\n * @author solaris\n */\npublic class DOCParser implements Parser {\n    File file = null;\n    \n    public DOCParser(File f) {\n        file = f;\n    }\n    \n    public DOCParser(String file) {\n        this.file = new File(file);\n    }\n    \n    public void parse(String fieldName, Document doc) {\n        String content = \"\";\n        try {            \n            WordDocument wd = new WordDocument(file.toString());\n            StringWriter docTextWriter = new StringWriter();\n            wd.writeAllText(new PrintWriter(docTextWriter));\n            docTextWriter.close();\n            content = docTextWriter.toString();            \n        } catch (IOException ex) {\n            Logger.getLogger(PDFParser.class.getName()).log(Level.SEVERE, null, ex);\n        } \n        doc.add(new Field(fieldName, content, Field.Store.YES, Field.Index.TOKENIZED));\n    }\n}\n\nError stack trace:\nException in thread \"main\" java.lang.NegativeArraySizeException\n        at org.apache.poi.hdf.extractor.data.ListTables.createLVL(ListTables.java:171)\n        at org.apache.poi.hdf.extractor.data.ListTables.initLFO(ListTables.java:149)\n        at org.apache.poi.hdf.extractor.data.ListTables.<init>(ListTables.java:43)\n        at org.apache.poi.hdf.extractor.WordDocument.createListTables(WordDocument.java:1640)\n        at org.apache.poi.hdf.extractor.WordDocument.findFormatting(WordDocument.java:365)\n        at org.apache.poi.hdf.extractor.WordDocument.processComplexFile(WordDocument.java:292)\n        at org.apache.poi.hdf.extractor.WordDocument.readFIB(WordDocument.java:244)\n        at org.apache.poi.hdf.extractor.WordDocument.<init>(WordDocument.java:194)\n        at org.apache.poi.hdf.extractor.WordDocument.<init>(WordDocument.java:183)\n        at resumecrawler.utils.parser.DOCParser.parse(DOCParser.java:37)\n.......\n\nfile.toString() returns something like this: /home/solaris/crawler/StoreDocuments/9cbb0d2ab441c5a900b7e072915ba298.doc", "attachment_id": null, "id": 117775, "creator": "maksimov.andrei@gmail.com", "time": "2008-06-17T14:47:05Z", "bug_id": 45223, "creation_time": "2008-06-17T14:47:05Z", "is_private": false}, {"count": 1, "tags": [], "bug_id": 45223, "attachment_id": null, "is_private": false, "id": 117810, "time": "2008-06-19T04:43:01Z", "creator": "apache@gagravarr.org", "creation_time": "2008-06-19T04:43:01Z", "text": "You're likely to have much more luck with hwpf than with hdf, hdf is unsupported\n\nFor word text extracting, try org.apache.poi.hwpf.extractor.WordExtractor -\nhttp://poi.apache.org/apidocs/org/apache/poi/hwpf/extractor/WordExtractor.html"}]