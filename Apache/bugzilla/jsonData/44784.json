[{"count": 0, "tags": [], "creator": "robert.rees@thoughtworks.com", "attachment_id": null, "is_private": false, "id": 115455, "time": "2008-04-09T03:36:32Z", "bug_id": 44784, "creation_time": "2008-04-09T03:36:32Z", "text": "I was using the Web Proxy to capture a transaction on a website that was sending malformed ContentType in the response. The content type was of the format: charset=x;charset=x.\n\nAfter extraction the store of the sample failed showing a 503 error on the browser and a UnsupportedEncoding exception in the log (the encoding being passed to the String constructor being of the form \"x;charset=x\").\n\nLooking into the error I saw that the problem was occurring in the Proxy.getContentEncoding method. I also noticed that there were three getContentEncoding methods at different levels (document, etc) all of which use slightly different versions of the indexOf followed by substring index strategy for extraction.\n\nI solved my problem by using the regexp below and defaulting to the platform encoding if the expression does not match.\n\nPattern p = Pattern.compile(\"charset=([\\\\d\\\\w-]+)\");\n\nThis simply extracted the first sequence in the charset.\n\nI think the Proxy needs to be more forgiving in its parsing of the Content-Type and if it is malformed use a sensible default as browsers do. I also think that the Content Type extractor should check whether the coding extracted is actually one supported by the Java platform that is running JMeter. It is easier to debug if the failure occurs closer to the source of the problem instead of failing on the store of the Sampler.\n\nThis problem occurred on an SVN tip build of 28th of March and is still occurring as far as I know."}, {"count": 1, "tags": [], "text": "According to\n\nhttp://www.iana.org/assignments/character-sets\n\ncharset names may be up to 40 characters of the US-ASCII character set, which would include \";\" and space, tab etc.\n\nThe document cited above lists some charset formal names which also include \".\" and \"-\".\n\nUnless you can find a formal definition of the allowable characters for a charset, I think it would be safest to assume only that \";\" is not allowed.\n\nThis is what has been fixed in SVN in \n\nhttp://svn.apache.org/viewvc?rev=648909&view=rev\nhttp://svn.apache.org/viewvc?rev=648910&view=rev\nhttp://svn.apache.org/viewvc?rev=648916&view=rev\n", "attachment_id": null, "bug_id": 44784, "id": 115654, "time": "2008-04-16T18:33:40Z", "creator": "sebb@apache.org", "creation_time": "2008-04-16T18:33:40Z", "is_private": false}, {"count": 2, "tags": [], "text": "(In reply to comment #1)\n> According to\n> \n> http://www.iana.org/assignments/character-sets\n\n> Unless you can find a formal definition of the allowable characters for a\n> charset, I think it would be safest to assume only that \";\" is not allowed.\n\nI'm happy with this as a solution for the extraction. The refactor to a Helper class makes it easier to read the code too.\n\nBut if the server specifies a charset that the JVM doesn't support you will still get an invalid captured sampler. I think that the new conversion method should check Charset.isSupported on the captured charset and if the answer is false return Charset.defaultCharset().name().\n\nThat way getEncodingFromContentType will always return a valid encoding for the platform. ", "is_private": false, "id": 115804, "creation_time": "2008-04-23T08:22:15Z", "time": "2008-04-23T08:22:15Z", "creator": "robert.rees@thoughtworks.com", "bug_id": 44784, "attachment_id": null}, {"count": 3, "text": "OK, added check for unsupported Charset:\n\nhttp://svn.apache.org/viewvc?rev=650928&view=rev", "bug_id": 44784, "is_private": false, "id": 115807, "time": "2008-04-23T09:13:25Z", "creator": "sebb@apache.org", "creation_time": "2008-04-23T09:13:25Z", "tags": [], "attachment_id": null}]