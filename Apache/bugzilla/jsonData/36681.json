[{"count": 0, "tags": [], "bug_id": 36681, "is_private": false, "text": "I have a Remedy webservice running on a cluster of 2 physical tomcat 5.5.7 \nservers using multi-cast broadcast replicating sessions.  The servers on a \nweekly bases come to a grinding hault and randomly generate errors of missing \nreplication states with each other.  Below are the errors on tomcat 1 and \ntomcat 2.\n\nTomcat 1\nAppendedText:\n        at com.remedy.arsys.api.Proxy.ARGetListActiveLink(Native Method)\n        at com.remedy.arsys.api.ActiveLinkFactory.find\n(ActiveLinkFactory.java:103)\n        at com.remedy.arsys.goat.ActiveLinkCollector.<init>(Unknown Source)\n        at com.remedy.arsys.goat.FieldGraph.getJSData(Unknown Source)\n        at com.remedy.arsys.goat.FieldGraph.transmitJS(Unknown Source)\n        at com.remedy.arsys.stubs.FormServlet.doRequest(Unknown Source)\n        at com.remedy.arsys.stubs.GoatServlet.postInternal(Unknown Source)\n        at com.remedy.arsys.stubs.GoatHttpServlet.doGet(Unknown Source)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter\n(ApplicationFilterChain.java:252)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter\n(ApplicationFilterChain.java:173)\n        at org.apache.catalina.core.StandardWrapperValve.invoke\n(StandardWrapperValve.java:214)\n        at org.apache.catalina.core.StandardContextValve.invoke\n(StandardContextValve.java:178)\n        at org.apache.catalina.core.StandardHostValve.invoke\n(StandardHostValve.java:126)\n        at org.apache.catalina.cluster.tcp.ReplicationValve.invoke\n(ReplicationValve.java:130)\n        at org.apache.catalina.valves.ErrorReportValve.invoke\n(ErrorReportValve.java:105)\n        at org.apache.catalina.core.StandardEngineValve.invoke\n(StandardEngineValve.java:107)\n        at org.apache.catalina.connector.CoyoteAdapter.service\n(CoyoteAdapter.java:148)\n        at org.apache.jk.server.JkCoyoteHandler.invoke(JkCoyoteHandler.java:306)\n        at org.apache.jk.common.HandlerRequest.invoke(HandlerRequest.java:385)\n        at org.apache.jk.common.ChannelSocket.invoke(ChannelSocket.java:745)\n        at org.apache.jk.common.ChannelSocket.processConnection\n(ChannelSocket.java:675)\n        at org.apache.jk.common.SocketConnection.runIt(ChannelSocket.java:868)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run\n(ThreadPool.java:684)\n        at java.lang.Thread.run(Thread.java:595)\nSep 15, 2005 2:23:20 PM org.apache.catalina.cluster.tcp.ReplicationValve \naddClusterSendTime\nINFO: Average request time=138 ms for Cluster overhead time=93 ms for 500 \nrequests (Request=69490ms Cluster=46922ms).\n\n\n\n\nTomcat2\nAppendedText:\n        at com.remedy.arsys.api.Proxy.ARGetListActiveLink(Native Method)\n        at com.remedy.arsys.api.ActiveLinkFactory.find\n(ActiveLinkFactory.java:103)\n        at com.remedy.arsys.goat.ActiveLinkCollector.<init>(Unknown Source)\n        at com.remedy.arsys.goat.FieldGraph.getJSData(Unknown Source)\n        at com.remedy.arsys.goat.FieldGraph.transmitJS(Unknown Source)\n        at com.remedy.arsys.stubs.FormServlet.doRequest(Unknown Source)\n        at com.remedy.arsys.stubs.GoatServlet.postInternal(Unknown Source)\n        at com.remedy.arsys.stubs.GoatHttpServlet.doGet(Unknown Source)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)\n        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)\n        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter\n(ApplicationFilterChain.java:252)\n        at org.apache.catalina.core.ApplicationFilterChain.doFilter\n(ApplicationFilterChain.java:173)\n        at org.apache.catalina.core.StandardWrapperValve.invoke\n(StandardWrapperValve.java:214)\n        at org.apache.catalina.core.StandardContextValve.invoke\n(StandardContextValve.java:178)\n        at org.apache.catalina.core.StandardHostValve.invoke\n(StandardHostValve.java:126)\n        at org.apache.catalina.cluster.tcp.ReplicationValve.invoke\n(ReplicationValve.java:130)\n        at org.apache.catalina.valves.ErrorReportValve.invoke\n(ErrorReportValve.java:105)\n        at org.apache.catalina.core.StandardEngineValve.invoke\n(StandardEngineValve.java:107)\n        at org.apache.catalina.connector.CoyoteAdapter.service\n(CoyoteAdapter.java:148)\n        at org.apache.jk.server.JkCoyoteHandler.invoke(JkCoyoteHandler.java:306)\n        at org.apache.jk.common.HandlerRequest.invoke(HandlerRequest.java:385)\n        at org.apache.jk.common.ChannelSocket.invoke(ChannelSocket.java:745)\n        at org.apache.jk.common.ChannelSocket.processConnection\n(ChannelSocket.java:675)\n        at org.apache.jk.common.SocketConnection.runIt(ChannelSocket.java:868)\n        at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run\n(ThreadPool.java:684)\n        at java.lang.Thread.run(Thread.java:595)\nSep 15, 2005 10:42:47 AM org.apache.catalina.cluster.tcp.TcpReplicationThread \nrun\nSEVERE: TCP Worker thread in cluster caught 'java.io.IOException: Connection \nreset by peer' closing channel\njava.io.IOException: Connection reset by peer\n        at sun.nio.ch.FileDispatcher.read0(Native Method)\n        at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:21)\n        at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:233)\n        at sun.nio.ch.IOUtil.read(IOUtil.java:206)\n        at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:207)\n        at org.apache.catalina.cluster.tcp.TcpReplicationThread.drainChannel\n(TcpReplicationThread.java:120)\n        at org.apache.catalina.cluster.tcp.TcpReplicationThread.run\n(TcpReplicationThread.java:64)\nSep 15, 2005 11:01:38 AM org.apache.catalina.cluster.tcp.ReplicationValve \naddClusterSendTime\nINFO: Average request time=331 ms for Cluster overhead time=61 ms for 400 \nrequests (Request=132596ms Cluster=24723ms).\nSep 15, 2005 11:08:15 AM org.apache.catalina.cluster.tcp.SimpleTcpCluster \nmemberDisappeared\nINFO: Received member disappeared:org.apache.catalina.cluster.mcast.McastMember\n[tcp://142.182.90.235:4001,142.182.90.235,4001, alive=86826590]\nSep 15, 2005 11:09:07 AM org.apache.catalina.cluster.tcp.SimpleTcpCluster \nmemberAdded\n\nPlease help, this is becoming critical as I have to have a cronjob monitoring \nthese instances every 2 minutes to restart them just incase they crash.\n\nThanks\n\nZubair", "id": 80026, "time": "2005-09-16T05:30:09Z", "creator": "zubair.shaikh@cgi.com", "creation_time": "2005-09-16T05:30:09Z", "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 36681, "attachment_id": null, "id": 80027, "time": "2005-09-16T08:34:21Z", "creator": "pr@objektpark.de", "creation_time": "2005-09-16T08:34:21Z", "is_private": false, "text": "Hey,\n\nI can't see the problem without your cluster config. PLease report your\nserver.xml, used OS, JVM. Tomcat 5.5.7 clustering is not stable.\nPlease use Tomcat 5.5.9 with my Cluster Fix pack\nBug(http://issues.apache.org/bugzilla/show_bug.cgi?id=34389) and try your \nsituation again.\n\nPeter"}, {"count": 2, "tags": [], "bug_id": 36681, "is_private": false, "text": "Hi Peter,\n\nThank you for your quick reply. Below is my server.xml that you requested for \nboth server 1 and server 2.\n\nTomcat 1\n<!-- Example Server Configuration File -->\n<!-- Note that component elements are nested corresponding to their\n     parent-child relationships with each other -->\n\n<!-- A \"Server\" is a singleton element that represents the entire JVM,\n     which may contain one or more \"Service\" instances.  The Server\n     listens for a shutdown command on the indicated port.\n\n     Note:  A \"Server\" is not itself a \"Container\", so you may not\n     define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n -->\n\n<Server port=\"18005\" shutdown=\"SHUTDOWN\">\n\n  <!-- Comment these entries out to disable JMX MBeans support used for the \n       administration web application -->\n  <Listener className=\"org.apache.catalina.mbeans.ServerLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.storeconfig.StoreConfigLifecycleListener\"/>\n\n  <!-- Global JNDI resources -->\n  <GlobalNamingResources>\n\n    <!-- Test entry for demonstration purposes -->\n    <Environment name=\"simpleValue\" type=\"java.lang.Integer\" value=\"30\"/>\n\n    <!-- Editable user database that can also be used by\n         UserDatabaseRealm to authenticate users -->\n    <Resource name=\"UserDatabase\" auth=\"Container\"\n              type=\"org.apache.catalina.UserDatabase\"\n       description=\"User database that can be updated and saved\"\n           factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\"\n          pathname=\"conf/tomcat-users.xml\" />\n\n  </GlobalNamingResources>\n\n  <!-- A \"Service\" is a collection of one or more \"Connectors\" that share\n       a single \"Container\" (and therefore the web applications visible\n       within that Container).  Normally, that Container is an \"Engine\",\n       but this is not required.\n\n       Note:  A \"Service\" is not itself a \"Container\", so you may not\n       define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n   -->\n\n  <!-- Define the Tomcat Stand-Alone Service -->\n  <Service name=\"Catalina\">\n\n    <!-- A \"Connector\" represents an endpoint by which requests are received\n         and responses are returned.  Each Connector passes requests on to the\n         associated \"Container\" (normally an Engine) for processing.\n\n         By default, a non-SSL HTTP/1.1 Connector is established on port 8080.\n         You can also enable an SSL HTTP/1.1 Connector on port 8443 by\n         following the instructions below and uncommenting the second Connector\n         entry.  SSL support requires the following steps (see the SSL Config\n         HOWTO in the Tomcat 5 documentation bundle for more detailed\n         instructions):\n         * If your JDK version 1.3 or prior, download and install JSSE 1.0.2 or\n           later, and put the JAR files into \"$JAVA_HOME/jre/lib/ext\".\n         * Execute:\n             %JAVA_HOME%\\bin\\keytool -genkey -alias tomcat -keyalg RSA (Windows)\n             $JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA  (Unix)\n           with a password value of \"changeit\" for both the certificate and\n           the keystore itself.\n\n         By default, DNS lookups are enabled when a web application calls\n         request.getRemoteHost().  This can have an adverse impact on\n         performance, so you can disable it by setting the\n         \"enableLookups\" attribute to \"false\".  When DNS lookups are disabled,\n         request.getRemoteHost() will return the String version of the\n         IP address of the remote client.\n    -->\n    <!-- Define a non-SSL HTTP/1.1 Connector on port 8080 -->\n<!--\n    <Connector port=\"8080\"\n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" redirectPort=\"8443\" acceptCount=\"100\"\n               connectionTimeout=\"20000\" disableUploadTimeout=\"true\" />\n-->\n    <!-- Note : To disable connection timeouts, set connectionTimeout value\n     to 0 -->\n\t\n\t<!-- Note : To use gzip compression you could set the following \nproperties :\n\t\n\t\t\t   compression=\"on\" \n\t\t\t   compressionMinSize=\"2048\" \n\t\t\t   noCompressionUserAgents=\"gozilla, traviata\" \n\t\t\t   compressableMimeType=\"text/html,text/xml\"\n\t-->\n\n    <!-- Define a SSL HTTP/1.1 Connector on port 8443 -->\n    <!--\n    <Connector port=\"8443\" \n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" disableUploadTimeout=\"true\"\n               acceptCount=\"100\" scheme=\"https\" secure=\"true\"\n               clientAuth=\"false\" sslProtocol=\"TLS\" />\n    -->\n\n    <!-- Define an AJP 1.3 Connector on port 18012 -->\n    <Connector address=\"<MY IP-ADDR>\" port=\"18012\" \n               enableLookups=\"false\" redirectPort=\"18443\" protocol=\"AJP/1.3\" \nnumThreads=\"500\" maxThreads=\"500\" minSpareThreads=\"25\" maxSpareThreads=\"75\" />\n\n    <!-- Define a Proxied HTTP/1.1 Connector on port 8082 -->\n    <!-- See proxy documentation for more information about using this. -->\n    <!--\n    <Connector port=\"8082\" \n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" acceptCount=\"100\" connectionTimeout=\"20000\"\n               proxyPort=\"80\" disableUploadTimeout=\"true\" />\n    -->\n\n    <!-- An Engine represents the entry point (within Catalina) that processes\n         every request.  The Engine implementation for Tomcat stand alone\n         analyzes the HTTP headers included with the request, and passes them\n         on to the appropriate Host (virtual host). -->\n\n    <!-- You should set jvmRoute to support load-balancing via AJP ie :\n    <Engine name=\"Standalone\" defaultHost=\"localhost\" jvmRoute=\"jvm1\">         \n    --> \n         \n    <!-- Define the top level container in our container hierarchy -->\n    <Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"NetsTomcat3\">\n\n      <!-- The request dumper valve dumps useful debugging information about\n           the request headers and cookies that were received, and the response\n           headers and cookies that were sent, for all requests received by\n           this instance of Tomcat.  If you care only about requests to a\n           particular virtual host, or a particular application, nest this\n           element inside the corresponding <Host> or <Context> entry instead.\n\n           For a similar mechanism that is portable to all Servlet 2.4\n           containers, check out the \"RequestDumperFilter\" Filter in the\n           example application (the source for this filter may be found in\n           \"$CATALINA_HOME/webapps/examples/WEB-INF/classes/filters\").\n\n           Request dumping is disabled by default.  Uncomment the following\n           element to enable it. -->\n      <!--\n      <Valve className=\"org.apache.catalina.valves.RequestDumperValve\"/>\n      -->\n\n      <!-- Because this Realm is here, an instance will be shared globally -->\n\n      <!-- This Realm uses the UserDatabase configured in the global JNDI\n           resources under the key \"UserDatabase\".  Any edits\n           that are performed against this UserDatabase are immediately\n           available for use by the Realm.  -->\n      <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n             resourceName=\"UserDatabase\"/>\n\n      <!-- Comment out the old realm but leave here for now in case we\n           need to go back quickly -->\n      <!--\n      <Realm className=\"org.apache.catalina.realm.MemoryRealm\" />\n      -->\n\n      <!-- Replace the above Realm with one of the following to get a Realm\n           stored in a database and accessed via JDBC -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"org.gjt.mm.mysql.Driver\"\n          connectionURL=\"jdbc:mysql://localhost/authority\"\n         connectionName=\"test\" connectionPassword=\"test\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"oracle.jdbc.driver.OracleDriver\"\n          connectionURL=\"jdbc:oracle:thin:@ntserver:1521:ORCL\"\n         connectionName=\"scott\" connectionPassword=\"tiger\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"sun.jdbc.odbc.JdbcOdbcDriver\"\n          connectionURL=\"jdbc:odbc:CATALINA\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!-- Define the default virtual host\n           Note: XML Schema validation will not work with Xerces 2.2.\n       -->\n      <Host name=\"localhost\" appBase=\"webapps\"\n       unpackWARs=\"true\" autoDeploy=\"true\"\n       xmlValidation=\"false\" xmlNamespaceAware=\"false\">\n\n        <!-- Defines a cluster for this node,\n             By defining this element, means that every manager will be changed.\n             So when running a cluster, only make sure that you have webapps in \nthere\n             that need to be clustered and remove the other ones.\n             A cluster has the following parameters:\n\n             className = the fully qualified name of the cluster class\n\n             name = a descriptive name for your cluster, can be anything\n\n             mcastAddr = the multicast address, has to be the same for all the \nnodes\n\n             mcastPort = the multicast port, has to be the same for all the \nnodes\n             \n             mcastBindAddr = bind the multicast socket to a specific address\n             \n             mcastTTL = the multicast TTL if you want to limit your broadcast\n             \n             mcastSoTimeout = the multicast readtimeout \n\n             mcastFrequency = the number of milliseconds in between sending \na \"I'm alive\" heartbeat\n\n             mcastDropTime = the number a milliseconds before a node is \nconsidered \"dead\" if no heartbeat is received\n\n             tcpThreadCount = the number of threads to handle incoming \nreplication requests, optimal would be the same amount of threads as nodes \n\n             tcpListenAddress = the listen address (bind address) for TCP \ncluster request on this host, \n                                in case of multiple ethernet cards.\n                                auto means that address becomes\n                                InetAddress.getLocalHost().getHostAddress()\n\n             tcpListenPort = the tcp listen port\n\n             tcpSelectorTimeout = the timeout (ms) for the Selector.select() \nmethod in case the OS\n                                  has a wakup bug in java.nio. Set to 0 for no \ntimeout\n\n             printToScreen = true means that managers will also print to std.out\n\n             expireSessionsOnShutdown = true means that \n\n             useDirtyFlag = true means that we only replicate a session after \nsetAttribute,removeAttribute has been called.\n                            false means to replicate the session after each \nrequest.\n                            false means that replication would work for the \nfollowing piece of code: (only for SimpleTcpReplicationManager)\n                            <%\n                            HashMap map = (HashMap)session.getAttribute(\"map\");\n                            map.put(\"key\",\"value\");\n                            %>\n             replicationMode = can be either 'pooled', 'synchronous' \nor 'asynchronous'.\n                               * Pooled means that the replication happens \nusing several sockets in a synchronous way. Ie, the data gets replicated, then \nthe request return. This is the same as the 'synchronous' setting except it \nuses a pool of sockets, hence it is multithreaded. This is the fastest and \nsafest configuration. To use this, also increase the nr of tcp threads that you \nhave dealing with replication.\n                               * Synchronous means that the thread that \nexecutes the request, is also the\n                               thread the replicates the data to the other \nnodes, and will not return until all\n                               nodes have received the information.\n                               * Asynchronous means that there is a \nspecific 'sender' thread for each cluster node,\n                               so the request thread will queue the replication \nrequest into a \"smart\" queue,\n                               and then return to the client.\n                               The \"smart\" queue is a queue where when a \nsession is added to the queue, and the same session\n                               already exists in the queue from a previous \nrequest, that session will be replaced\n                               in the queue instead of replicating two \nrequests. This almost never happens, unless there is a \n                               large network delay.\n        -->             \n        <!--\n            When configuring for clustering, you also add in a valve to catch \nall the requests\n            coming in, at the end of the request, the session may or may not be \nreplicated.\n            A session is replicated if and only if all the conditions are met:\n            1. useDirtyFlag is true or setAttribute or removeAttribute has been \ncalled AND\n            2. a session exists (has been created)\n            3. the request is not trapped by the \"filter\" attribute\n\n            The filter attribute is to filter out requests that could not \nmodify the session,\n            hence we don't replicate the session after the end of this request.\n            The filter is negative, ie, anything you put in the filter, you \nmean to filter out,\n            ie, no replication will be done on requests that match one of the \nfilters.\n            The filter attribute is delimited by ;, so you can't escape out ; \neven if you wanted to.\n\n            filter=\".*\\.gif;.*\\.js;\" means that we will not replicate the \nsession after requests with the URI\n            ending with .gif and .js are intercepted.\n            \n            The deployer element can be used to deploy apps cluster wide.\n            Currently the deployment only deploys/undeploys to working members \nin the cluster\n            so no WARs are copied upons startup of a broken node.\n            The deployer watches a directory (watchDir) for WAR files when \nwatchEnabled=\"true\"\n            When a new war file is added the war gets deployed to the local \ninstance,\n            and then deployed to the other instances in the cluster.\n            When a war file is deleted from the watchDir the war is undeployed \nlocally \n            and cluster wide\n        -->\n        \n        <Cluster className=\"org.apache.catalina.cluster.tcp.SimpleTcpCluster\"\n                 \nmanagerClassName=\"org.apache.catalina.cluster.session.DeltaManager\"\n                 expireSessionsOnShutdown=\"false\"\n                 useDirtyFlag=\"true\"\n                 notifyListenersOnReplication=\"true\">\n\n            <Membership \n                className=\"org.apache.catalina.cluster.mcast.McastService\"\n                mcastAddr=\"228.0.0.4\"\n                mcastPort=\"45564\"\n                mcastFrequency=\"500\"\n                mcastDropTime=\"3000\"\n                mcastBindAddr=\"<MY IP-ADDR>\"/>\n\n            <Receiver \n                className=\"org.apache.catalina.cluster.tcp.ReplicationListener\"\n                tcpListenAddress=\"<MY IP-ADDR>\"\n                tcpListenPort=\"4001\"\n                tcpSelectorTimeout=\"100\"\n                tcpThreadCount=\"6\"/>\n\n            <Sender\n                \nclassName=\"org.apache.catalina.cluster.tcp.ReplicationTransmitter\"\n                replicationMode=\"pooled\"\n                ackTimeout=\"15000\"/>\n\n            <Valve className=\"org.apache.catalina.cluster.tcp.ReplicationValve\"\n                   \nfilter=\".*\\.gif;.*\\.js;.*\\.jpg;.*\\.png;.*\\.htm;.*\\.html;.*\\.css;.*\\.txt;\"/>\n                   \n            <Deployer \nclassName=\"org.apache.catalina.cluster.deploy.FarmWarDeployer\"\n                      tempDir=\"/apps/ar/netsprd2a/tomcat/tmp/war-temp/\"\n                      deployDir=\"/apps/ar/netsprd2a/tomcat/tmp/war-deploy/\"\n                      watchDir=\"/apps/ar/netsprd2a/tomcat/tmp/war-listen/\"\n                      watchEnabled=\"false\"/>\n        </Cluster>\n\n\n\n        <!-- Normally, users must authenticate themselves to each web app\n             individually.  Uncomment the following entry if you would like\n             a user to be authenticated the first time they encounter a\n             resource protected by a security constraint, and then have that\n             user identity maintained across *all* web applications contained\n             in this virtual host. -->\n        <!--\n        <Valve className=\"org.apache.catalina.authenticator.SingleSignOn\" />\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.FastCommonAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n\n             This valve use NIO direct Byte Buffer to asynchornously store the\n             log.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.ByteBufferAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n      </Host>\n\n    </Engine>\n\n  </Service>\n\n</Server>\n\n\n\nTomcat 2\n\n<!-- Example Server Configuration File -->\n<!-- Note that component elements are nested corresponding to their\n     parent-child relationships with each other -->\n\n<!-- A \"Server\" is a singleton element that represents the entire JVM,\n     which may contain one or more \"Service\" instances.  The Server\n     listens for a shutdown command on the indicated port.\n\n     Note:  A \"Server\" is not itself a \"Container\", so you may not\n     define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n -->\n\n<Server port=\"18005\" shutdown=\"SHUTDOWN\">\n\n  <!-- Comment these entries out to disable JMX MBeans support used for the \n       administration web application -->\n  <Listener className=\"org.apache.catalina.mbeans.ServerLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.storeconfig.StoreConfigLifecycleListener\"/>\n\n  <!-- Global JNDI resources -->\n  <GlobalNamingResources>\n\n    <!-- Test entry for demonstration purposes -->\n    <Environment name=\"simpleValue\" type=\"java.lang.Integer\" value=\"30\"/>\n\n    <!-- Editable user database that can also be used by\n         UserDatabaseRealm to authenticate users -->\n    <Resource name=\"UserDatabase\" auth=\"Container\"\n              type=\"org.apache.catalina.UserDatabase\"\n       description=\"User database that can be updated and saved\"\n           factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\"\n          pathname=\"conf/tomcat-users.xml\" />\n\n  </GlobalNamingResources>\n\n  <!-- A \"Service\" is a collection of one or more \"Connectors\" that share\n       a single \"Container\" (and therefore the web applications visible\n       within that Container).  Normally, that Container is an \"Engine\",\n       but this is not required.\n\n       Note:  A \"Service\" is not itself a \"Container\", so you may not\n       define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n   -->\n\n  <!-- Define the Tomcat Stand-Alone Service -->\n  <Service name=\"Catalina\">\n\n    <!-- A \"Connector\" represents an endpoint by which requests are received\n         and responses are returned.  Each Connector passes requests on to the\n         associated \"Container\" (normally an Engine) for processing.\n\n         By default, a non-SSL HTTP/1.1 Connector is established on port 8080.\n         You can also enable an SSL HTTP/1.1 Connector on port 8443 by\n         following the instructions below and uncommenting the second Connector\n         entry.  SSL support requires the following steps (see the SSL Config\n         HOWTO in the Tomcat 5 documentation bundle for more detailed\n         instructions):\n         * If your JDK version 1.3 or prior, download and install JSSE 1.0.2 or\n           later, and put the JAR files into \"$JAVA_HOME/jre/lib/ext\".\n         * Execute:\n             %JAVA_HOME%\\bin\\keytool -genkey -alias tomcat -keyalg RSA (Windows)\n             $JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA  (Unix)\n           with a password value of \"changeit\" for both the certificate and\n           the keystore itself.\n\n         By default, DNS lookups are enabled when a web application calls\n         request.getRemoteHost().  This can have an adverse impact on\n         performance, so you can disable it by setting the\n         \"enableLookups\" attribute to \"false\".  When DNS lookups are disabled,\n         request.getRemoteHost() will return the String version of the\n         IP address of the remote client.\n    -->\n    <!-- Define a non-SSL HTTP/1.1 Connector on port 8080 -->\n<!--\n    <Connector port=\"8080\"\n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" redirectPort=\"8443\" acceptCount=\"100\"\n               connectionTimeout=\"20000\" disableUploadTimeout=\"true\" />\n-->\n    <!-- Note : To disable connection timeouts, set connectionTimeout value\n     to 0 -->\n\t\n\t<!-- Note : To use gzip compression you could set the following \nproperties :\n\t\n\t\t\t   compression=\"on\" \n\t\t\t   compressionMinSize=\"2048\" \n\t\t\t   noCompressionUserAgents=\"gozilla, traviata\" \n\t\t\t   compressableMimeType=\"text/html,text/xml\"\n\t-->\n\n    <!-- Define a SSL HTTP/1.1 Connector on port 8443 -->\n    <!--\n    <Connector port=\"8443\" \n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" disableUploadTimeout=\"true\"\n               acceptCount=\"100\" scheme=\"https\" secure=\"true\"\n               clientAuth=\"false\" sslProtocol=\"TLS\" />\n    -->\n\n    <!-- Define an AJP 1.3 Connector on port 18012 -->\n    <Connector address=\"<MY IP-ADDR>\" port=\"18012\" \n               enableLookups=\"false\" redirectPort=\"18443\" protocol=\"AJP/1.3\" \nnumThreads=\"500\" maxThreads=\"500\" minSpareThreads=\"25\" maxSpareThreads=\"75\" />\n\n    <!-- Define a Proxied HTTP/1.1 Connector on port 8082 -->\n    <!-- See proxy documentation for more information about using this. -->\n    <!--\n    <Connector port=\"8082\" \n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" acceptCount=\"100\" connectionTimeout=\"20000\"\n               proxyPort=\"80\" disableUploadTimeout=\"true\" />\n    -->\n\n    <!-- An Engine represents the entry point (within Catalina) that processes\n         every request.  The Engine implementation for Tomcat stand alone\n         analyzes the HTTP headers included with the request, and passes them\n         on to the appropriate Host (virtual host). -->\n\n    <!-- You should set jvmRoute to support load-balancing via AJP ie :\n    <Engine name=\"Standalone\" defaultHost=\"localhost\" jvmRoute=\"jvm1\">         \n    --> \n         \n    <!-- Define the top level container in our container hierarchy -->\n    <Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"NetsTomcat4\">\n\n      <!-- The request dumper valve dumps useful debugging information about\n           the request headers and cookies that were received, and the response\n           headers and cookies that were sent, for all requests received by\n           this instance of Tomcat.  If you care only about requests to a\n           particular virtual host, or a particular application, nest this\n           element inside the corresponding <Host> or <Context> entry instead.\n\n           For a similar mechanism that is portable to all Servlet 2.4\n           containers, check out the \"RequestDumperFilter\" Filter in the\n           example application (the source for this filter may be found in\n           \"$CATALINA_HOME/webapps/examples/WEB-INF/classes/filters\").\n\n           Request dumping is disabled by default.  Uncomment the following\n           element to enable it. -->\n      <!--\n      <Valve className=\"org.apache.catalina.valves.RequestDumperValve\"/>\n      -->\n\n      <!-- Because this Realm is here, an instance will be shared globally -->\n\n      <!-- This Realm uses the UserDatabase configured in the global JNDI\n           resources under the key \"UserDatabase\".  Any edits\n           that are performed against this UserDatabase are immediately\n           available for use by the Realm.  -->\n      <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n             resourceName=\"UserDatabase\"/>\n\n      <!-- Comment out the old realm but leave here for now in case we\n           need to go back quickly -->\n      <!--\n      <Realm className=\"org.apache.catalina.realm.MemoryRealm\" />\n      -->\n\n      <!-- Replace the above Realm with one of the following to get a Realm\n           stored in a database and accessed via JDBC -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"org.gjt.mm.mysql.Driver\"\n          connectionURL=\"jdbc:mysql://localhost/authority\"\n         connectionName=\"test\" connectionPassword=\"test\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"oracle.jdbc.driver.OracleDriver\"\n          connectionURL=\"jdbc:oracle:thin:@ntserver:1521:ORCL\"\n         connectionName=\"scott\" connectionPassword=\"tiger\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"sun.jdbc.odbc.JdbcOdbcDriver\"\n          connectionURL=\"jdbc:odbc:CATALINA\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!-- Define the default virtual host\n           Note: XML Schema validation will not work with Xerces 2.2.\n       -->\n      <Host name=\"localhost\" appBase=\"webapps\"\n       unpackWARs=\"true\" autoDeploy=\"true\"\n       xmlValidation=\"false\" xmlNamespaceAware=\"false\">\n\n        <!-- Defines a cluster for this node,\n             By defining this element, means that every manager will be changed.\n             So when running a cluster, only make sure that you have webapps in \nthere\n             that need to be clustered and remove the other ones.\n             A cluster has the following parameters:\n\n             className = the fully qualified name of the cluster class\n\n             name = a descriptive name for your cluster, can be anything\n\n             mcastAddr = the multicast address, has to be the same for all the \nnodes\n\n             mcastPort = the multicast port, has to be the same for all the \nnodes\n             \n             mcastBindAddr = bind the multicast socket to a specific address\n             \n             mcastTTL = the multicast TTL if you want to limit your broadcast\n             \n             mcastSoTimeout = the multicast readtimeout \n\n             mcastFrequency = the number of milliseconds in between sending \na \"I'm alive\" heartbeat\n\n             mcastDropTime = the number a milliseconds before a node is \nconsidered \"dead\" if no heartbeat is received\n\n             tcpThreadCount = the number of threads to handle incoming \nreplication requests, optimal would be the same amount of threads as nodes \n\n             tcpListenAddress = the listen address (bind address) for TCP \ncluster request on this host, \n                                in case of multiple ethernet cards.\n                                auto means that address becomes\n                                InetAddress.getLocalHost().getHostAddress()\n\n             tcpListenPort = the tcp listen port\n\n             tcpSelectorTimeout = the timeout (ms) for the Selector.select() \nmethod in case the OS\n                                  has a wakup bug in java.nio. Set to 0 for no \ntimeout\n\n             printToScreen = true means that managers will also print to std.out\n\n             expireSessionsOnShutdown = true means that \n\n             useDirtyFlag = true means that we only replicate a session after \nsetAttribute,removeAttribute has been called.\n                            false means to replicate the session after each \nrequest.\n                            false means that replication would work for the \nfollowing piece of code: (only for SimpleTcpReplicationManager)\n                            <%\n                            HashMap map = (HashMap)session.getAttribute(\"map\");\n                            map.put(\"key\",\"value\");\n                            %>\n             replicationMode = can be either 'pooled', 'synchronous' \nor 'asynchronous'.\n                               * Pooled means that the replication happens \nusing several sockets in a synchronous way. Ie, the data gets replicated, then \nthe request return. This is the same as the 'synchronous' setting except it \nuses a pool of sockets, hence it is multithreaded. This is the fastest and \nsafest configuration. To use this, also increase the nr of tcp threads that you \nhave dealing with replication.\n                               * Synchronous means that the thread that \nexecutes the request, is also the\n                               thread the replicates the data to the other \nnodes, and will not return until all\n                               nodes have received the information.\n                               * Asynchronous means that there is a \nspecific 'sender' thread for each cluster node,\n                               so the request thread will queue the replication \nrequest into a \"smart\" queue,\n                               and then return to the client.\n                               The \"smart\" queue is a queue where when a \nsession is added to the queue, and the same session\n                               already exists in the queue from a previous \nrequest, that session will be replaced\n                               in the queue instead of replicating two \nrequests. This almost never happens, unless there is a \n                               large network delay.\n        -->             \n        <!--\n            When configuring for clustering, you also add in a valve to catch \nall the requests\n            coming in, at the end of the request, the session may or may not be \nreplicated.\n            A session is replicated if and only if all the conditions are met:\n            1. useDirtyFlag is true or setAttribute or removeAttribute has been \ncalled AND\n            2. a session exists (has been created)\n            3. the request is not trapped by the \"filter\" attribute\n\n            The filter attribute is to filter out requests that could not \nmodify the session,\n            hence we don't replicate the session after the end of this request.\n            The filter is negative, ie, anything you put in the filter, you \nmean to filter out,\n            ie, no replication will be done on requests that match one of the \nfilters.\n            The filter attribute is delimited by ;, so you can't escape out ; \neven if you wanted to.\n\n            filter=\".*\\.gif;.*\\.js;\" means that we will not replicate the \nsession after requests with the URI\n            ending with .gif and .js are intercepted.\n            \n            The deployer element can be used to deploy apps cluster wide.\n            Currently the deployment only deploys/undeploys to working members \nin the cluster\n            so no WARs are copied upons startup of a broken node.\n            The deployer watches a directory (watchDir) for WAR files when \nwatchEnabled=\"true\"\n            When a new war file is added the war gets deployed to the local \ninstance,\n            and then deployed to the other instances in the cluster.\n            When a war file is deleted from the watchDir the war is undeployed \nlocally \n            and cluster wide\n        -->\n        \n        <Cluster className=\"org.apache.catalina.cluster.tcp.SimpleTcpCluster\"\n                 \nmanagerClassName=\"org.apache.catalina.cluster.session.DeltaManager\"\n                 expireSessionsOnShutdown=\"false\"\n                 useDirtyFlag=\"true\"\n                 notifyListenersOnReplication=\"true\">\n\n            <Membership \n                className=\"org.apache.catalina.cluster.mcast.McastService\"\n                mcastAddr=\"228.0.0.4\"\n                mcastPort=\"45564\"\n                mcastFrequency=\"500\"\n                mcastDropTime=\"3000\"\n                mcastBindAddr=\"<MY IP-ADDR>\"/>\n\n            <Receiver \n                className=\"org.apache.catalina.cluster.tcp.ReplicationListener\"\n                tcpListenAddress=\"<MY IP-ADDR>\"\n                tcpListenPort=\"4001\"\n                tcpSelectorTimeout=\"100\"\n                tcpThreadCount=\"6\"/>\n\n            <Sender\n                \nclassName=\"org.apache.catalina.cluster.tcp.ReplicationTransmitter\"\n                replicationMode=\"pooled\"\n                ackTimeout=\"15000\"/>\n\n            <Valve className=\"org.apache.catalina.cluster.tcp.ReplicationValve\"\n                   \nfilter=\".*\\.gif;.*\\.js;.*\\.jpg;.*\\.png;.*\\.htm;.*\\.html;.*\\.css;.*\\.txt;\"/>\n                   \n            <Deployer \nclassName=\"org.apache.catalina.cluster.deploy.FarmWarDeployer\"\n                      tempDir=\"/apps/ar/netsprd2b/tomcat/tmp/war-temp/\"\n                      deployDir=\"/apps/ar/netsprd2b/tomcat/tmp/war-deploy/\"\n                      watchDir=\"/apps/ar/netsprd2b/tomcat/tmp/war-listen/\"\n                      watchEnabled=\"false\"/>\n        </Cluster>\n\n\n\n        <!-- Normally, users must authenticate themselves to each web app\n             individually.  Uncomment the following entry if you would like\n             a user to be authenticated the first time they encounter a\n             resource protected by a security constraint, and then have that\n             user identity maintained across *all* web applications contained\n             in this virtual host. -->\n        <!--\n        <Valve className=\"org.apache.catalina.authenticator.SingleSignOn\" />\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.FastCommonAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n\n             This valve use NIO direct Byte Buffer to asynchornously store the\n             log.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.ByteBufferAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n      </Host>\n\n    </Engine>\n\n  </Service>\n\n</Server>\n\nHope this helps you out.  I will however in the mean time take your advice and \ninstall Tomcat 5.5.9 on a dev env't and do cluster testing before I deploy on \nProduction.  Let me know if we can tweak the above.  Thanks\n\nZubair\n", "id": 80043, "time": "2005-09-16T18:18:17Z", "creator": "zubair.shaikh@cgi.com", "creation_time": "2005-09-16T18:18:17Z", "attachment_id": null}, {"count": 3, "tags": [], "creator": "rainer.jung@kippdata.de", "attachment_id": null, "text": "Since one of the messages is \"member disappeared\": If you use a big heap size,\nmake sure you activate verbose logging of GC to check, if you have full GCs\nlasting longer than your heartbeat timeout of 3 seconds. In that case, increase\nyour heartbeat timeout or optimize GC duration.", "id": 80047, "time": "2005-09-16T20:57:28Z", "bug_id": 36681, "creation_time": "2005-09-16T20:57:28Z", "is_private": false}, {"count": 4, "tags": [], "bug_id": 36681, "is_private": false, "text": "Be careful when upgrading to 5.5.9 and the cluster fix pak from bug 34389. I see\nthat you are using pooled cluster replication which appears to be broken. (see\nBug 36540) I didn't test that config, but the 5.5.11 release though. But that\nrelease uses the fix pak, too.", "id": 80051, "time": "2005-09-16T22:46:35Z", "creator": "bachhube@fmi.uni-passau.de", "creation_time": "2005-09-16T22:46:35Z", "attachment_id": null}, {"text": "I think use 5.5.9 with fix pack with greater mcastDropTime (30 sec). At\nproduction server you can't really use the farm deployer.\nPersonally I use only the fastasyncqueue sender mode for production server,\nwithout waitAck and no message compression.\n\n              <Receiver                  \nclassName=\"org.apache.catalina.cluster.tcp.ReplicationListener\"\n                  tcpListenAddress=\"auto\"\n                  tcpListenPort=\"@node.clustertcp.port@\"\n                  tcpSelectorTimeout=\"100\"\n                  tcpThreadCount=\"6\"\n                  compress=\"false\" />\n             <Sender\n                  className=\"org.apache.catalina.cluster.tcp.ReplicationTransmitter\"\n                  replicationMode=\"fastasyncqueue\"\n                  compress=\"false\"\n                  doProcessingStats=\"true\"\n                  queueTimeWait=\"true\"\n                  waitForAck=\"false\"\n                  autoConnect=\"false\"\n                  keepAliveTimeout=\"360000\"\n                  keepAliveMaxRequestCount=\"-1\"/>\n\nCan you please test your configuration, with greater mcastDropTime and report\nthe results?\n\nPeter\n\nPS:5.5.11 and more has a lot of usefull changes, but currently this release is \na good alpha.\nPPS: The Bug 36540 is invalid: We don't support clustering without sticky session.\n", "tags": [], "bug_id": 36681, "attachment_id": null, "count": 5, "id": 80088, "time": "2005-09-18T10:49:03Z", "creator": "pr@objektpark.de", "creation_time": "2005-09-18T10:49:03Z", "is_private": false}, {"count": 6, "tags": [], "bug_id": 36681, "attachment_id": null, "id": 80197, "time": "2005-09-20T18:29:51Z", "creator": "zubair.shaikh@cgi.com", "creation_time": "2005-09-20T18:29:51Z", "is_private": false, "text": "Hello Peter,\n\nI have implemented tomcat559 with cluster fix by putting the cluster fix \nbinaries under the server/classes directory on 2 machines.  Below are the \nserver.xml's for tomcat1 and tomcat2.  I am getting the error message on both \nTOMCAT1 and TOMCAT2 \"Sep 20, 2005 12:04:36 PM \norg.apache.catalina.cluster.session.DeltaManager start\nINFO: Manager [/arsys]: skipping state transfer. No members active in cluster \ngroup.\" eventhough the session sharing is configured.  Below are server.xml for \nboth TOMCAT1 and TOMCAT2\n\nTOMCAT1\n<!-- Example Server Configuration File -->\n<!-- Note that component elements are nested corresponding to their\n     parent-child relationships with each other -->\n\n<!-- A \"Server\" is a singleton element that represents the entire JVM,\n     which may contain one or more \"Service\" instances.  The Server\n     listens for a shutdown command on the indicated port.\n\n     Note:  A \"Server\" is not itself a \"Container\", so you may not\n     define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n -->\n\n<Server port=\"18015\" shutdown=\"SHUTDOWN\">\n\n  <!-- Comment these entries out to disable JMX MBeans support used for the \n       administration web application -->\n  <Listener className=\"org.apache.catalina.mbeans.ServerLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.storeconfig.StoreConfigLifecycleListener\"/>\n\n  <!-- Global JNDI resources -->\n  <GlobalNamingResources>\n\n    <!-- Test entry for demonstration purposes -->\n    <Environment name=\"simpleValue\" type=\"java.lang.Integer\" value=\"30\"/>\n\n    <!-- Editable user database that can also be used by\n         UserDatabaseRealm to authenticate users -->\n    <Resource name=\"UserDatabase\" auth=\"Container\"\n              type=\"org.apache.catalina.UserDatabase\"\n       description=\"User database that can be updated and saved\"\n           factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\"\n          pathname=\"conf/tomcat-users.xml\" />\n\n  </GlobalNamingResources>\n\n  <!-- A \"Service\" is a collection of one or more \"Connectors\" that share\n       a single \"Container\" (and therefore the web applications visible\n       within that Container).  Normally, that Container is an \"Engine\",\n       but this is not required.\n\n       Note:  A \"Service\" is not itself a \"Container\", so you may not\n       define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n   -->\n\n  <!-- Define the Tomcat Stand-Alone Service -->\n  <Service name=\"Catalina\">\n\n    <!-- A \"Connector\" represents an endpoint by which requests are received\n         and responses are returned.  Each Connector passes requests on to the\n         associated \"Container\" (normally an Engine) for processing.\n\n         By default, a non-SSL HTTP/1.1 Connector is established on port 8080.\n         You can also enable an SSL HTTP/1.1 Connector on port 8443 by\n         following the instructions below and uncommenting the second Connector\n         entry.  SSL support requires the following steps (see the SSL Config\n         HOWTO in the Tomcat 5 documentation bundle for more detailed\n         instructions):\n         * If your JDK version 1.3 or prior, download and install JSSE 1.0.2 or\n           later, and put the JAR files into \"$JAVA_HOME/jre/lib/ext\".\n         * Execute:\n             %JAVA_HOME%\\bin\\keytool -genkey -alias tomcat -keyalg RSA (Windows)\n             $JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA  (Unix)\n           with a password value of \"changeit\" for both the certificate and\n           the keystore itself.\n\n         By default, DNS lookups are enabled when a web application calls\n         request.getRemoteHost().  This can have an adverse impact on\n         performance, so you can disable it by setting the\n         \"enableLookups\" attribute to \"false\".  When DNS lookups are disabled,\n         request.getRemoteHost() will return the String version of the\n         IP address of the remote client.\n    -->\n\n    <!-- Define a non-SSL HTTP/1.1 Connector on port 8080 -->\n    <!-- Connector port=\"8080\" maxHttpHeaderSize=\"8192\"\n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" redirectPort=\"8443\" acceptCount=\"100\"\n               connectionTimeout=\"20000\" disableUploadTimeout=\"true\" />\n-->\n    <!-- Note : To disable connection timeouts, set connectionTimeout value\n     to 0 -->\n\t\n\t<!-- Note : To use gzip compression you could set the following \nproperties :\n\t\n\t\t\t   compression=\"on\" \n\t\t\t   compressionMinSize=\"2048\" \n\t\t\t   noCompressionUserAgents=\"gozilla, traviata\" \n\t\t\t   compressableMimeType=\"text/html,text/xml\"\n\t-->\n\n    <!-- Define a SSL HTTP/1.1 Connector on port 8443 -->\n    <!--\n    <Connector port=\"8443\" maxHttpHeaderSize=\"8192\"\n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" disableUploadTimeout=\"true\"\n               acceptCount=\"100\" scheme=\"https\" secure=\"true\"\n               clientAuth=\"false\" sslProtocol=\"TLS\" />\n    -->\n\n    <!-- Define an AJP 1.3 Connector on port 18012 -->\n<Connector address=\"<MY-IP-server1>\" port=\"18012\" \n              enableLookups=\"false\" redirectPort=\"18443\" protocol=\"AJP/1.3\" \nnumThreads=\"500\" maxThreads=\"500\" minSpareThreads=\"25\" maxSpareThreads=\"75\" />\n\n    <!-- Define a Proxied HTTP/1.1 Connector on port 8082 -->\n    <!-- See proxy documentation for more information about using this. -->\n    <!--\n    <Connector port=\"8082\" \n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" acceptCount=\"100\" connectionTimeout=\"20000\"\n               proxyPort=\"80\" disableUploadTimeout=\"true\" />\n    -->\n\n    <!-- An Engine represents the entry point (within Catalina) that processes\n         every request.  The Engine implementation for Tomcat stand alone\n         analyzes the HTTP headers included with the request, and passes them\n         on to the appropriate Host (virtual host). -->\n\n    <!-- You should set jvmRoute to support load-balancing via AJP ie :\n    <Engine name=\"Standalone\" defaultHost=\"localhost\" jvmRoute=\"jvm1\">         \n    --> \n         \n    <!-- Define the top level container in our container hierarchy -->\n    <Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"RemedyTomcat1\">\n\n      <!-- The request dumper valve dumps useful debugging information about\n           the request headers and cookies that were received, and the response\n           headers and cookies that were sent, for all requests received by\n           this instance of Tomcat.  If you care only about requests to a\n           particular virtual host, or a particular application, nest this\n           element inside the corresponding <Host> or <Context> entry instead.\n\n           For a similar mechanism that is portable to all Servlet 2.4\n           containers, check out the \"RequestDumperFilter\" Filter in the\n           example application (the source for this filter may be found in\n           \"$CATALINA_HOME/webapps/examples/WEB-INF/classes/filters\").\n\n           Request dumping is disabled by default.  Uncomment the following\n           element to enable it. -->\n      <!--\n      <Valve className=\"org.apache.catalina.valves.RequestDumperValve\"/>\n      -->\n\n      <!-- Because this Realm is here, an instance will be shared globally -->\n\n      <!-- This Realm uses the UserDatabase configured in the global JNDI\n           resources under the key \"UserDatabase\".  Any edits\n           that are performed against this UserDatabase are immediately\n           available for use by the Realm.  -->\n      <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n             resourceName=\"UserDatabase\"/>\n\n      <!-- Comment out the old realm but leave here for now in case we\n           need to go back quickly -->\n      <!--\n      <Realm className=\"org.apache.catalina.realm.MemoryRealm\" />\n      -->\n\n      <!-- Replace the above Realm with one of the following to get a Realm\n           stored in a database and accessed via JDBC -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"org.gjt.mm.mysql.Driver\"\n          connectionURL=\"jdbc:mysql://localhost/authority\"\n         connectionName=\"test\" connectionPassword=\"test\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"oracle.jdbc.driver.OracleDriver\"\n          connectionURL=\"jdbc:oracle:thin:@ntserver:1521:ORCL\"\n         connectionName=\"scott\" connectionPassword=\"tiger\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"sun.jdbc.odbc.JdbcOdbcDriver\"\n          connectionURL=\"jdbc:odbc:CATALINA\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!-- Define the default virtual host\n           Note: XML Schema validation will not work with Xerces 2.2.\n       -->\n      <Host name=\"localhost\" appBase=\"webapps\"\n       unpackWARs=\"true\" autoDeploy=\"true\"\n       xmlValidation=\"false\" xmlNamespaceAware=\"false\">\n\n        <!-- Defines a cluster for this node,\n             By defining this element, means that every manager will be changed.\n             So when running a cluster, only make sure that you have webapps in \nthere\n             that need to be clustered and remove the other ones.\n             A cluster has the following parameters:\n\n             className = the fully qualified name of the cluster class\n\n             name = a descriptive name for your cluster, can be anything\n\n             mcastAddr = the multicast address, has to be the same for all the \nnodes\n\n             mcastPort = the multicast port, has to be the same for all the \nnodes\n             \n             mcastBindAddr = bind the multicast socket to a specific address\n             \n             mcastTTL = the multicast TTL if you want to limit your broadcast\n             \n             mcastSoTimeout = the multicast readtimeout \n\n             mcastFrequency = the number of milliseconds in between sending \na \"I'm alive\" heartbeat\n\n             mcastDropTime = the number a milliseconds before a node is \nconsidered \"dead\" if no heartbeat is received\n\n             tcpThreadCount = the number of threads to handle incoming \nreplication requests, optimal would be the same amount of threads as nodes \n\n             tcpListenAddress = the listen address (bind address) for TCP \ncluster request on this host, \n                                in case of multiple ethernet cards.\n                                auto means that address becomes\n                                InetAddress.getLocalHost().getHostAddress()\n\n             tcpListenPort = the tcp listen port\n\n             tcpSelectorTimeout = the timeout (ms) for the Selector.select() \nmethod in case the OS\n                                  has a wakup bug in java.nio. Set to 0 for no \ntimeout\n\n             printToScreen = true means that managers will also print to std.out\n\n             expireSessionsOnShutdown = true means that \n\n             useDirtyFlag = true means that we only replicate a session after \nsetAttribute,removeAttribute has been called.\n                            false means to replicate the session after each \nrequest.\n                            false means that replication would work for the \nfollowing piece of code: (only for SimpleTcpReplicationManager)\n                            <%\n                            HashMap map = (HashMap)session.getAttribute(\"map\");\n                            map.put(\"key\",\"value\");\n                            %>\n             replicationMode = can be either 'pooled', 'synchronous' \nor 'asynchronous'.\n                               * Pooled means that the replication happens \nusing several sockets in a synchronous way. Ie, the data gets replicated, then \nthe request return. This is the same as the 'synchronous' setting except it \nuses a pool of sockets, hence it is multithreaded. This is the fastest and \nsafest configuration. To use this, also increase the nr of tcp threads that you \nhave dealing with replication.\n                               * Synchronous means that the thread that \nexecutes the request, is also the\n                               thread the replicates the data to the other \nnodes, and will not return until all\n                               nodes have received the information.\n                               * Asynchronous means that there is a \nspecific 'sender' thread for each cluster node,\n                               so the request thread will queue the replication \nrequest into a \"smart\" queue,\n                               and then return to the client.\n                               The \"smart\" queue is a queue where when a \nsession is added to the queue, and the same session\n                               already exists in the queue from a previous \nrequest, that session will be replaced\n                               in the queue instead of replicating two \nrequests. This almost never happens, unless there is a \n                               large network delay.\n        -->             \n        <!--\n            When configuring for clustering, you also add in a valve to catch \nall the requests\n            coming in, at the end of the request, the session may or may not be \nreplicated.\n            A session is replicated if and only if all the conditions are met:\n            1. useDirtyFlag is true or setAttribute or removeAttribute has been \ncalled AND\n            2. a session exists (has been created)\n            3. the request is not trapped by the \"filter\" attribute\n\n            The filter attribute is to filter out requests that could not \nmodify the session,\n            hence we don't replicate the session after the end of this request.\n            The filter is negative, ie, anything you put in the filter, you \nmean to filter out,\n            ie, no replication will be done on requests that match one of the \nfilters.\n            The filter attribute is delimited by ;, so you can't escape out ; \neven if you wanted to.\n\n            filter=\".*\\.gif;.*\\.js;\" means that we will not replicate the \nsession after requests with the URI\n            ending with .gif and .js are intercepted.\n            \n            The deployer element can be used to deploy apps cluster wide.\n            Currently the deployment only deploys/undeploys to working members \nin the cluster\n            so no WARs are copied upons startup of a broken node.\n            The deployer watches a directory (watchDir) for WAR files when \nwatchEnabled=\"true\"\n            When a new war file is added the war gets deployed to the local \ninstance,\n            and then deployed to the other instances in the cluster.\n            When a war file is deleted from the watchDir the war is undeployed \nlocally \n            and cluster wide\n        -->\n        \n        <Cluster className=\"org.apache.catalina.cluster.tcp.SimpleTcpCluster\"\n                 \nmanagerClassName=\"org.apache.catalina.cluster.session.DeltaManager\"\n                 expireSessionsOnShutdown=\"false\"\n                 useDirtyFlag=\"true\"\n                 notifyListenersOnReplication=\"true\">\n\n            <Membership \n                className=\"org.apache.catalina.cluster.mcast.McastService\"\n                mcastAddr=\"228.0.0.3\"\n                mcastPort=\"45564\"\n                mcastFrequency=\"1000\"\n                mcastBindAddr=\"<MY-IP-server1>\"\n                mcastDropTime=\"30000\"/>\n\n            <Receiver \n                className=\"org.apache.catalina.cluster.tcp.ReplicationListener\"\n                tcpListenAddress=\"<MY-IP-server1>\"\n                tcpListenPort=\"4001\"\n                tcpSelectorTimeout=\"100\"\n                tcpThreadCount=\"6\"\n                compress=\"false\"/>\n\n            <Sender\n                  \nclassName=\"org.apache.catalina.cluster.tcp.ReplicationTransmitter\"\n                  replicationMode=\"fastasyncqueue\"\n                  compress=\"false\"\n                  doProcessingStats=\"true\"\n                  queueTimeWait=\"true\"\n                  waitForAck=\"false\"\n                  autoConnect=\"false\"\n                  keepAliveTimeout=\"360000\"\n                  keepAliveMaxRequestCount=\"-1\"/>\n\n            <Valve className=\"org.apache.catalina.cluster.tcp.ReplicationValve\"\n                   \nfilter=\".*\\.gif;.*\\.js;.*\\.jpg;.*\\.png;.*\\.htm;.*\\.html;.*\\.css;.*\\.txt;\"/>\n                   \n            <Deployer \nclassName=\"org.apache.catalina.cluster.deploy.FarmWarDeployer\"\n                      tempDir=\"/tmp/war-temp/\"\n                      deployDir=\"/tmp/war-deploy/\"\n                      watchDir=\"/tmp/war-listen/\"\n                      watchEnabled=\"false\"/>\n        </Cluster>\n\n\n\n        <!-- Normally, users must authenticate themselves to each web app\n             individually.  Uncomment the following entry if you would like\n             a user to be authenticated the first time they encounter a\n             resource protected by a security constraint, and then have that\n             user identity maintained across *all* web applications contained\n             in this virtual host. -->\n        <!--\n        <Valve className=\"org.apache.catalina.authenticator.SingleSignOn\" />\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.FastCommonAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n\n             This valve use NIO direct Byte Buffer to asynchornously store the\n             log.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.ByteBufferAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n      </Host>\n\n    </Engine>\n\n  </Service>\n\n</Server>\n\n\nTOMCAT2\n<!-- Example Server Configuration File -->\n<!-- Note that component elements are nested corresponding to their\n     parent-child relationships with each other -->\n\n<!-- A \"Server\" is a singleton element that represents the entire JVM,\n     which may contain one or more \"Service\" instances.  The Server\n     listens for a shutdown command on the indicated port.\n\n     Note:  A \"Server\" is not itself a \"Container\", so you may not\n     define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n -->\n\n<Server port=\"18015\" shutdown=\"SHUTDOWN\">\n\n  <!-- Comment these entries out to disable JMX MBeans support used for the \n       administration web application -->\n  <Listener className=\"org.apache.catalina.mbeans.ServerLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.mbeans.GlobalResourcesLifecycleListener\" />\n  <Listener \nclassName=\"org.apache.catalina.storeconfig.StoreConfigLifecycleListener\"/>\n\n  <!-- Global JNDI resources -->\n  <GlobalNamingResources>\n\n    <!-- Test entry for demonstration purposes -->\n    <Environment name=\"simpleValue\" type=\"java.lang.Integer\" value=\"30\"/>\n\n    <!-- Editable user database that can also be used by\n         UserDatabaseRealm to authenticate users -->\n    <Resource name=\"UserDatabase\" auth=\"Container\"\n              type=\"org.apache.catalina.UserDatabase\"\n       description=\"User database that can be updated and saved\"\n           factory=\"org.apache.catalina.users.MemoryUserDatabaseFactory\"\n          pathname=\"conf/tomcat-users.xml\" />\n\n  </GlobalNamingResources>\n\n  <!-- A \"Service\" is a collection of one or more \"Connectors\" that share\n       a single \"Container\" (and therefore the web applications visible\n       within that Container).  Normally, that Container is an \"Engine\",\n       but this is not required.\n\n       Note:  A \"Service\" is not itself a \"Container\", so you may not\n       define subcomponents such as \"Valves\" or \"Loggers\" at this level.\n   -->\n\n  <!-- Define the Tomcat Stand-Alone Service -->\n  <Service name=\"Catalina\">\n\n    <!-- A \"Connector\" represents an endpoint by which requests are received\n         and responses are returned.  Each Connector passes requests on to the\n         associated \"Container\" (normally an Engine) for processing.\n\n         By default, a non-SSL HTTP/1.1 Connector is established on port 8080.\n         You can also enable an SSL HTTP/1.1 Connector on port 8443 by\n         following the instructions below and uncommenting the second Connector\n         entry.  SSL support requires the following steps (see the SSL Config\n         HOWTO in the Tomcat 5 documentation bundle for more detailed\n         instructions):\n         * If your JDK version 1.3 or prior, download and install JSSE 1.0.2 or\n           later, and put the JAR files into \"$JAVA_HOME/jre/lib/ext\".\n         * Execute:\n             %JAVA_HOME%\\bin\\keytool -genkey -alias tomcat -keyalg RSA (Windows)\n             $JAVA_HOME/bin/keytool -genkey -alias tomcat -keyalg RSA  (Unix)\n           with a password value of \"changeit\" for both the certificate and\n           the keystore itself.\n\n         By default, DNS lookups are enabled when a web application calls\n         request.getRemoteHost().  This can have an adverse impact on\n         performance, so you can disable it by setting the\n         \"enableLookups\" attribute to \"false\".  When DNS lookups are disabled,\n         request.getRemoteHost() will return the String version of the\n         IP address of the remote client.\n    -->\n\n    <!-- Define a non-SSL HTTP/1.1 Connector on port 8080 -->\n    <!-- Connector port=\"8080\" maxHttpHeaderSize=\"8192\"\n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" redirectPort=\"8443\" acceptCount=\"100\"\n               connectionTimeout=\"20000\" disableUploadTimeout=\"true\" />\n-->\n    <!-- Note : To disable connection timeouts, set connectionTimeout value\n     to 0 -->\n\t\n\t<!-- Note : To use gzip compression you could set the following \nproperties :\n\t\n\t\t\t   compression=\"on\" \n\t\t\t   compressionMinSize=\"2048\" \n\t\t\t   noCompressionUserAgents=\"gozilla, traviata\" \n\t\t\t   compressableMimeType=\"text/html,text/xml\"\n\t-->\n\n    <!-- Define a SSL HTTP/1.1 Connector on port 8443 -->\n    <!--\n    <Connector port=\"8443\" maxHttpHeaderSize=\"8192\"\n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" disableUploadTimeout=\"true\"\n               acceptCount=\"100\" scheme=\"https\" secure=\"true\"\n               clientAuth=\"false\" sslProtocol=\"TLS\" />\n    -->\n\n    <!-- Define an AJP 1.3 Connector on port 18012 -->\n<Connector address=\"<MY-IP-server2>\" port=\"18012\" \n              enableLookups=\"false\" redirectPort=\"18443\" protocol=\"AJP/1.3\" \nnumThreads=\"500\" maxThreads=\"500\" minSpareThreads=\"25\" maxSpareThreads=\"75\" />\n\n    <!-- Define a Proxied HTTP/1.1 Connector on port 8082 -->\n    <!-- See proxy documentation for more information about using this. -->\n    <!--\n    <Connector port=\"8082\" \n               maxThreads=\"150\" minSpareThreads=\"25\" maxSpareThreads=\"75\"\n               enableLookups=\"false\" acceptCount=\"100\" connectionTimeout=\"20000\"\n               proxyPort=\"80\" disableUploadTimeout=\"true\" />\n    -->\n\n    <!-- An Engine represents the entry point (within Catalina) that processes\n         every request.  The Engine implementation for Tomcat stand alone\n         analyzes the HTTP headers included with the request, and passes them\n         on to the appropriate Host (virtual host). -->\n\n    <!-- You should set jvmRoute to support load-balancing via AJP ie :\n    <Engine name=\"Standalone\" defaultHost=\"localhost\" jvmRoute=\"jvm1\">         \n    --> \n         \n    <!-- Define the top level container in our container hierarchy -->\n    <Engine name=\"Catalina\" defaultHost=\"localhost\" jvmRoute=\"RemedyTomcat2\">\n\n      <!-- The request dumper valve dumps useful debugging information about\n           the request headers and cookies that were received, and the response\n           headers and cookies that were sent, for all requests received by\n           this instance of Tomcat.  If you care only about requests to a\n           particular virtual host, or a particular application, nest this\n           element inside the corresponding <Host> or <Context> entry instead.\n\n           For a similar mechanism that is portable to all Servlet 2.4\n           containers, check out the \"RequestDumperFilter\" Filter in the\n           example application (the source for this filter may be found in\n           \"$CATALINA_HOME/webapps/examples/WEB-INF/classes/filters\").\n\n           Request dumping is disabled by default.  Uncomment the following\n           element to enable it. -->\n      <!--\n      <Valve className=\"org.apache.catalina.valves.RequestDumperValve\"/>\n      -->\n\n      <!-- Because this Realm is here, an instance will be shared globally -->\n\n      <!-- This Realm uses the UserDatabase configured in the global JNDI\n           resources under the key \"UserDatabase\".  Any edits\n           that are performed against this UserDatabase are immediately\n           available for use by the Realm.  -->\n      <Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\"\n             resourceName=\"UserDatabase\"/>\n\n      <!-- Comment out the old realm but leave here for now in case we\n           need to go back quickly -->\n      <!--\n      <Realm className=\"org.apache.catalina.realm.MemoryRealm\" />\n      -->\n\n      <!-- Replace the above Realm with one of the following to get a Realm\n           stored in a database and accessed via JDBC -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"org.gjt.mm.mysql.Driver\"\n          connectionURL=\"jdbc:mysql://localhost/authority\"\n         connectionName=\"test\" connectionPassword=\"test\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"oracle.jdbc.driver.OracleDriver\"\n          connectionURL=\"jdbc:oracle:thin:@ntserver:1521:ORCL\"\n         connectionName=\"scott\" connectionPassword=\"tiger\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!--\n      <Realm  className=\"org.apache.catalina.realm.JDBCRealm\"\n             driverName=\"sun.jdbc.odbc.JdbcOdbcDriver\"\n          connectionURL=\"jdbc:odbc:CATALINA\"\n              userTable=\"users\" userNameCol=\"user_name\" userCredCol=\"user_pass\"\n          userRoleTable=\"user_roles\" roleNameCol=\"role_name\" />\n      -->\n\n      <!-- Define the default virtual host\n           Note: XML Schema validation will not work with Xerces 2.2.\n       -->\n      <Host name=\"localhost\" appBase=\"webapps\"\n       unpackWARs=\"true\" autoDeploy=\"true\"\n       xmlValidation=\"false\" xmlNamespaceAware=\"false\">\n\n        <!-- Defines a cluster for this node,\n             By defining this element, means that every manager will be changed.\n             So when running a cluster, only make sure that you have webapps in \nthere\n             that need to be clustered and remove the other ones.\n             A cluster has the following parameters:\n\n             className = the fully qualified name of the cluster class\n\n             name = a descriptive name for your cluster, can be anything\n\n             mcastAddr = the multicast address, has to be the same for all the \nnodes\n\n             mcastPort = the multicast port, has to be the same for all the \nnodes\n             \n             mcastBindAddr = bind the multicast socket to a specific address\n             \n             mcastTTL = the multicast TTL if you want to limit your broadcast\n             \n             mcastSoTimeout = the multicast readtimeout \n\n             mcastFrequency = the number of milliseconds in between sending \na \"I'm alive\" heartbeat\n\n             mcastDropTime = the number a milliseconds before a node is \nconsidered \"dead\" if no heartbeat is received\n\n             tcpThreadCount = the number of threads to handle incoming \nreplication requests, optimal would be the same amount of threads as nodes \n\n             tcpListenAddress = the listen address (bind address) for TCP \ncluster request on this host, \n                                in case of multiple ethernet cards.\n                                auto means that address becomes\n                                InetAddress.getLocalHost().getHostAddress()\n\n             tcpListenPort = the tcp listen port\n\n             tcpSelectorTimeout = the timeout (ms) for the Selector.select() \nmethod in case the OS\n                                  has a wakup bug in java.nio. Set to 0 for no \ntimeout\n\n             printToScreen = true means that managers will also print to std.out\n\n             expireSessionsOnShutdown = true means that \n\n             useDirtyFlag = true means that we only replicate a session after \nsetAttribute,removeAttribute has been called.\n                            false means to replicate the session after each \nrequest.\n                            false means that replication would work for the \nfollowing piece of code: (only for SimpleTcpReplicationManager)\n                            <%\n                            HashMap map = (HashMap)session.getAttribute(\"map\");\n                            map.put(\"key\",\"value\");\n                            %>\n             replicationMode = can be either 'pooled', 'synchronous' \nor 'asynchronous'.\n                               * Pooled means that the replication happens \nusing several sockets in a synchronous way. Ie, the data gets replicated, then \nthe request return. This is the same as the 'synchronous' setting except it \nuses a pool of sockets, hence it is multithreaded. This is the fastest and \nsafest configuration. To use this, also increase the nr of tcp threads that you \nhave dealing with replication.\n                               * Synchronous means that the thread that \nexecutes the request, is also the\n                               thread the replicates the data to the other \nnodes, and will not return until all\n                               nodes have received the information.\n                               * Asynchronous means that there is a \nspecific 'sender' thread for each cluster node,\n                               so the request thread will queue the replication \nrequest into a \"smart\" queue,\n                               and then return to the client.\n                               The \"smart\" queue is a queue where when a \nsession is added to the queue, and the same session\n                               already exists in the queue from a previous \nrequest, that session will be replaced\n                               in the queue instead of replicating two \nrequests. This almost never happens, unless there is a \n                               large network delay.\n        -->             \n        <!--\n            When configuring for clustering, you also add in a valve to catch \nall the requests\n            coming in, at the end of the request, the session may or may not be \nreplicated.\n            A session is replicated if and only if all the conditions are met:\n            1. useDirtyFlag is true or setAttribute or removeAttribute has been \ncalled AND\n            2. a session exists (has been created)\n            3. the request is not trapped by the \"filter\" attribute\n\n            The filter attribute is to filter out requests that could not \nmodify the session,\n            hence we don't replicate the session after the end of this request.\n            The filter is negative, ie, anything you put in the filter, you \nmean to filter out,\n            ie, no replication will be done on requests that match one of the \nfilters.\n            The filter attribute is delimited by ;, so you can't escape out ; \neven if you wanted to.\n\n            filter=\".*\\.gif;.*\\.js;\" means that we will not replicate the \nsession after requests with the URI\n            ending with .gif and .js are intercepted.\n            \n            The deployer element can be used to deploy apps cluster wide.\n            Currently the deployment only deploys/undeploys to working members \nin the cluster\n            so no WARs are copied upons startup of a broken node.\n            The deployer watches a directory (watchDir) for WAR files when \nwatchEnabled=\"true\"\n            When a new war file is added the war gets deployed to the local \ninstance,\n            and then deployed to the other instances in the cluster.\n            When a war file is deleted from the watchDir the war is undeployed \nlocally \n            and cluster wide\n        -->\n        \n        <Cluster className=\"org.apache.catalina.cluster.tcp.SimpleTcpCluster\"\n                 \nmanagerClassName=\"org.apache.catalina.cluster.session.DeltaManager\"\n                 expireSessionsOnShutdown=\"false\"\n                 useDirtyFlag=\"true\"\n                 notifyListenersOnReplication=\"true\">\n\n            <Membership \n                className=\"org.apache.catalina.cluster.mcast.McastService\"\n                mcastAddr=\"228.0.0.3\"\n                mcastPort=\"45564\"\n                mcastFrequency=\"1000\"\n                mcastBindAddr=\"<MY-IP-server2>\"\n                mcastDropTime=\"30000\"/>\n\n            <Receiver \n                className=\"org.apache.catalina.cluster.tcp.ReplicationListener\"\n                tcpListenAddress=\"<MY-IP-server2>\"\n                tcpListenPort=\"4001\"\n                tcpSelectorTimeout=\"100\"\n                tcpThreadCount=\"6\"\n                compress=\"false\"/>\n\n            <Sender\n                  \nclassName=\"org.apache.catalina.cluster.tcp.ReplicationTransmitter\"\n                  replicationMode=\"fastasyncqueue\"\n                  compress=\"false\"\n                  doProcessingStats=\"true\"\n                  queueTimeWait=\"true\"\n                  waitForAck=\"falst\"\n                  autoConnect=\"false\"\n                  keepAliveTimeout=\"360000\"\n                  keepAliveMaxRequestCount=\"-1\"/>\n\n            <Valve className=\"org.apache.catalina.cluster.tcp.ReplicationValve\"\n                   \nfilter=\".*\\.gif;.*\\.js;.*\\.jpg;.*\\.png;.*\\.htm;.*\\.html;.*\\.css;.*\\.txt;\"/>\n                   \n            <Deployer \nclassName=\"org.apache.catalina.cluster.deploy.FarmWarDeployer\"\n                      tempDir=\"/tmp/war-temp/\"\n                      deployDir=\"/tmp/war-deploy/\"\n                      watchDir=\"/tmp/war-listen/\"\n                      watchEnabled=\"false\"/>\n        </Cluster>\n\n\n\n        <!-- Normally, users must authenticate themselves to each web app\n             individually.  Uncomment the following entry if you would like\n             a user to be authenticated the first time they encounter a\n             resource protected by a security constraint, and then have that\n             user identity maintained across *all* web applications contained\n             in this virtual host. -->\n        <!--\n        <Valve className=\"org.apache.catalina.authenticator.SingleSignOn\" />\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.AccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.FastCommonAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n        <!-- Access log processes all requests for this virtual host.  By\n             default, log files are created in the \"logs\" directory relative to\n             $CATALINA_HOME.  If you wish, you can specify a different\n             directory with the \"directory\" attribute.  Specify either a \nrelative\n             (to $CATALINA_HOME) or absolute path to the desired directory.\n             This access log implementation is optimized for maximum \nperformance,\n             but is hardcoded to support only the \"common\" and \"combined\" \npatterns.\n\n             This valve use NIO direct Byte Buffer to asynchornously store the\n             log.\n        -->\n        <!--\n        <Valve className=\"org.apache.catalina.valves.ByteBufferAccessLogValve\"\n                 directory=\"logs\"  prefix=\"localhost_access_log.\" suffix=\".txt\"\n                 pattern=\"common\" resolveHosts=\"false\"/>\n        -->\n\n      </Host>\n\n    </Engine>\n\n  </Service>\n\n</Server>\n\nIf this is not correct please let me know and i will make appropriate \nrecommended changes but session replication is not working rightnow with \ntomcat5.5.9 w/cluster fix.  The install dir for cluster fix binaries is \n$CATALINA_HOME/server/classes.  Thx\n\nZubair\n\n "}, {"count": 7, "tags": [], "creator": "pr@objektpark.de", "attachment_id": null, "is_private": false, "id": 80387, "time": "2005-09-23T17:45:40Z", "bug_id": 36681, "creation_time": "2005-09-23T17:45:40Z", "text": "Your are sure the your network is correct configured?\n\ncheck that multicast is enabled at your network device (mcastBindAddr).\nIs 228.0.0.3 routed to mcastBindAddr interface?\nopen the firewall for UDP at Mutlicast port (45564) and TCP Sender port (4001)\n\nTest your config without mcastBindAddr attribute.\n\nPeter\n"}, {"count": 8, "tags": [], "creator": "pr@objektpark.de", "attachment_id": null, "text": "Nothing heard from you! I thing the network config is the problem....", "id": 81457, "time": "2005-10-20T08:50:37Z", "bug_id": 36681, "creation_time": "2005-10-20T08:50:37Z", "is_private": false}, {"count": 9, "tags": [], "bug_id": 36681, "is_private": false, "text": "Thanks for your help,  the tomcat 5.5.9 with cluster-fix has helped resolve the \nissue.  \n\nZubair", "id": 81470, "time": "2005-10-20T16:11:55Z", "creator": "zubair.shaikh@cgi.com", "creation_time": "2005-10-20T16:11:55Z", "attachment_id": null}]