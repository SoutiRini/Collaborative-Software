[{"count": 0, "tags": [], "bug_id": 45718, "is_private": false, "id": 120244, "creation_time": "2008-08-31T13:07:32Z", "time": "2008-08-31T13:07:32Z", "creator": "qadeer.qadeer@gmail.com", "text": "This enhancement request is about bzip2 component of Ant Tools.\n\nHadoop is Apache's open source implementation of map-reduce framework.  One of the cornerstones of this framework is to split the input files into chunks, which are fed to different machines for parallel processing.  When it comes to compressed files, most of the codecs need the whole file to successfully decode the data.  This limitation forces Hadoop to send one compressed input file to one process only.  The result is the reduced parallelism.\n\nbzip2 does compression on blocks of data and so while decompressing, these blocks can be processed independent of each other.  This capability of bzip2 is indeed an opportunity to split the bzip2 compressed file, for Hadoop parallel processing.\n\nThe current code of bzip2 in Ant, does not provide such \"by block\" processing capability and rather considers it a continuous stream.  We suggest the following enhancements to make it possible to be used with Hadoop out of the box.\n\n(1) CBZip2InputStream should provide two reading modes.  e.g. continuous and By Block.  In the continuous reading mode, its behavior is the same as it is.  While in \"By Block\" mode, the code tells its client when it reaches a bzip2 block delimiter.  So effectively in 'by block' mode it processes one block at a time and informs the user about the events when it hits a bzip2 block boundary.\n\n(2) CBZip2InputStream should tell the client that how much of compressed data it has processed at a certain point in time.  e.g. if at a point CBZip2InputStream tells its client that it has processed 500 bytes of compressed data, that would mean that the client has read un-compressed data which was generated from 500 bytes of compressed data.  The ant code should also provide a setter for this statistic.  This is needed because e.g. if compressed stream has BZ at the start and the client has stripped that off the stream, it should tell bzip2 code about it.\n\n(3) Hadoop input files are huge (in tera bytes).  So for such a big files, the probability that the bzip2 block delimiters accidentally occur somewhere in the stream is not small.  So bzip2 should make sure that a block maintains its integrity (by comparing computed crc with recorded crc).  This should be done before spilling out a block data.  And if a block is found spurious, it is skipped and tell the client about this event and move on to process the next block.  Another reason for this functionality is that in a huge file, only a few bad blocks should not stop the rest of the file from processing", "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 45718, "text": "If I had to point at the piece of code inside Ant's source tree that is the least understood one (by the current set of active committers) I'd immediately choose the bzip2 package.\n\nI completely agree with the reasons why the code could and should be changed (though I might argue that using commons-compress instead of Ant's libraries might be better if all you want is compression), but don't think anybody around Ant currently knows the BZIP2 algorithm well enough to actually make the changes.\n\nPatches with tests are certainly welcome ;-) ", "id": 121219, "time": "2008-10-06T02:09:34Z", "creator": "bodewig@apache.org", "creation_time": "2008-10-06T02:09:34Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 45718, "attachment_id": null, "text": "For unrelated reasons I have implemented an alternative BZip2 encoder/decoder - see http://code.google.com/p/jbzip2/\n\nAlthough its default InputStream implementation behaves much like the current CBZip2InputStream, a block level interface is also provided that can be wrapped however is desired. This could perhaps be used to provide the functionality requested.\n\nHadoop and/or Apache are welcome to adopt, adapt or simply learn from this code. At the very least, it should be easier for a person of ordinary skill to read it and gain some understanding of how the various algorithms fit together, possibly helping to solve the \"nobody understands this package\" problem.\n\nAnyone simply wishing to be demystified as to how BZip2 works is also most welcome to get in touch. There's a certain amount of \"Aha!\" involved in grasping how it all fits together, but none of the individual parts are especially difficult to understand.", "id": 146584, "time": "2011-05-24T11:59:01Z", "creator": "mjay.francis@gmail.com", "creation_time": "2011-05-24T11:59:01Z", "is_private": false}]