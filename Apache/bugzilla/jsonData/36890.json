[{"count": 0, "tags": [], "bug_id": 36890, "is_private": false, "id": 80677, "attachment_id": null, "creator": "ramon.casha@linux.org.mt", "creation_time": "2005-10-02T10:40:33Z", "time": "2005-10-02T10:40:33Z", "text": "It would be nice if the concat task had the ability to recognise and correctly\nconcatenate XML files by checking for and removing the initial <?xml ..?>\nheader, ideally after determining the file's encoding from it if present. With\nthat header removed it will be possible to concatenate several XML files into\none large file, using the header and footer elements to add the resulting file's\nroot element."}, {"count": 1, "tags": [], "bug_id": 36890, "text": "Or we could have a filter that just removed the ^<\\?xml.*$ from the file being \ninspected. Do we already have some regexp filter able to do this kind of thing?\n", "id": 80699, "time": "2005-10-03T15:23:50Z", "creator": "j_a_fernandez@yahoo.com", "creation_time": "2005-10-03T15:23:50Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "creator": "ramon.casha@linux.org.mt", "attachment_id": null, "id": 80700, "time": "2005-10-03T15:35:01Z", "bug_id": 36890, "creation_time": "2005-10-03T15:35:01Z", "is_private": false, "text": "I tried using a HeadFilter (skip=1,lines=-1) to exclude the first line, but it\nonly worked on the first file in the fileset - that is, it removed the first\nline from the *result* of the concatenation, not from the component parts. I'm\nnot sure if that is by design or a bug. If by design, then a filter wouldn't\nwork here."}, {"count": 3, "tags": [], "creator": "j_a_fernandez@yahoo.com", "is_private": false, "text": "I think someone has suggested this in the past, but what we need is two \nadditional types of filters that you could easily write:\n\n1) A concat filter that takes the output of several independent filterchains \nand concatenates them toghether.\n\n2) A source filter that takes the content of a file and streams it out on a \nfilter chain.\n\nAlternatively one could write a <concatfilter> that takes a bunch of files as \nsources (just like the <concat> task) and applies the same template of filters \nto each one of the source files and acheive (1) that way.\n\nWith that you could do what you want. As the API is open, you just need to \nimplement the interface and voila!\n", "id": 80706, "time": "2005-10-03T18:00:40Z", "bug_id": 36890, "creation_time": "2005-10-03T18:00:40Z", "attachment_id": null}, {"count": 4, "tags": [], "bug_id": 36890, "attachment_id": null, "is_private": false, "id": 80708, "time": "2005-10-03T18:12:42Z", "creator": "ramon.casha@linux.org.mt", "creation_time": "2005-10-03T18:12:42Z", "text": "I thought of something like that but in the meantime I wrote my own task\n\"XmlAggregator\" which does what I need. I just left this enh.request here\nbecause I think it would be useful for ant to have anyway.\n\nPS: Would anyone like an Xml aggregator task? :)"}, {"count": 5, "tags": [], "text": "Why can you not remove the offending tag with a regex filter?", "is_private": false, "id": 80717, "creator": "mbenson@apache.org", "time": "2005-10-03T21:32:35Z", "bug_id": 36890, "creation_time": "2005-10-03T21:32:35Z", "attachment_id": null}, {"count": 6, "tags": [], "bug_id": 36890, "text": "Just write a small XML document that list the files to be concatenated, and \nwrite an XSL transform to process this file to generate the concatenated \nversion by using the document() XSL function. That's the way to go. --DD", "id": 80807, "time": "2005-10-05T19:08:00Z", "creator": "ddevienne@lgc.com", "creation_time": "2005-10-05T19:08:00Z", "is_private": false, "attachment_id": null}, {"count": 7, "tags": [], "bug_id": 36890, "text": "In my experience, concatenation of big XML documents is orders of magnitude\nfaster than performing such concatenation by means of XSL transformations.\nHowever the  concat task can already filter out certain lines by using a\nLineContains filter with the negate option (as of ant 1.7)", "id": 80808, "time": "2005-10-05T19:49:01Z", "creator": "jkf@apache.org", "creation_time": "2005-10-05T19:49:01Z", "is_private": false, "attachment_id": null}, {"count": 8, "tags": [], "bug_id": 36890, "text": "It is perhaps not the fastest or memory efficient mean for very large XML \nfiles, although one could argue that in theory a good optimizing XSL processor \ndoesn't need buffer/load whole document to do a concatenation when compiling \nthe stylesheet.\n\nIt is however the 'right' way to manipulate XML files, even for concatenation. \nWorks all the time, whether a DTD or entities are used in the part, or when \nencoding differs, whereas straight concatenation with head/tail filters is much \nless robust.\n\nBTW, concatenating large XML files is in all cases a bad idea (something Ant's \nown JUnit does, BTW). --DD", "id": 80811, "time": "2005-10-05T20:08:56Z", "creator": "ddevienne@lgc.com", "creation_time": "2005-10-05T20:08:56Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "creator": "j_a_fernandez@yahoo.com", "attachment_id": null, "id": 80812, "time": "2005-10-05T20:21:00Z", "bug_id": 36890, "creation_time": "2005-10-05T20:21:00Z", "is_private": false, "text": "(In reply to comment #8)\n> It is perhaps not the fastest or memory efficient mean for very large XML \n> files, although one could argue that in theory a good optimizing XSL \nprocessor \n> doesn't need buffer/load whole document to do a concatenation when compiling \n> the stylesheet.\n> It is however the 'right' way to manipulate XML files, even for \nconcatenation. \n> Works all the time, whether a DTD or entities are used in the part, or when \n> encoding differs, whereas straight concatenation with head/tail filters is \nmuch \n> less robust.\n> BTW, concatenating large XML files is in all cases a bad idea (something \nAnt's \n> own JUnit does, BTW). --DD\n\nWell, although I agree that XML transformation may be the right tool, XSL \ntransformations is really the wrong thing to use. STX is a much better \ntechnology in this case as the language is designed to execute using the SAX \nmodel (i.e., streaming the documents as you go). \n\nJoost (STX for Java) supports the transformer API, it should not be too \ndificult to allow the style task to use it.\n"}, {"count": 10, "tags": [], "bug_id": 36890, "attachment_id": null, "is_private": false, "id": 80815, "time": "2005-10-05T20:31:15Z", "creator": "ddevienne@lgc.com", "creation_time": "2005-10-05T20:31:15Z", "text": "Sorry Jose, but your comment doesn't make sense to me. XSL also is built on \nSAX. The issue is whether or not the XSL engine needs to and does in fact \nbuffer the XML document before processing it. In some instances it must. In \nmany it doesn't need to, but it does anyway because it's really difficult to \nfind out when compiling the stylesheet whether true streaming is possible.\n\nOr I completely misunderstood you. (Quite possible!)\n\nIt would not be difficult to write a little SAX program that does the same job \na concatenation XSL would do, but that involves writing code. Would be the most \nrobust solution, almost as fast as straight concat, but with XML correctness \nensured. --DD"}, {"count": 11, "tags": [], "creator": "ddevienne@lgc.com", "attachment_id": null, "id": 80816, "time": "2005-10-05T20:52:39Z", "bug_id": 36890, "creation_time": "2005-10-05T20:52:39Z", "is_private": false, "text": "Nevermind, and apologies Jose. Sounds like STX's the ticket for a general \npurpose solution to this problem. In the mean time, I'd still go with regular \nXSL, especially in the XML files to concat aren't that big. --DD"}, {"count": 12, "tags": [], "bug_id": 36890, "text": "It's possible to concatenate a lot of XMLs with an XSL processor, but what I\nneed is something that can process FILESETS. I want to use something like\n\"**/*.comp.xml\".\n\nTo put things in context, what I have are a bunch of small XML files each\ndescribing a JavaServerFaces component. Then I have XSL files which uses these\nto create the Tag class and the Component class, and I have two other XSL files\nwhich take the concatenation of all these XML files to produce the TLD file and\nthe faces-config.xml file. The component files are quite small, as is the\nresulting file (a few Kb). A similar technique produces EJB3 pojo's from lists\nof properties.", "id": 80825, "time": "2005-10-06T08:41:43Z", "creator": "ramon.casha@linux.org.mt", "creation_time": "2005-10-06T08:41:43Z", "is_private": false, "attachment_id": null}, {"count": 13, "tags": [], "bug_id": 36890, "text": "Yes, I understood that part. You iterate over the fileset(s) with Ant-Contrib's \n<for>, generating a small XML file that only lists the files to process (one \nper element). You feed this file into an XSL that process this file, applying a \ntemplate rule to each file element to document() load it, and copy its \nelements. Here's an example:\n\n    <echo file=\"${javadocs}/index.xml\"\n>&lt;?xml version=\"1.0\" ?&gt;\n&lt;javadocs last-modified=\"${CVS_DATE}\"\n          root=\"${docsroot}\"&gt;\n</echo>\n\n    <ac:for param=\"name\" list=\"${docdirs}\">\n      <ac:sequential>\n        ...\n        <echo file=\"${javadocs}/index.xml\" append=\"true\"><![CDATA[\n          <module name=\"@{name}\"\n                  tag=\"${@{name}-tag}\"\n                  errors=\"${@{name}-errors}\"\n                  warnings=\"${@{name}-warnings}\"\n                  versions=\"${@{name}-versions}\"\n                  packages=\"${@{name}-packages}\" />\n        ]]></echo>\n      </ac:sequential>\n    </ac:for>\n\n    <echo file=\"${javadocs}/index.xml\" append=\"true\">\n      &lt;/javadocs&gt;\n    </echo>\n\n    <!-- Inject the errors/warnings stats into index.xml -->\n    <style in=\"${javadocs}/index.xml\" out=\"${javadocs}/index2.xml\"\n           style=\"config/javadocs-addchecks.xsl\" />\n\n    <!-- The index.html listing all Modules and the Javadocs links -->\n    <style in=\"${javadocs}/index2.xml\" out=\"${javadocs}/index.html\"\n           style=\"config/javadocs-index.xsl\">\n      <param name=\"cycletitle\" expression=\"${cycletitle}\" />\n    </style>\n\n    ...\n\n\nAnd here's an example XSL to inject something into the document. You simply \nneed a variation that copies the content of the xmlroot variable into the \nresult document instead of copying the input element with additional nodes.\n\n--DD\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<xsl:stylesheet version=\"1.0\"\n                xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n\n  <xsl:output method=\"xml\" encoding=\"UTF-8\" indent=\"yes\" />\n\n  <!-- ================================================= -->\n  <xsl:template match=\"node() | @*\">\n    <xsl:copy>\n      <xsl:apply-templates select=\"@* | node()\" />\n    </xsl:copy>\n  </xsl:template>\n\n  <!-- ================================================= -->\n  <xsl:template match=\"module\">\n    <xsl:param name=\"javadocs\" select=\"'../build/javadocs'\" />\n\n    <xsl:variable name=\"docsdir\" select=\"concat($javadocs, '/', @name)\" />\n    <xsl:variable name=\"xmlfile\" select=\"concat($docsdir, '/checkstyle.xml')\" />\n    <xsl:variable name=\"xmlroot\" select=\"document($xmlfile)/checkstyle\" />\n\n    <xsl:copy>\n      <!-- copy attributes -->\n      <xsl:copy-of select=\"@*\" />\n\n      <!-- insert checktyle element -->\n      <xsl:choose>\n        <xsl:when test=\"$xmlroot\">\n          <xsl:variable name=\"errorcount\" select=\"count($xmlroot/file/error)\" />\n          <xsl:variable name=\"totalfiles\" select=\"count($xmlroot/file)\" />\n\n          <checkstyle errorcount=\"{$errorcount}\"\n                      errorfiles=\"{count($xmlroot/file[error])}\"\n                      totalfiles=\"{$totalfiles}\"\n                      errperfile=\"{$errorcount div $totalfiles}\"\n                      fullreport=\"{$xmlfile}\" />\n        </xsl:when>\n        <xsl:otherwise>\n          <checkstyle report=\"{$xmlfile}\" />\n        </xsl:otherwise>\n      </xsl:choose>\n\n      <!-- copy nested elements -->\n      <xsl:apply-templates select=\"node()\" />\n    </xsl:copy>\n  </xsl:template>\n\n</xsl:stylesheet>", "id": 80843, "time": "2005-10-06T15:52:35Z", "creator": "ddevienne@lgc.com", "creation_time": "2005-10-06T15:52:35Z", "is_private": false, "attachment_id": null}, {"count": 14, "tags": [], "bug_id": 36890, "text": "I'm also against changes to concat to merge XML docs, as there is a lot to do\n-encoding changes\n-namespace propagation\n-adding of an external doc\n\nAt the same time, XSLT may be a bit of overkill. What do we have that processes\nXInclude?\n\nMaybe some extra XML-specific aggregator would make sense, though we dont want\nto become generic XML workflow (that is Cocoon's job). Nor can we use the name\nXmlAggegator, as the W3c have reserved the string \"xml\" (all cases) for their\nown use. I know we have abused in the past, but we were ignorant then.", "id": 80945, "time": "2005-10-10T11:39:11Z", "creator": "stevel@apache.org", "creation_time": "2005-10-10T11:39:11Z", "is_private": false, "attachment_id": null}]