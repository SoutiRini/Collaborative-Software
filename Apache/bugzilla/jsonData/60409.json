[{"count": 0, "tags": [], "text": "An unexpected exception found in log.\n\nSEVERE: Error finishing response\njava.lang.IllegalArgumentException\n  at java.nio.Buffer.position(Buffer.java:244)\n  at sun.nio.ch.IOUtil.write(IOUtil.java:68)\n  at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:471)\n  at org.apache.tomcat.util.net.NioChannel.write(NioChannel.java:134)\n  at org.apache.tomcat.util.net.NioBlockingSelector.write(NioBlockingSelector.java:101)\n  at org.apache.tomcat.util.net.NioSelectorPool.write(NioSelectorPool.java:157)\n  at org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper.doWrite(NioEndpoint.java:125\n  at org.apache.tomcat.util.net.SocketWrapperBase.doWrite(SocketWrapperBase.java:670)\n  at org.apache.tomcat.util.net.SocketWrapperBase.flushBlocking(SocketWrapperBase.java:60\n  at org.apache.tomcat.util.net.SocketWrapperBase.flush(SocketWrapperBase.java:597)\n  at org.apache.coyote.http11.Http11OutputBuffer.flushBuffer(Http11OutputBuffer.java:519)\n  at org.apache.coyote.http11.Http11OutputBuffer.finishResponse(Http11OutputBuffer.java:318)\n  at org.apache.coyote.http11.Http11Processor.endRequest(Http11Processor.java:1458)\n  at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:823)\n  at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\n  at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:7\n  at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1455)\n  at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n  at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n  at java.lang.Thread.run(Thread.java:745)\n\nI'm not sure but cause may be the same as in recently fixed bug 60372. SocketWrapperBase also does not guard Buffer.limit() usages. Looks like all usages of this method on reusable buffers should be checked.", "attachment_id": null, "id": 195170, "creator": "katzyn@gmail.com", "time": "2016-11-24T01:00:32Z", "bug_id": 60409, "creation_time": "2016-11-24T01:00:32Z", "is_private": false}, {"count": 1, "tags": [], "creator": "violetagg@apache.org", "attachment_id": null, "text": "Hi,\n\nDo you have a reproducible scenario? It will help.\nAlso is it reproducible every time or just under load?\n\nThanks,\nVioleta", "id": 195172, "time": "2016-11-24T07:51:29Z", "bug_id": 60409, "creation_time": "2016-11-24T07:51:29Z", "is_private": false}, {"count": 2, "tags": [], "bug_id": 60409, "text": "Created attachment 34473\nA sample of stack traces", "id": 195178, "time": "2016-11-24T09:19:22Z", "creator": "katzyn@gmail.com", "creation_time": "2016-11-24T09:19:22Z", "is_private": false, "attachment_id": 34473}, {"attachment_id": null, "tags": [], "bug_id": 60409, "is_private": false, "count": 3, "id": 195179, "time": "2016-11-24T09:23:25Z", "creator": "katzyn@gmail.com", "creation_time": "2016-11-24T09:23:25Z", "text": "1-3 errors per day under load. At least it has a stack trace. It's not easy to simulate I/O error at right time to reproduce it.\n\nThere are too many assorted messages in logs. After some filtering and search I see that this exception usualy happends just a two or three seconds after\n\norg.apache.coyote.http11.Http11Processor service\nINFO: Error parsing HTTP request header\n Note: further occurrences of HTTP header parsing errors will be logged at DEBUG level.\njava.lang.IllegalStateException: Unexpected state: headers already parsed. Buffer not recycled?\n  at org.apache.coyote.http11.Http11InputBuffer.parseHeaders(Http11InputBuffer.java:550)\n\norg.apache.coyote.http11.Http11Processor endRequest\nSEVERE: Error finishing response\njava.lang.NullPointerException\n  at org.apache.coyote.http11.Http11OutputBuffer.commit(Http11OutputBuffer.java:351)\n\nSee attachment for full traces.\n\nSo all of them may be related. There are many such errors in service and endRequest, but only a few at Buffer.position().\n\nSometimes it has a longer stack trace (see sample in the same attachment)."}, {"count": 4, "attachment_id": 34478, "bug_id": 60409, "text": "Created attachment 34478\nCompressed journalctl output\n\nI've uploaded a nearly full log (without sensitive data and unrelevant messages from web applications).\n\nThere are also a lot of\n\norg.apache.tomcat.util.net.AbstractEndpoint countDownConnection\nWARNING: Incorrect connection count, multiple socket.close called on the same socket.\n\nafter some uptime.", "id": 195227, "time": "2016-11-26T08:56:51Z", "creator": "katzyn@gmail.com", "creation_time": "2016-11-26T08:56:51Z", "tags": [], "is_private": false}, {"count": 5, "attachment_id": null, "bug_id": 60409, "text": "Hi,\n\nI succeeded to reproduce the exceptions from this issue [1].\n\n1. Request a file with such a length so that \"send file\" is used.\n - just before serving the file [2], delete it, thus it will cause the processor to be released and recycled. As a result this processor will be added to the \"recycled processors\" [3].\n - after this while finishing the response the processor will be released and recycled once again [4]. This will add the processor again to the \"recycled processors\". As a result one and the same processor will be in the \"recycled processors\".\n2. Now request twice. One and the same processor will be provided for the two different requests [5].\n\nI do not know whether you scenario is similar. If you can describe your scenario it will be helpful.\n\nSo currently we are using org.apache.tomcat.util.collections.SynchronizedStack<T> which does not guarantee uniqueness of the elements.\n\nRegards,\nVioleta\n\n\n\n[1] https://github.com/apache/tomcat/commit/74a12f550478b34261b39d2e324b3951e2ef80cc\n[2] https://github.com/apache/tomcat/blob/trunk/java/org/apache/tomcat/util/net/NioEndpoint.java#L891\n[3] https://github.com/apache/tomcat/blob/trunk/java/org/apache/coyote/AbstractProtocol.java#L927\n[4] https://github.com/apache/tomcat/blob/trunk/java/org/apache/coyote/AbstractProtocol.java#L854\n[5] https://github.com/apache/tomcat/blob/trunk/java/org/apache/coyote/AbstractProtocol.java#L728", "id": 195249, "time": "2016-11-27T17:48:54Z", "creator": "violetagg@apache.org", "creation_time": "2016-11-27T17:48:54Z", "tags": [], "is_private": false}, {"count": 6, "tags": [], "creator": "markt@apache.org", "is_private": false, "text": "To date, the design decision has been that the request processing thread is responsible for ensuring that a processor is only recycled once per request.\n\nOne reason for not making it a cache responsibility is that the cache only tracks unused processors so preventing duplicates isn't guaranteed to fix the problem.", "id": 195251, "time": "2016-11-27T18:38:27Z", "bug_id": 60409, "creation_time": "2016-11-27T18:38:27Z", "attachment_id": null}, {"count": 7, "tags": [], "text": "Created attachment 34484\nUnexpected IllegalStateException in HttpServletResponse.sendError()\n\n(In reply to Violeta Georgieva from comment #5)\n>  - just before serving the file [2], delete it, thus it will cause the\n> processor to be released and recycled.\nI don't think that this is my case. Static content is not touched at all in this period. May be more unknown causes exist. I'm still not able to find a sequence to reproduce it.\n\nI've uploaded a one more strange exception. Last change in this directory was six month ago. All these requests are definitely should return 404. But one request throws a strange exception and I'm unable too see how it possible in DefaultServlet. Two more exceptions follow it. This also looks like response was incorretly reused.", "is_private": false, "id": 195255, "creator": "katzyn@gmail.com", "time": "2016-11-28T00:32:47Z", "bug_id": 60409, "creation_time": "2016-11-28T00:32:47Z", "attachment_id": 34484}, {"count": 8, "tags": [], "creator": "katzyn@gmail.com", "attachment_id": null, "text": "I've appended useSendfile=\"false\" to all HTTP connectors for testing purposes.", "id": 195256, "time": "2016-11-28T07:45:27Z", "bug_id": 60409, "creation_time": "2016-11-28T07:45:27Z", "is_private": false}, {"count": 9, "tags": [], "creator": "violetagg@apache.org", "attachment_id": 34485, "id": 195267, "creation_time": "2016-11-28T13:35:24Z", "time": "2016-11-28T13:35:24Z", "bug_id": 60409, "text": "Created attachment 34485\nPatch proposal\n\nHi Mark,\n\n(In reply to Mark Thomas from comment #6)\n> To date, the design decision has been that the request processing thread is\n> responsible for ensuring that a processor is only recycled once per request.\n> \n> One reason for not making it a cache responsibility is that the cache only\n> tracks unused processors so preventing duplicates isn't guaranteed to fix\n> the problem.\n\nWhat do you think about this approach?\nThe patch is made against Tomcat 9 trunk.\n\nThanks,\nVioleta", "is_private": false}, {"count": 10, "tags": [], "text": "Created attachment 34486\nAlternative patch\n\nMy initial impression looking at that patch was that it was fixing the symptom rather than the cause. The case it handles should never happen.\n\nI have attached an alternative patch that I believe addresses the root cause.", "is_private": false, "id": 195269, "creator": "markt@apache.org", "time": "2016-11-28T14:35:50Z", "bug_id": 60409, "creation_time": "2016-11-28T14:35:50Z", "attachment_id": 34486}, {"count": 11, "tags": [], "creator": "violetagg@apache.org", "is_private": false, "text": "(In reply to Mark Thomas from comment #10)\n> Created attachment 34486 [details]\n> Alternative patch\n> \n> My initial impression looking at that patch was that it was fixing the\n> symptom rather than the cause. The case it handles should never happen.\n> \n> I have attached an alternative patch that I believe addresses the root cause.\n\n+1", "id": 195270, "time": "2016-11-28T14:40:56Z", "bug_id": 60409, "creation_time": "2016-11-28T14:40:56Z", "attachment_id": null}, {"count": 12, "tags": [], "bug_id": 60409, "attachment_id": null, "id": 195271, "time": "2016-11-28T14:54:36Z", "creator": "remm@apache.org", "creation_time": "2016-11-28T14:54:36Z", "is_private": false, "text": "(In reply to Mark Thomas from comment #10)\n> Created attachment 34486 [details]\n> Alternative patch\n> \n> My initial impression looking at that patch was that it was fixing the\n> symptom rather than the cause. The case it handles should never happen.\n> \n> I have attached an alternative patch that I believe addresses the root cause.\n\nI failed to reproduce the exception with the test case, for some reason, but the patch looks good."}, {"attachment_id": null, "tags": [], "bug_id": 60409, "is_private": false, "count": 13, "id": 195272, "time": "2016-11-28T15:03:32Z", "creator": "violetagg@apache.org", "creation_time": "2016-11-28T15:03:32Z", "text": "Hi Evgenij,\n\n(In reply to Evgenij Ryazanov from comment #8)\n> I've appended useSendfile=\"false\" to all HTTP connectors for testing\n> purposes.\n\nDo you have already some results with \"send file\" disabled?\n\nThanks a lot,\nVioleta"}, {"count": 14, "tags": [], "bug_id": 60409, "attachment_id": null, "id": 195278, "time": "2016-11-29T01:29:19Z", "creator": "katzyn@gmail.com", "creation_time": "2016-11-29T01:29:19Z", "is_private": false, "text": "Hi. I don't see such strange exceptions in journal any more. 16 hours may be not enough to be fully sure, however. But in previous runs (with sendfile) first NPE or IAE appears in a half an hour or so."}, {"count": 15, "tags": [], "creator": "violetagg@apache.org", "attachment_id": null, "text": "Hi,\n\nI committed the Mark's patch.\n\nThe fix will be available in:\n- 9.0.x for 9.0.0.M14 onwards and\n- 8.5.x for 8.5.9 onwards\n\nI do not see these exceptions in 8.0.x and 7.0.x.\n\nRegard,\nVioleta", "id": 195284, "time": "2016-11-29T09:24:33Z", "bug_id": 60409, "creation_time": "2016-11-29T09:24:33Z", "is_private": false}, {"count": 16, "tags": [], "bug_id": 60409, "attachment_id": null, "id": 195510, "time": "2016-12-15T19:57:02Z", "creator": "erakestraw@bbandt.com", "creation_time": "2016-12-15T19:57:02Z", "is_private": false, "text": "Try enabling NIO in 8.0.X and you should be able to recreate same issue there.  We did using 8.0.30.  It seems to be NIO specific--8.5.4 was where we discovered it because NIO was enforced for the first time, but you can see it in older versions too."}, {"count": 17, "tags": [], "bug_id": 60409, "text": "I've received a report at $work of a customer seeing the same / a similar issue with 8.0.38 + NIO + send file.\n\nWhile our test case doesn't trigger the issue, it does appear that there is still something that needs to be fixed in 8.0.x (and possibly earlier versions).\n\nRe-opening to investigate further.", "id": 195516, "time": "2016-12-16T07:15:35Z", "creator": "markt@apache.org", "creation_time": "2016-12-16T07:15:35Z", "is_private": false, "attachment_id": null}, {"count": 18, "tags": [], "text": "I have confirmed that the issue observed in 8.0.x is essentially the same as that seen in 8.5.x. Rather than introduce the issue, the refactoring appears simply to have made it easier to observe.\n\nIt has been fixed in:\n- 8.0.x for 8.0.40 onwards\n- 7.0.x for 7.0.74 onwards\n- 6.0.x for 6.0.49 onwards", "is_private": false, "id": 195879, "creator": "markt@apache.org", "time": "2017-01-05T15:09:35Z", "bug_id": 60409, "creation_time": "2017-01-05T15:09:35Z", "attachment_id": null}]