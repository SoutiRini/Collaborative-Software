[{"count": 0, "tags": [], "bug_id": 57943, "attachment_id": null, "id": 183070, "time": "2015-05-22T06:21:27Z", "creator": "sunqi800@163.com", "creation_time": "2015-05-22T06:21:27Z", "is_private": false, "text": "when i restart tomcat,the tomcat can not process request soon\uff0ci find an error log\n\nException in thread \"http-nio-7001-ClientPoller-1\" java.util.ConcurrentModificationException\n        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)\n        at java.util.HashMap$KeyIterator.next(HashMap.java:828)\n        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\n        at org.apache.tomcat.util.net.NioEndpoint$Poller.timeout(NioEndpoint.java:1421)\n        at org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1215)\n        at java.lang.Thread.run(Thread.java:662)\n\ntomcat poller thread is not catch this exception,so this thread is died.\nconnection is accept but has no poller thread to process."}, {"count": 1, "tags": [], "bug_id": 57943, "is_private": false, "id": 183073, "attachment_id": null, "creator": "markt@apache.org", "creation_time": "2015-05-22T13:29:47Z", "time": "2015-05-22T13:29:47Z", "text": "This is the third report we have received about this issue.\n\nThe other two are:\nhttp://markmail.org/message/xgxblpk4v4ykgi5y\nhttp://markmail.org/message/eypk42i6gdpztkpy\n\nI have looked through the NIO Poller code again and I still can't see how this can be happening. I've also dug into the JRE code and I can't see any issues there either (although I'll not this has been reported on a variety of JVMs and I haven't checked the specific ones mentions).\n\nI think the best thing to do at this point is catch the error, log a warning and maybe ask folks to report it if they can repeat it."}, {"count": 2, "tags": [], "bug_id": 57943, "is_private": false, "text": "I have added the work-around to trunk (for 9.0.x), 8.0.x (for 8.0.24 onwards) and 7.0.x (for 7.0.63 onwards).\n\nI suspect a JVM bug so I am resolving this as FIXED. If we discover it is a Tomcat bug we can always re-open.", "id": 183074, "time": "2015-05-22T14:29:41Z", "creator": "markt@apache.org", "creation_time": "2015-05-22T14:29:41Z", "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 57943, "attachment_id": null, "id": 183838, "time": "2015-07-02T01:28:26Z", "creator": "sunqi800@163.com", "creation_time": "2015-07-02T01:28:26Z", "is_private": false, "text": "(In reply to Mark Thomas from comment #2)\n> I have added the work-around to trunk (for 9.0.x), 8.0.x (for 8.0.24\n> onwards) and 7.0.x (for 7.0.63 onwards).\n> \n> I suspect a JVM bug so I am resolving this as FIXED. If we discover it is a\n> Tomcat bug we can always re-open.\n\nwe know the reason why poller thread died,as this bug https://bz.apache.org/bugzilla/show_bug.cgi?id=57340\n\nwe use async servlet, many request is async timeout,at the same time,async servlet calls complete or dispatch\n\n\nnioChannels cache contain 2 references to the same object,and two request will use same NioChannel,and poller object will replace by other request\n\nwo also find a new place put the same NioChannel and AttachmentKey into caches. \n\n     } else if (handshake == -1 ) {\n                    if (key != null) {\n                        socket.getPoller().cancelledKey(key, SocketStatus.DISCONNECT);\n                    }\n                    if (running && !paused) {\n                        nioChannels.push(socket);\n                    }\n                    socket = null;\n                    if (running && !paused) {\n                        keyCache.push(ka);\n                    }\n                    ka = null;\n}"}, {"count": 4, "tags": [], "bug_id": 57943, "attachment_id": 32880, "id": 183856, "time": "2015-07-02T15:45:19Z", "creator": "ian.luo@gmail.com", "creation_time": "2015-07-02T15:45:19Z", "is_private": false, "text": "Created attachment 32880\nanalysis for bug57943\n\nit's in markdown format"}, {"count": 5, "tags": [], "bug_id": 57943, "is_private": false, "id": 183859, "attachment_id": 32880, "creator": "chris@christopherschultz.net", "creation_time": "2015-07-02T16:07:20Z", "time": "2015-07-02T16:07:20Z", "text": "Comment on attachment 32880\nanalysis for bug57943\n\nIan's comment, not as an attachment, and therefore much more readable, is:\n\nI am the colleague of Sun Qi who reported [bug57943](https://bz.apache.org/bugzilla/show_bug.cgi?id=57943) one month ago. I believe we managed to find out why ConcurrentModificationException happens in our scenario.\n\nHere's the scenario, our application uses async servlet to write the response back to the client. The operation we put in async servlet which run in another thread is quite time-consuming. When the incoming traffic is heavy, which usually happens when the instances of tomcat server reboots, we hit this issue very easily. \n\nWhen the ClientPoller thread run into timeout method (in NioEndpoint) and execute the following code:\n\n```java\n} else if (!ka.isAsync() || ka.getTimeout() > 0) {\n    // Async requests with a timeout of 0 or less never timeout\n    long delta = now - ka.getLastAccess();\n    long timeout = (ka.getTimeout()==-1)?((long)socketProperties.getSoTimeout()):(ka.getTimeout());\n    boolean isTimedout = delta > timeout;\n    if (isTimedout) {\n        // Prevent subsequent timeouts if the timeout event takes a while to process\n        ka.access(Long.MAX_VALUE);\n        processSocket(ka.getChannel(), SocketStatus.TIMEOUT, true, 6);\n    }\n}\n```\n\nEventually it calls `processSocket(ka.getChannel())` and puts back the NioChannel instance to the cache `nioChannels` for the late re-use:\n\n```java\nif (ka!=null) ka.setComet(false);\nsocket.getPoller().cancelledKey(key, SocketStatus.ERROR, false);\nif (running && !paused) {\n    nioChannels.offer(socket);\n}\n```\n\nUnfortunately in our scenarios, when QPS is greater than 1000req/sec, async servlet threads have very large chance to start async-complete and begin to call `processSocket` (in Http11NioProcessor) at the same time:\n\n```java\n} else if (actionCode == ActionCode.ASYNC_COMPLETE) {\n    if (asyncStateMachine.asyncComplete()) {\n    ((NioEndpoint)endpoint).processSocket(socketWrapper.getSocket(), SocketStatus.OPEN_READ, true, 10);\n}\n```\n\nThis leads to cache pollution in `nioChannels` since there're chances to offer the same object into the cache multiple times. When the Acceptor thread polls the object and hands it over to the ClientPollers, the same object could be pass into the different ClientPoller threads, then leads to very serious problem.\n\nYou may notice the code I show here is the code from tomcat 7.0.54, and claim the similar issue has already been addressed, but this is not true. We noticed the similar issue was reported on [Bug57340](https://bz.apache.org/bugzilla/show_bug.cgi?id=57340), and the solution has already been checked into the later release.\n\nBut this solution is not a complete solution, in our scenario, there's chance to offer the duplicated object to the cache in `else if` clause where the solution for Bug57340 doesn't cover:\n\n```java\n} else if (handshake == -1 ) {\n    if (key != null) {\n        socket.getPoller().cancelledKey(key, SocketStatus.DISCONNECT, false);\n    }\n    nioChannels.offer(socket);\n    socket = null;\n    if ( ka!=null ) keyCache.offer(ka);\n    ka = null;\n}\n```\n\nThis is easily to understand. When handshake equals -1, one possibility is the `key` passed into the doRun method is `null`, and when `key` is null, it means some other thread has already finished processing on the same socket:\n\n```java\npublic void run() {\n    SelectionKey key = socket.getIOChannel().keyFor(\n        socket.getPoller().getSelector());\n```\n\nWe propose the change below in order to address this issue throughly. In this case, I think we can simply drop the object instead of offering it since it looks there's no other ideal way to not use lock.\n\n```java\n} else if (handshake == -1 ) {\n    if (key != null) {\n        if (socket.getPoller().cancelledKey(key, SocketStatus.DISCONNECT, false) != null) {\n            nioChannels.offer(socket);\n            if (ka != null) keyCache.offer(ka);\n        }\n    }\n    socket = null;\n    ka = null;\n```"}, {"count": 6, "tags": [], "bug_id": 57943, "attachment_id": null, "is_private": false, "id": 183865, "time": "2015-07-02T21:13:16Z", "creator": "markt@apache.org", "creation_time": "2015-07-02T21:13:16Z", "text": "Many thanks for the details analysis.\n\nI have applied a patch that should fix this to trunk (9.0.x) and back-ported it to 8.0.x (for 8.0.25 onwards) and 7.0.x (7.0.64 onwards). I have also proposed is for 6.0.x."}, {"count": 7, "tags": [], "text": "Fixed in Tomcat 6 in r1710473 and will be in 6.0.45 onwards.", "attachment_id": null, "id": 185931, "creation_time": "2015-10-25T18:36:02Z", "time": "2015-10-25T18:36:02Z", "creator": "knst.kolinko@gmail.com", "bug_id": 57943, "is_private": false}]