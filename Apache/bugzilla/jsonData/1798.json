[{"count": 0, "attachment_id": null, "creator": "bugzilla@apache.org", "text": "I have Apache with mod_jk working as load balancer (using ajp13) \nfor 3 Tomcat 3.2.2b5 instances, with a simple jsp application.\nThey are all running on a Sun e250 with 2 CPUs - 1 Gbyte RAM - Solaris 2.8\nThe JVM is Sun 1.2.2 with native threads.\n\nI noticed that after some hour of work Tomcat stops responding to requests,\nas if it has reached the maximum number of allocated threads...\nThis behaviour is causing me major troubles because this system is serving\nthe application to our customers, and we have to stop and restart tomcat\nand apache many times per day (and per night!)\n\nThis remembered me the bug #1006 - I didn't find any fix of this bug\nin version 3.2.2b5, so I applied the fix suggested in that bug, then\nI rebuilt tomcat. The timeout on PoolTcpEndpoint.java now works.\n\nBut this did not fix the problem.\nAt the same time, the amount of Apache processes in memory grows\nand even stopping tomcat, they don't decrease. It happens that even if\ntomcat could answer (it still answers from the http connector) the apache\ndoesn't have a process to handle a new request.\n\nI used truss to see where one of the apache processes was stuck: it was\nwaiting for a recv call (the 3rd parameter was a 4) to complete. So I\ndumped its core with gcore, and loaded it into gdb. This was the backtrace\nresult:\n\n#0  0xff216e68 in _so_recv () from /usr/lib/libc.so.1\n#1  0xff15f8f8 in jk_tcp_socket_recvfull ()\n   from /usr/local/apache/libexec/mod_jk.so\n#2  0xff15fdc8 in connection_tcp_get_message ()\n   from /usr/local/apache/libexec/mod_jk.so\n#3  0xff161258 in service () from /usr/local/apache/libexec/mod_jk.so\n#4  0xff15b934 in service () from /usr/local/apache/libexec/mod_jk.so\n#5  0xff166a7c in jk_handler () from /usr/local/apache/libexec/mod_jk.so\n#6  0x407c4 in ap_invoke_handler ()\n#7  0x5d700 in process_request_internal ()\n#8  0x5d784 in ap_process_request ()\n#9  0x50d80 in child_main ()\n#10 0x5110c in make_child ()\n#11 0x51684 in perform_idle_server_maintenance ()\n#12 0x51ee8 in standalone_main ()\n#13 0x5281c in main ()\n\nSo I modified the jk_tcp_socket_recvfull() function to check with\npoll() if there are data to read within a timeout of 5 minutes.\nI case of timeout, I close the socket before to call the recv function.\n\nNow, this patched system is in production and it seems to be fixed.\nBut (besides this \"raw\" patch - it works _after_ the bug happened)\nI suppose that there's some bug in the ajp13 dialog between tomcat and,\napache, since they are both stuck waiting for the other part to send\nsomething. It's like if one of them should send more data than it does...\nSorry, I don't have enough knowledge of tomcat and mod_jk to give you any\nmore hint... But I'm available for you to help with tests.\n\nHope this bug report contains enough information to help you fix it.", "id": 2504, "time": "2001-05-17T08:46:23Z", "bug_id": 1798, "creation_time": "2001-05-17T08:46:23Z", "tags": [], "is_private": false}, {"count": 1, "tags": [], "creator": "Brian.Ewins@btinternet.com", "attachment_id": null, "id": 3374, "time": "2001-07-03T10:38:15Z", "bug_id": 1798, "creation_time": "2001-07-03T10:38:15Z", "is_private": false, "text": "for those who read this bug but cant figure out what Luca's patch was:\ntry changing\nsrc/native/mod_jk/common/jk_connect.c\n\nso that the start of jk_tcp_socket_recvfull reads:\n\n   /* Additional code to poll for incoming data */\n   struct pollfd fds[1];\n   fds[0].fd=sd;\n   fds[0].events=POLLIN;\n   if (poll(fds,1,300)<0) {\n      /* ERROR - nothing appeared while we polled. */\n      /* nasty error handling - close the socket. */\n      close(sd);\n   }\n   /* end*/\n\nAs Luca says this is a workaround not a fix but be warned: it is not even\na perfect workaround. I've just tried this on our setup (Sun 4500, jre 131,\n6 cpus), driving tomcat way too hard using daiquiri to replay our logs (a good\nway to reproduce this problem very quickly)\n\nAfter turning off the taps and letting apache/tomcat recover, 3 out of 250 of \nthe apache processes were still jammed at the recv() call. Every other jammed \napache process recovered (patch was applied to the 3.3m4 branch of mod_jk, but \nI'm using tomcat 3.2.2. The protocol hasnt changed, the later version of mod_jk \nonly includes bugfixes) It may be an independent problem or perhaps tomcat is \nmanaging to hang up _between_ the call to poll() and recv()??? Seems unlikely \nbut there ya go.\n"}, {"count": 2, "tags": [], "creator": "Brian.Ewins@btinternet.com", "text": "After applying the patch you see a lot of connection reset by peer errors\nin the tomcat side of ajp13. The line it occurs at - line 146 of \nAjp13ConnectionHandler - is where tomcat attempting to recieve the next Ajp13 \nmessage (ie both mod_jk and tomcat are listening, given that we know the \nprocesses hung at a call to recv() - deadlock)\n\nThere was a fairly recent message on one of the mailing lists which mentioned a \npoint where a buffer on the tomcat side was tested as being < max size when it\nshould have been <= max size. The submitters comment was that he fixed it in \nTC4, and said someone should fix it in TC3 too. Unfortunatelty \nmarc.theaimsgroup is down and I can't find the message! It occurs to me that \nthis error - which would cause tc to fail to send data if the amount of data in \nthe buffer was exactly right - would cause exactly the problem I'm seeing.\n\nSee also Bug#1253, Bug#391 which look to be the same issue.", "id": 3386, "time": "2001-07-04T03:03:31Z", "bug_id": 1798, "creation_time": "2001-07-04T03:03:31Z", "is_private": false, "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 1798, "attachment_id": null, "is_private": false, "id": 3394, "time": "2001-07-04T05:31:23Z", "creator": "Brian.Ewins@btinternet.com", "creation_time": "2001-07-04T05:31:23Z", "text": "In Ajp13ConnectionRequest.decodeRequest() there are several places where\n-1 (error) can be returned without any exception being logged.\nThis kind of error is then _ignored_ in Ajp13ConnectionHandler.\nSubsequently ContextManager looks at the response object to check its status\nand will go on to handle the request as if it was ok otherwise - but as far as \nI can tell these errors won't cause the status to be set.\nMay be unconnected to this bug but adding some code to Ajp13ConnectionHandler \nwouldn't hurt:\nerr = req.decodeRequest(msg); // add new code below\nif (err<0) {\n res.setStatus(500);\n}\n\nCode-review comment...In general the code here does not seem to provide the \nright 'contract' to mod_jk, in that there is no _guarantee_ that after going \nround the main loop of Ajp13ConnectionHandler that mod_jk will be sent \n_anything_. Responsibility for sending a response is spread around several \nclasses and thus seems error-prone. "}, {"count": 4, "tags": [], "bug_id": 1798, "is_private": false, "text": "This appears to be _partly_ resolved in 3.3m4. The code now sends a 500 \nresponse instead of ignoring the error on the tomcat side, so eventually locked \nprocesses clear down - without patching mod_jk as above. Compared with \nmod_jserv (which times out in 20s in similar circumstances, but kills the \nbrowser tcp connection instead of sending an HTTP response) mod_jk takes \nforever to time out dead processes, since its using the underlying tcp timeouts \n(mod_jserv uses apache's api to set up timeouts). Doesnt seem right that we \nneed the timeouts at all though... ", "id": 3412, "time": "2001-07-04T12:52:08Z", "creator": "Brian.Ewins@btinternet.com", "creation_time": "2001-07-04T12:52:08Z", "attachment_id": null}, {"count": 5, "tags": [], "text": "I'll try to reproduce it. Could you check with 3.3Beta2 and the latest mod_jk ?\nIs there a simpler way to reproduce it ? Like doing \"ab\" with some requests. Are\nyou doing simple GETs or is a POST involved ? This is a very serious bug, thank\nyou very much for the report and the informations you provided !", "attachment_id": null, "bug_id": 1798, "id": 5193, "time": "2001-09-06T22:05:21Z", "creator": "cmanolache@yahoo.com", "creation_time": "2001-09-06T22:05:21Z", "is_private": false}, {"count": 6, "tags": [], "bug_id": 1798, "attachment_id": null, "id": 5283, "time": "2001-09-10T03:20:31Z", "creator": "Brian.Ewins@btinternet.com", "creation_time": "2001-09-10T03:20:31Z", "is_private": false, "text": "Costin - we got this with just GET requests, but only under extreme load. Our \nservlet was fairly slow (eg 2s-4s response) which makes it easy to saturate the \nserver with requests. Then all you need to do is wait. You can almost certainly \nreproduce with ab. I no longer work on that project, so I can't retest the new \nbuild with the same system, sorry. My gut feeling was that the code required \nsome reorganisation to enforce a response from the tomcat side - otherwise you \nhave to trace all of the possible paths to check for code that might cause \ndeadlock (see my third comment below). I was under too much time pressure to \ndelve into that."}, {"count": 7, "tags": [], "bug_id": 1798, "attachment_id": 540, "id": 5554, "time": "2001-09-14T09:34:58Z", "creator": "hgomez@slib.fr", "creation_time": "2001-09-14T09:34:58Z", "is_private": false, "text": "Created attachment 540\nsome ab (Apache Bench logs) and jsp used"}, {"count": 8, "attachment_id": null, "creator": "cmanolache@yahoo.com", "text": "It seems we are unable to duplicate this, at least not with 3.3. If anyone still has problems, please reopen the bug and add more details. I agree such a bug is important to resolved - and will be a top priority for 3.3.1. ", "id": 6694, "time": "2001-10-14T17:14:56Z", "bug_id": 1798, "creation_time": "2001-10-14T17:14:56Z", "tags": [], "is_private": false}]