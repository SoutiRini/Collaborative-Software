[{"text": "This is an issue with org.apache.tools.tar.TarBuffer\n\nWhen trying to use the TarInputStream with a corrupted archive the number of\nbytes passing through the stream is whatever value is set for the filesize in\nthe tar header, and not the actual number of bytes in the tar file. \n\nThe TarBuffer.readBlock() method will read a number of bytes (a given blocksize)\nfrom the stream. A previous fix (#29877) changed the functionality in such a way\nthat if EOF is read before the entire block is filled, then the remaining part\nof the block buffer is filled with 0s. The problem is that this is also done\nwhen no bytes at all could be read from the stream. \n\nAs a result, TarInputStream.read will never return EOF anymore, and will just\nfill up your buffer with zeros whenever you try to read from the stream. \n\nNone of this is a real issue when the header of the tar archive indicates the\ncorrect size of the data. But if for any reason the size field in the tar header\ncontains a huge number your application and/or any wrapped streams potentially\nend up having to process gigabytes of zeros. \n\nMy suggested fix is simple: when EOF is read, \n- if any bytes were read, fill the buffer with 0s up to the block size, as before\n- if no bytes has been read yet, return false\n\n\nsimply add the following \"if(offset == 0) return false\" as below. \n\n\n...\nif (numBytes == -1) {\n           \t\n    // if no bytes had been read at all yet, return false\n    if (offset == 0)\n    \treturn false;\n\n    // However, just leaving ...... \n     .....", "tags": [], "bug_id": 39924, "is_private": false, "count": 0, "id": 90736, "time": "2006-06-28T19:10:23Z", "creator": "phulst@sbcglobal.net", "creation_time": "2006-06-28T19:10:23Z", "attachment_id": null}, {"count": 1, "tags": [], "creator": "peterreilly@apache.org", "text": "Fixed in SVN, thanks for the report.", "id": 93293, "time": "2006-09-09T21:45:06Z", "bug_id": 39924, "creation_time": "2006-09-09T21:45:06Z", "is_private": false, "attachment_id": null}]