[{"count": 0, "tags": [], "bug_id": 56798, "attachment_id": null, "id": 176817, "time": "2014-07-31T21:36:22Z", "creator": "brenuart@gmail.com", "creation_time": "2014-07-31T21:36:22Z", "is_private": false, "text": "Connections are taken out of the idle pool when available or a new one is created if the pool limits are yet not reached.\nThe idle pool is implemented using an ArrayBlockingQueue where:\n- returned connections are put back at the TAIL of the queue\n- borrowed connections are taken out of the HEAD of the queue\nThe handling of idle connections follows therefore a FIFO strategy.\n\nThe PoolCleaner thread wakes up every timeBetweenEvictionRunsMillis and attempts to enforce the minIdle limit by removing connections sitting in the idle pool for more than minEvictableIdleTimeMillis. Unfortunately, this strategy combined with the FIFO queue handling may lead to less optimal situation where unnecessary connections are kept alive in the pool although they could have been removed.\n\nConsider the following scenario:\n- PoolCleaner configured to wakeup every 1 second (timeBetweenEvictionRunsMillis=1000)\n- Connection must be idle for at least 500ms before being eligible for eviction (minEvictableIdleTimeMillis=500)\n- minIdle is set to 2\n- The pool starts with 5 connections (either because of past activity or because of initialSize=5)\nSuppose the application requests a connection from the pool every 100ms, use it and releases it almost immediately. Since only one connection is used at a time, one would expect the pool to shrink to minIdle (i.e. 2 in this example) after one (or a few) runs of the PoolCleaner thread. But because of FIFO strategy, none of the 5 connections is eligible for eviction: they all have been used every 500ms\u2026 The entire pool is \u201chot\u201d.\n\nThe higher you set the minEvictableIdleTimeMillis, the higher are the chances to be hit by this phenomena.\n\nA better strategy seems to use a LIFO queue for the idle connections. This way, the pool attempts to maximise the use of the \u201clatest\u201d connection and therefore reduce the amount of \u201chot\u201d connections. In the previous example, the same connection would always be reused by the application, letting the other \"cool down\" until they become eligible for eviction. \n\nThis would also reduce the chance to get a \u201cstale\u201d connection from the pool when not configured to validate on borrow. The chance to get a bad connection from the pool increases with the time the connection stays idle in the pool (chances are higher they are closed by the db server). With a LIFO strategy, the pool always gives hot connections that have been used the more recently: those that are less likely to be closed.\n\n\nWhat do you think?"}, {"count": 1, "tags": [], "bug_id": 56798, "attachment_id": 31866, "is_private": false, "id": 176833, "time": "2014-08-01T20:42:53Z", "creator": "brenuart@gmail.com", "creation_time": "2014-08-01T20:42:53Z", "text": "Created attachment 31866\nTestCase to show that the pool will fail to shrink"}, {"count": 2, "tags": [], "bug_id": 56798, "attachment_id": null, "id": 176838, "time": "2014-08-01T22:25:51Z", "creator": "chris@christopherschultz.net", "creation_time": "2014-08-01T22:25:51Z", "is_private": false, "text": "Nice analysis. I think you're on to something, here. The \"depth\" of the pool should end up, over time, being roughly equal to the number of connections actually required to serve the needs of the clients, *but no more*. Using a LIFO structure does in fact mean that the whole pool will stay \"hot\" regardless of how big it becomes... as long as the connections are used frequently enough.\n\nBut the frequency of a check-out is not really relevant: only the number of connections that are used /simultaneously/ is relevant. A site may be able to get away with a pool with a depth of 2 or 3 connections, but if the pool grows to 50 connections, they all might stay in the pool and not be evicted due to the LIFO behavior.\n\nI'm not sure if the LIFO queue gives a performance benefit -- because the head of the structure is only under contention for check-outs and the tail of the structure is only under contention for check-ins -- but it's worth investigating."}, {"count": 3, "attachment_id": null, "bug_id": 56798, "is_private": false, "id": 176845, "time": "2014-08-02T11:31:00Z", "creator": "sebb@apache.org", "creation_time": "2014-08-02T11:31:00Z", "tags": [], "text": "(In reply to Christopher Schultz from comment #2)\n\n> Using a\n> LIFO structure does in fact mean that the whole pool will stay \"hot\"\n> regardless of how big it becomes... as long as the connections are used\n> frequently enough.\n\nSurely you mean FIFO here?\n \n> But the frequency of a check-out is not really relevant: only the number of\n> connections that are used /simultaneously/ is relevant. A site may be able\n> to get away with a pool with a depth of 2 or 3 connections, but if the pool\n> grows to 50 connections, they all might stay in the pool and not be evicted\n> due to the LIFO behavior.\n\nDitto\n \n> I'm not sure if the LIFO queue gives a performance benefit -- because the\n> head of the structure is only under contention for check-outs and the tail\n> of the structure is only under contention for check-ins\n\nHuh? Is that really true of a LIFO queue?"}, {"attachment_id": null, "tags": [], "bug_id": 56798, "is_private": false, "count": 4, "id": 176846, "time": "2014-08-02T13:59:24Z", "creator": "brenuart@gmail.com", "creation_time": "2014-08-02T13:59:24Z", "text": "Lets talk about MRU and LRU strategies instead - these terms seem to be less confusing in this context.\n\nIn short, proposition is to follow a MRU strategy when checking out connections from the idle pool. This way, least recently used connections are the first to become eligible for eviction out of the pool.\n\nSo either we talk about the strategy used to checkout/borrow connections or the one followed to determine which connections should be evicted."}, {"count": 5, "tags": [], "creator": "chris@christopherschultz.net", "attachment_id": null, "id": 176855, "time": "2014-08-03T15:56:24Z", "bug_id": 56798, "creation_time": "2014-08-03T15:56:24Z", "is_private": false, "text": "(In reply to Sebb from comment #3)\n> (In reply to Christopher Schultz from comment #2)\n> \n> > Using a\n> > LIFO structure does in fact mean that the whole pool will stay \"hot\"\n> > regardless of how big it becomes... as long as the connections are used\n> > frequently enough.\n> \n> Surely you mean FIFO here?\n\nYes, I meant FIFO. Sorry for the confusing typo.\n\n> > But the frequency of a check-out is not really relevant: only the number of\n> > connections that are used /simultaneously/ is relevant. A site may be able\n> > to get away with a pool with a depth of 2 or 3 connections, but if the pool\n> > grows to 50 connections, they all might stay in the pool and not be evicted\n> > due to the LIFO behavior.\n> \n> Ditto\n>  \n> > I'm not sure if the LIFO queue gives a performance benefit -- because the\n> > head of the structure is only under contention for check-outs and the tail\n> > of the structure is only under contention for check-ins\n> \n> Huh? Is that really true of a LIFO queue?\n\nA queue is FIFO, a stack LIFO. To align the nomenclature, here, queue is FIFO / LRU and stack is LIFO / MRU.\n\nFor a stack/LIFO/MRU structure, there is only one \"hot\" end of the structure: both check-ins and check-outs are happening in the same place (the \"top\" of the stack). For a queue/FIFO/LRU structure, check-ins are happening at one end and check-outs are happening at the other end. So, depending upon the synchronization techniques used, the queue may offer better performance at the structure level -- even if the stack model gives a better outcome. It was just a thought."}, {"attachment_id": null, "tags": [], "bug_id": 56798, "is_private": false, "count": 6, "id": 176856, "time": "2014-08-03T17:00:09Z", "creator": "chuck.caldarale@unisys.com", "creation_time": "2014-08-03T17:00:09Z", "text": "The contention issue is a red herring.  Both a queue and a stack will normally have to be completely locked when inserting or removing items, since there may only be zero or one entries in the container at the time of the operation.  This will almost always outweigh any cache ping-ponging issues that could occur with a stack."}, {"count": 7, "tags": [], "bug_id": 56798, "attachment_id": null, "is_private": false, "id": 176965, "time": "2014-08-06T22:13:21Z", "creator": "brenuart@gmail.com", "creation_time": "2014-08-06T22:13:21Z", "text": "(In reply to Chuck Caldarale from comment #6)\nThe pool currently uses java.util.concurrent.ArrayBlockingQueue unless a \"fair\" implementation is requested (in which case a custom implementation is used).\n\nA stack/LIFO/MRU strategy could be built on top of a java.util.concurrent.LinkedBlockingDeque.\n\nI'm not an expert in concurrency issues but both implementations seem to make use of a single global lock for their put/get operations. We should therefore get the same performances except may be for a small penalty for the LinkedBlockingDeque due to the extra overhead of creating Nodes. \n\nI made a quick prototype by changing the idle pool into a LinkedBlockingDeque and ran about 100 concurrent threads asking for 10 thousands connections each. At first glance the difference between the two approaches is minimal. I haven't got any further though because you may already have been doing tests in that direction..."}]