[{"count": 0, "tags": [], "bug_id": 38793, "is_private": false, "id": 86255, "attachment_id": null, "creator": "mk-asf@gigacodes.de", "creation_time": "2006-02-27T17:31:02Z", "time": "2006-02-27T17:31:02Z", "text": "We run apache22 as reverse proxy to a backend application server (apache1.3).\nWhen we put apache22 under load ( ab -k -c 200 ) and restart the backend server,\nthere's a good chance of a segmentation fault. \n\nWe've done multiple runs and all Segfault backtraces shared the \nproxy_http_handler in mod_proxy_http.c with calls between the comments \"Step\nOne\" and \"Step Six\". The attached backtrace is the most common one. \n\nMy guess is, that when the first connection fails, it clears pooled\nconnections/ressources currently being used by other threads that are already in\nthe code between \"Step One\" and \"Step Six\", so their backend->connection gets\nnulled in the middle of doing something. In my opinion backend->connection\nshould never be 0 in this part of the code, since all failed functions would\ngoto cleanup. However backtrace shows them 0 as well as some cond breakpoints.\n(Although sometimes breakpoints get passed, but thread segfaults anyway).\n\n\n\n\n#0  0x08095f79 in ap_proxy_make_fake_req (c=0x0, r=0x19520540) at proxy_util.c:351\n        rp = (request_rec *) 0x94d53f0\n#1  0x0809b6ca in ap_proxy_http_process_response (p=0x94d42f8, r=0x19520540,\nbackend=0x917c0e0, origin=0x0, conf=0x91069d8,\n    server_portstr=0xaef82190 \"\") at mod_proxy_http.c:1206\n        c = (conn_rec *) 0x94d44e8\n        buffer = '\\0' <repeats 3420 times>,\n\"\\211\\003_\\000\\211\\003_\\000H\\037\\uffff\\uffff\\uffffG]\\000\\000\\000\\000\\000\\uffff)`\\000\\023\\000\\000\\000\\uffff\\016\\uffff\\uffff\\000\\000\\000\\000\\000\\000\\000\\000\\uffff\\036\\uffff\\uffff\\f\\000\\000\\000\\024\\000\\000\\000\\uffff!\\003D\\uffff\\016\\uffff\\uffff\\uffff\\016\\uffff\\uffff\\uffff\\036\\uffff\\uffff\\n\\000\\000\\000\\003\\000\\000\\001\\207F\\000\\000\\023\\000\\000\\000\\uffff\\016\\uffff\\uffff\\000\\020\\000\\000\\f\\000\\000\\000\\uffff\\036\\uffff\\uffff\\f\\000\\000\\000\\uffff\\016\\uffff\\uffff\\001\",\n'\\0' <repeats 19 times>,\n\"\\024\\000\\000\\000\\003\\000\\002\\000\\uffff!\\003D\\207F\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\024\\000\\001\",\n'\\0' <repeats 16 times>,\n\"\\001\\024\\000\\006\\000\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffff\\uffffd\\r\\000\\000d\\r\\000\\000@\\000\\000\\000\\024\\000\\002\\000\\uffff!\\003D\\207\"...\n        buf = 0xa <Address 0xa out of bounds>\n        keepchar = 100 'd'\n        rp = (request_rec *) 0x95037d8\n        e = (apr_bucket *) 0x312e302e\n        bb = (apr_bucket_brigade *) 0x94d53f0\n        len = -1\n        backasswards = 774909495\n        interim_response = 842082336\n        pread_len = 0\n        save_table = (apr_table_t *) 0x72656b72\n#2  0x0809c7e2 in proxy_http_handler (r=0x19520540, worker=0x9106db0,\nconf=0x91069d8, url=0x94d4ff0 \"/test/output.php?delay=10\",\n    proxyname=0x0, proxyport=0) at mod_proxy_http.c:1712\n        status = 0\n        server_portstr = \"\\000N\\r\\b]\\005\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000\ne\\030\\t\\uffffDM\\t@\\005R\\031\\000\\000\\000\"\n        scheme = 0x94d4f90 \"http\"\n        proxy_function = 0x80d5ff9 \"HTTP\"\n        u = 0x195217fa \"://127.0.0.1:8081/test/output.php?delay=10\"\n        backend = (proxy_conn_rec *) 0x917c0e0\n        is_ssl = 0\n        p = (apr_pool_t *) 0x94d42f8\n        c = (conn_rec *) 0x94d44e8\n        uri = (apr_uri_t *) 0x94d4f60\n#3  0x080951d5 in proxy_run_scheme_handler (r=0x19520540, worker=0x9106db0,\nconf=0x91069d8,\n    url=0x195217f6 \"http://127.0.0.1:8081/test/output.php?delay=10\",\nproxyhost=0x0, proxyport=0) at mod_proxy.c:1936\n        pHook = (proxy_LINK_scheme_handler_t *) 0x91dd358\n        n = 0\n        rv = 424810486\n#4  0x08092a3d in proxy_handler (r=0x19520540) at mod_proxy.c:739\n#5  0x0807cdcd in ap_run_handler (r=0x19520540) at config.c:157\n#6  0x0807d50d in ap_invoke_handler (r=0x19520540) at config.c:371\n#7  0x080b49d2 in ap_process_request (r=0x19520540) at http_request.c:258\n#8  0x080b1ee8 in ap_process_http_connection (c=0x94d44e8) at http_core.c:171\n#9  0x08084264 in ap_run_process_connection (c=0x94d44e8) at connection.c:43\n#10 0x08084693 in ap_process_connection (c=0x94d44e8, csd=0x94d4338) at\nconnection.c:178\n#11 0x080bddcb in process_socket (p=0x94d42f8, sock=0x94d4338, my_child_num=0,\nmy_thread_num=12, bucket_alloc=0x1951c4f8)\n    at worker.c:531\n#12 0x080be5d4 in worker_thread (thd=0x91a05c0, dummy=0x91dddc8) at worker.c:876\n#13 0xb7ef7868 in dummy_worker (opaque=0x91a05c0) at threadproc/unix/thread.c:138\n#14 0x006bb341 in start_thread () from /lib/tls/libpthread.so.0\n#15 0x005e36fe in clone () from /lib/tls/libc.so.6\n\n\nas mentioned this is the most common one but we even got segfaults here:\n\n#0  0xb7ed2246 in allocator_free (allocator=0x0, node=0x9b15110) at\nmemory/unix/apr_pools.c:319\n#1  0xb7ed2224 in apr_allocator_free (allocator=0x0, node=0x9b15110) at\nmemory/unix/apr_pools.c:384\n#2  0xb7fbd81f in apr_bucket_free (mem=0x9b15138) at buckets/apr_buckets_alloc.c:182\n#3  0xb7fbda6a in socket_bucket_read (a=0x9b011c8, str=0xb6a47f40,\nlen=0xb6a47f3c, block=APR_BLOCK_READ)\n    at buckets/apr_buckets_socket.c:71\n#4  0xb7fbe933 in apr_brigade_split_line (bbOut=0x9af8180, bbIn=0x9af81a8,\nblock=APR_BLOCK_READ, maxbytes=8192)\n    at buckets/apr_brigade.c:292\n#5  0x0807b024 in ap_core_input_filter (f=0x9af71d0, b=0x9af8180,\nmode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)\n    at core_filters.c:171\n#6  0x080878e3 in ap_get_brigade (next=0x9af71d0, bb=0x9af8180,\nmode=AP_MODE_GETLINE, block=APR_BLOCK_READ, readbytes=0)\n    at util_filter.c:489\n#7  0x0806e358 in ap_rgetline_core (s=0xb6a480a4, n=8192, read=0xb6a4809c,\nr=0x9af7400, fold=0, bb=0x9af8180) at protocol.c:222\n#8  0x0806e78f in ap_getline (s=0xb6a48120 \"\", n=8192, r=0x9af7400, fold=0) at\nprotocol.c:463\n#9  0x0809b70a in ap_proxy_http_process_response (p=0x9b04a98, r=0x9b11150,\nbackend=0x9a94e80, origin=0x9af6f90, conf=0x9a1f9d8,\n    server_portstr=0xb6a4a190 \"\") at mod_proxy_http.c:1214\n#10 0x0809c7e2 in proxy_http_handler (r=0x9b11150, worker=0x9a1fdb0,\nconf=0x9a1f9d8, url=0x9b05018 \"/test/output.php?delay=1\",\n    proxyname=0x0, proxyport=0) at mod_proxy_http.c:1712\n#11 0x080951d5 in proxy_run_scheme_handler (r=0x9b11150, worker=0x9a1fdb0,\nconf=0x9a1f9d8,\n    url=0x9b123fe \"http://127.0.0.1:8081/test/output.php?delay=1\",\nproxyhost=0x0, proxyport=0) at mod_proxy.c:1936\n#12 0x08092a3d in proxy_handler (r=0x9b11150) at mod_proxy.c:739\n#13 0x0807cdcd in ap_run_handler (r=0x9b11150) at config.c:157\n#14 0x0807d50d in ap_invoke_handler (r=0x9b11150) at config.c:371\n#15 0x080b49d2 in ap_process_request (r=0x9b11150) at http_request.c:258\n#16 0x080b1ee8 in ap_process_http_connection (c=0x9b04c88) at http_core.c:171\n#17 0x08084264 in ap_run_process_connection (c=0x9b04c88) at connection.c:43\n#18 0x08084693 in ap_process_connection (c=0x9b04c88, csd=0x9b04ad8) at\nconnection.c:178\n#19 0x080bddcb in process_socket (p=0x9b04a98, sock=0x9b04ad8, my_child_num=0,\nmy_thread_num=1, bucket_alloc=0x9b06aa0)\n    at worker.c:531\n#20 0x080be5d4 in worker_thread (thd=0x9ab88c0, dummy=0x9aa8a38) at worker.c:876\n#21 0xb7ede868 in dummy_worker (opaque=0x9ab88c0) at threadproc/unix/thread.c:138\n#22 0x006bb341 in start_thread () from /lib/tls/libpthread.so.0\n#23 0x005e36fe in clone () from /lib/tls/libc.so.6"}, {"count": 1, "tags": [], "bug_id": 38793, "text": "I did some more debugging and found a strange behaviour in ap_proxy_connect_backend\n\n#0  ap_proxy_connect_backend (proxy_function=0x80d5ff9 \"HTTP\", conn=0x9d0cfd8,\nworker=0x9c95db0, s=0x9d154c8) at proxy_util.c:2045\n        rv = 164679640\n        connected = 1\n        loglevel = 164190680\n        backend_addr = (apr_sockaddr_t *) 0x9d60a00\n        newsock = (apr_socket_t *) 0x9d8fa28\n#1  0x0809c748 in proxy_http_handler (r=0x9d99af8, worker=0x9c95db0,\nconf=0x9c959d8, url=0x9d91268 \"/test/output.php?delay=0\", proxyname=0x0,\nproxyport=0)\n    at mod_proxy_http.c:1691\n\nI put a breakpoint on the return statement in case that conn->sock is null,\nhowever the function will return true, because its internal newsock is valid and\nits connected counter is 1. (see stacktrace above). conn looks magically empty:\n\n(gdb) inspect conn->hostname\n$4 = 0x0\n(gdb) inspect conn->port\n$5 = 0\n(gdb) inspect conn->pool\n$6 = (apr_pool_t *) 0x9d60768\n(gdb) inspect conn->is_ssl\n$7 = 0\n(gdb) inspect conn->sock\n$8 = (apr_socket_t *) 0x0\n(gdb) inspect conn->addr\n$9 = (apr_sockaddr_t *) 0x0\n(gdb) inspect conn->flags\n$10 = 0\n(gdb) inspect conn->close\n$11 = 0\n(gdb) inspect conn->close_on_recycle\n$12 = 0\n(gdb) inspect conn->worker\n$13 = (proxy_worker *) 0x9c95db0\n\nconnected is only set right after conn->sock = newsock , both vars are never\ntouched until return then. How does conn become so empty ? I also do not have\nany of the error messages from ap_proxy_connect_backend in the error_log, so I\nassume the bad boy might be another thread.\n\nI get the following error messages from other threads and they are already int\nthe logfile when the above breakpoint is hit, so chances are that things get\nmessed up here.\n\n[Sat Mar 04 18:12:48 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Sat Mar 04 18:12:48 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n\nabove this errormessage is \nap_proxy_http_cleanup(NULL, r, backend);\nwhich i think is redundant as proxy_http_handler runs cleanup: anyway. removing\ndid not fix the problem. \n\nLet me know if this looks like something to go into deeper.\n(PS. We are running mod_worker)\n", "id": 86485, "time": "2006-03-04T19:18:30Z", "creator": "mk-asf@gigacodes.de", "creation_time": "2006-03-04T19:18:30Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 38793, "attachment_id": 17836, "is_private": false, "id": 86497, "time": "2006-03-05T14:13:23Z", "creator": "rpluem@apache.org", "creation_time": "2006-03-05T14:13:23Z", "text": "Created attachment 17836\nTemporary debug patch to narrow down the problem.\n\nCould you please apply the attached patch temporarily and set the LogLevel to\ndebug? A conn data structure should be only leased to one thread at the same\ntime from the connection pool. So in theory different threads should not have\naccess to the same data structure at the same time. The patch logs the aquire\nand release operations and hopefully helps to see if this is not the case."}, {"count": 3, "tags": [], "creator": "mk-asf@gigacodes.de", "attachment_id": null, "is_private": false, "id": 86541, "time": "2006-03-06T20:16:39Z", "bug_id": 38793, "creation_time": "2006-03-06T20:16:39Z", "text": "switch loglevel to debug eliminates problem ( probably because of a change in\ntiming because of the additional overhead).\n\nI changed the patch to log as ERROR. I grepped the logfile for the segfaulting\nbackend and all non \"backend\" messages:\n\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for\nrequest 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e20540, connection 0xaa01ab08, pid 13549, tid 0xb4184bb0\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for\nrequest 0xaa034be8, connection 0xaa030d90, pid 13549, tid 0xadd7abb0\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Aquired backend 0x987bff8 for\nrequest 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: error reading\nstatus line from remote server (null)\n[Mon Mar 06 19:37:35 2006] [error] [client 127.0.0.1] proxy: Error reading from\nremote server returned by /test/output.php\n[Mon Mar 06 19:37:35 2006] [error] proxy: HTTP: Released backend 0x987bff8 for\nrequest 0xa9e2a568, connection 0xaa018a90, pid 13549, tid 0xaf17cbb0\n\nThe backend gets released, \"error reading status line\" gets logged, and the same\nbackend gets released again. Afterwards it gets acquired by 2 different threads. \nOne thread fails with same error (0xaf17cbb0) releasing the backend, the other\nthread gets the segfault (0xadd7abb0) while in ap_proxy_connection_create. (gdb bt).\n\nI suspect   ap_proxy_http_cleanup(NULL, r, backend)   in line 1220 ( and 1246,\nnumbers my vary because of your patch ) of mod_proxy_http.c to be the problem,\nas mentioned in previous comment, it gets called there and again in line 1741,\nafter the cleanup:-goto.  I don't know what the proxy_function argument means in\nline 1741, because the other cleanups are called with NULL ?\n\n\n\nRemoving line 1220 eliminates the Segfaults. But I get these lines after some\ntime running ab:\n\n(99)Cannot assign requested address: proxy: HTTP: attempt to connect to\n127.0.0.1:8081 (127.0.0.1) failed\n\nI guess this could be related to a temporary shortage of tcp-ip source ports\n(I'm running ab from the same machine and it never happens for the first 20000\nrequests)"}, {"count": 4, "tags": [], "bug_id": 38793, "is_private": false, "id": 86544, "attachment_id": null, "creator": "mk-asf@gigacodes.de", "creation_time": "2006-03-06T20:35:24Z", "time": "2006-03-06T20:35:24Z", "text": "BTW: this also fixes the \" remote server (null) \" thing of the error line.\nsee also: http://issues.apache.org/bugzilla/show_bug.cgi?id=37770#c2\n\n"}, {"count": 5, "tags": [], "text": "Many thanks for the update. It was very helpful. The problem seems to be caused\nby the fact that apr_reslist_release does not notice \"double releases\" (see also\nhttp://marc.theaimsgroup.com/?l=apr-dev&m=114168465029319&w=2).\nI am checking now if this is a bug inside apr-util or inside the proxy code.\nIf it is a bug inside the proxy code, I need to implement additional measures to\nprevent such \"double releases\" (apart from removing the unnecessary double calls\nto ap_proxy_http_cleanup which you already mentioned). These additional measures\nshould help track down such issues faster in the future and prevent the server\nfrom segfaulting in such situations. I'll keep you updated.", "is_private": false, "bug_id": 38793, "id": 86552, "time": "2006-03-06T23:04:21Z", "creator": "rpluem@apache.org", "creation_time": "2006-03-06T23:04:21Z", "attachment_id": null}, {"count": 6, "tags": [], "creator": "rpluem@apache.org", "is_private": false, "id": 86724, "attachment_id": 17874, "bug_id": 38793, "creation_time": "2006-03-12T00:12:52Z", "time": "2006-03-12T00:12:52Z", "text": "Created attachment 17874\nPatch against trunk to fix double return of connections to pool\n\nI created a patch that removes the double calls to ap_proxy_http_cleanup and\nadds a check if a connection has been already returned to the connection pool\nbefore. Could you please give the patch a try and let me know if this fixes\nyour problem and if you do not see any error messages of \"proxy: Pooled\nconnection 0x%pp for worker %s has been already returned to the connection\npool.\". Thanks."}, {"count": 7, "tags": [], "bug_id": 38793, "text": "We applied the patch about 10 days ago, no double-free warnings so far. Crash is\nno longer reproducable with ab in test environment. \n\nHowever we are still seeing segfaults in our logfiles in production use. I have\nthe suspect it might be related to mod_ssl, but I did not have time to look into\nthis so far. \n\nSo this patch is probably ready to roll, although there's more to do ...", "id": 87348, "time": "2006-03-28T12:13:53Z", "creator": "mk-asf@gigacodes.de", "creation_time": "2006-03-28T12:13:53Z", "is_private": false, "attachment_id": null}, {"count": 8, "tags": [], "bug_id": 38793, "is_private": false, "id": 88060, "creation_time": "2006-04-14T13:20:56Z", "time": "2006-04-14T13:20:56Z", "creator": "rpluem@apache.org", "text": "Committed patch to trunk as r394088\n(http://svn.apache.org/viewcvs?rev=394088&view=rev).", "attachment_id": null}, {"count": 9, "tags": [], "creator": "rpluem@apache.org", "attachment_id": null, "is_private": false, "id": 88149, "time": "2006-04-17T10:43:44Z", "bug_id": 38793, "creation_time": "2006-04-17T10:43:44Z", "text": "Proposed for backport to 2.2.x as r394653\n(http://svn.apache.org/viewcvs?rev=394653&view=rev)."}, {"count": 10, "tags": [], "bug_id": 38793, "attachment_id": null, "is_private": false, "id": 88381, "time": "2006-04-22T15:28:30Z", "creator": "rpluem@apache.org", "creation_time": "2006-04-22T15:28:30Z", "text": "Backported to 2.2.x as r396049 ( http://svn.apache.org/viewcvs?rev=396049&view=rev)."}]