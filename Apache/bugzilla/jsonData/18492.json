[{"count": 0, "tags": [], "bug_id": 18492, "attachment_id": null, "id": 34108, "time": "2003-03-29T17:22:12Z", "creator": "mike@thetroubleshooters.dk", "creation_time": "2003-03-29T17:22:12Z", "is_private": false, "text": "I have set up a really simple html file to upload a file.\n\n<html>\n<head>\n</head>\n<body>\n<form method=\"POST\" enctype=\"multipart/form-data\" action=\"cgi-bin/env.cgi\">\nFile to upload: <input type=\"file\" name=\"upfile\"><br><br>\n<input type=submit >\n</form>\n</body>\n</html>\n\n\n\nThis calls a very simple cgi script.\n\n#!/bin/bash\necho \"Content-type:text/html\"\necho \"\"\necho '<HTML><BODY><PRE>'\nenv\necho \"data\"\ncat\necho \"done data\"\necho '</pre><body></html>'\n\n\n\nThese are about the simplest test case that I can imagine for this kind of\nthing.    The \"cat\" command will simply print anything transmitted to standard\nout, and in turn back to the browser.\n\nHowever..\n\nUploading a file results in an enormous wait time before the page actually\nreturns, and the data that is displayed is only a very small fraction of the\ntotal data transmitted from the file..  The main file is about 500k, and the\namount of data shown is probably in the vicinity of 2-3k.\n\nUsing TCP dump I can see that the browse (mozilla Version 1.3 final) does indeed\ntransmit the amount of data, corresponding roughly, to the 500k that was\nintended to be transmitted..  However The application (cgi script) does not see\nall of the data.\n\nIt may be a configuration issue, however, search as I may (www.google.com, and\nwww.apache.org, for \"file upload problem\"), I find lots of examples on how to\nimplement the server side code.   All scripts, all attempts at performing the\nfile upload results in the very same problem.\n\n1.  it hangs for an extremely long time.\n2.  When it finally returns (if it finally returns), only a part of the data is\nactually received by the CGI.\n\nThe application that I intend to use is a perl script I found on the web, this\nscript works fine in several other installations, however on my system it simply\nhangs forever.  Trying to debug it, I reduced the cgi script, and the html page\nto their bare essentials, and the problem persists..  Initially I was using\napache version 2.0.39, but upgraded to 2.0.44 hoping it may solve the problem,\nboth seem to have the same problems.\n\nI have reverted the convfiguration file (httpd.conf) back to the original\nstandard version that is distributed with the apache distribution, and have then\nadded in the changes necessary to reference my web page...  However to no avail,\nthe problem persists."}, {"count": 1, "tags": [], "bug_id": 18492, "attachment_id": null, "id": 34712, "time": "2003-04-08T11:39:53Z", "creator": "trawick@apache.org", "creation_time": "2003-04-08T11:39:53Z", "is_private": false, "text": "The problem is that mod_cgi[d] doesn't start reading output from the script\nuntil it has transferred the entire request body to the script.  So scripts that\ngenerate more than 4K* of output before reading all the request body will block\nwhile writing the response body since mod_cgi[d] isn't reading, and mod_cgi[d]\nwill block writing the request body since the script isn't reading.\n\n*replace 4K with whatever the kernel buffer size is for pipes (mod_cgi) or Unix\nsockets (mod_cgid)\n\nI was able to reproduce this and put together a test patch yesterday. \nUnfortunately, the way the patch worked was to save all intermediate output in a\nbrigade prior to the point where we had written all of the request body to the\nscript, so we can pass that brigade (with the pipe bucket behind it) to \nap_scan_script_header_err_brigade().  But that brigade could hold arbitrary\namounts of data (memory use unbounded), so this doesn't seem to be a good\nsolution.  Some changes would be needed to the way we scan for header lines in\nthe script output so that it can be accomplished even before we finish writing\nthe request body to the script.\n\nI'll attach the clumsy patch I was playing with in case anybody is interested.\nI don't think it should be used as-is unless perhaps in an environment where it\nis known that the script output won't be unbounded up until the point that the\nrequest body has been written to the script.\n\nOn the somewhat-bright side, it looks like this was broken in Apache 1.3 too,\nso there is some indication that this problem wasn't a showstopper for everyone.\n"}, {"count": 2, "tags": [], "creator": "trawick@apache.org", "attachment_id": 5691, "id": 34714, "time": "2003-04-08T11:41:00Z", "bug_id": 18492, "creation_time": "2003-04-08T11:41:00Z", "is_private": false, "text": "Created attachment 5691\nhack mod_cgi to suck up script output as necessary while writing request body to script"}, {"count": 3, "tags": [], "bug_id": 18492, "attachment_id": null, "id": 62666, "time": "2004-08-29T20:30:56Z", "creator": "nick@webthing.com", "creation_time": "2004-08-29T20:30:56Z", "is_private": false, "text": "cat will listen on stdin until it gets EOF (or timeout).\n\nBut CGI doesn't offer you an EOF.  So that's a bug in your script, and hanging\nindefinitely is expected behaviour.\n\nCan you reproduce it with a script that reads CONTENT_LENGTH bytes, as expected\nby the CGI spec?\n"}, {"count": 4, "text": "No response to my last comment - assume noone is interested.\nNotabug in the sense that it won't happen with a valid CGI script.", "bug_id": 18492, "attachment_id": null, "id": 64230, "time": "2004-09-26T15:57:32Z", "creator": "nick@webthing.com", "creation_time": "2004-09-26T15:57:32Z", "tags": [], "is_private": false}]