[{"count": 0, "tags": [], "text": "An strace gives me the following...\n\n...\ngettimeofday({1046470949, 388345}, NULL) = 0\npoll([{fd=10, events=POLLIN, revents=POLLIN}], 1, 5000) = 1\nrecvfrom(10, \"\\213o\\201\\200\\0\\1\\0\\1\\0\\2\\0\\2\\4code\\vnewsclr\\3co\"..., 65536, 0\n, {sa_family=AF_INET, sin_port=htons(53), sin_addr=inet_addr(\"142.77.2.36\")}, \n[1\n6]) = 131\nclose(10)                               = 0\nsocket(PF_INET, SOCK_STREAM, IPPROTO_IP) = 10\nconnect(10, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr\n(\"207.126.64.50\")}, 16) = 0\nsend(10, \"GET /1/code.js\"..., 43, 0) = 43\nsend(10, \"Host: www.domain.com\\r\\n\", 28, 0) = 28\nsend(10, \"\\r\\n\", 2, 0)                  = 2\nselect(11, [10], NULL, NULL, {60, 0})   = 1 (in [10], left {59, 930000})\nrecv(10, 0x83d4d64, 8192, 0)            = -1 ECONNRESET (Connection reset by \npee\nr)\nfsync(10)                               = -1 EINVAL (Invalid argument)\nshutdown(10, 0 /* receive */)           = -1 ENOTCONN (Transport endpoint is \nnot\n connected)\nselect(11, NULL, [10], [10], NULL\n\n-- It just ends there.  Lots of these processes are just accumulating waiting \nfor the same thing.\n\n any ideas?", "attachment_id": null, "bug_id": 17548, "id": 32189, "time": "2003-02-28T22:35:34Z", "creator": "mike@epicworks.com", "creation_time": "2003-02-28T22:35:34Z", "is_private": false}, {"count": 1, "tags": [], "text": "Basically, at what appears to be random intervals, it gets to this point, and \nthe process just stops at that last SELECT noted below.  So the process does \nnothing useful from then on.  Eventually it increases the clients until it \nreaches MaxClients and then everyone just waits permenantly. and no requests \nget served.\n\n  sending a graceful restart just adds the following...\n    = ? ERESTARTNOHAND (To be restarted)\n--- SIGUSR1 (User defined signal 1) @ 0 (0) ---\nselect(11, NULL, [10], [10], NULL\n\nand we appear to be back where we started.\n\n Using GLIBC2.3.1 if it affects anything.\n\nAny thoughts?  This appears ot be just on this one server.\n", "is_private": false, "bug_id": 17548, "id": 32193, "time": "2003-02-28T22:51:16Z", "creator": "mike@epicworks.com", "creation_time": "2003-02-28T22:51:16Z", "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 17548, "text": "This looks like mod_proxy and I suspect that the select() call showing up\nas this\n\nselect(11, NULL, [10], [10], NULL\n\nshould be changed to also pop when the socket descriptor is readable (to handle\nthe case where there is an error on the socket, which is the current situation).\nHopefully that works when the socket has been shutdown for recv... never done\nthat :)\n\nAny chance you can attach to one of these hanging processes with gdb and get a\nbacktrace to post?  Thanks!\n\n", "id": 32204, "time": "2003-03-01T01:25:21Z", "creator": "trawick@apache.org", "creation_time": "2003-03-01T01:25:21Z", "is_private": false, "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 17548, "attachment_id": null, "id": 32206, "time": "2003-03-01T01:34:19Z", "creator": "mike@epicworks.com", "creation_time": "2003-03-01T01:34:19Z", "is_private": false, "text": "according to http -l, I don't have mod_proxy in there, and that is similar to \nme disabling it from the start.  It seems to be as it was normally serving a \nrequest of a dynamic web page.\n  I'll try and get a gdb debugger next time I find them.  It seems to not do \nit for a day or two and then start doing it for a bit.  Not sure why exactly.  \nI'll grab one next time I get notified of MaxClients again.\n\nThanks for your help."}, {"count": 4, "tags": [], "bug_id": 17548, "attachment_id": null, "is_private": false, "id": 32211, "time": "2003-03-01T02:24:00Z", "creator": "trawick@apache.org", "creation_time": "2003-03-01T02:24:00Z", "text": "I guess I need to be hit by a big stick, because I can't think of any other code\nin Apache that is going to do a DNS lookup, get a socket, connect to another\nserver, send HTTP request, and try to read some response.  What am I missing?\n\nYes, a gdb backtrace would be very useful :)\n\n(and when you check for modules in use, make sure you check not just `httpd -l`\nbut also for `grep -i LoadModule httpd.conf`)\n"}, {"attachment_id": null, "tags": [], "bug_id": 17548, "text": "Makes me wonder if it's PHP that's doing it.  I woudln't spend too much time \non it for that reason.  I'm going to try and track it down more, but I have a \nfeeling it's PHP then.\n-M", "count": 5, "id": 32212, "time": "2003-03-01T04:25:11Z", "creator": "mike@epicworks.com", "creation_time": "2003-03-01T04:25:11Z", "is_private": false}, {"count": 6, "tags": [], "text": "...left at \"probably a PHP bug\" given no further information.", "attachment_id": null, "id": 65583, "creator": "jorton@redhat.com", "time": "2004-10-23T11:55:51Z", "bug_id": 17548, "creation_time": "2004-10-23T11:55:51Z", "is_private": false}]