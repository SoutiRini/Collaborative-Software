[{"count": 0, "tags": [], "bug_id": 51218, "text": "Hi,\n\nWe have two problems :\n\n1. FOP Performs unusually SLOW if there is a large paragraph\nWe have noticed that when there is an unusually large paragraph than FOP performance is incredibly slow. FOP takes more than 15 minutes in the method findBreakingPoints which is defined in BreakingAlgorithm.java. The paragraph size is of around 50 thousand characters. This method seems to find the best possible Break point. Can we not make this method return a default break point that works for the English language ?\n\n2. FOP uses unusually large memory when running in findBreakingPoints method defined in BreakingAlgorithm.java. This method starts to consume around 500 MB memory creating thousands of Objects of KnuthNode type. Such memory consumption is unacceptable just for finding a line break :-(.\n\n2. FOP gives a SAX Exception on having a long paragraph in Systems which dont have 1.5 GB RAM for a simple paragraph which has 90K Characters. Below is the exception \njavax.xml.transform.TransformerConfigurationException: javax.xml.transform.TransformerException: org.xml.sax.SAXParseException: The element type \"xsl:template\" must be terminated by the matching end-tag \"</xsl:template>\".\n                at org.apache.xalan.processor.TransformerFactoryImpl.newTemplates(TransformerFactoryImpl.java:995)\n                at com.ca.calm.reporter.pdf.PDFGenerator.buildPdf(PDFGenerator.java:1271) \nCaused by: javax.xml.transform.TransformerException: org.xml.sax.SAXParseException: The element type \"xsl:template\" must be terminated by the matching end-tag \"</xsl:template>\".\n                at org.apache.xalan.processor.TransformerFactoryImpl.newTemplates(TransformerFactoryImpl.java:991)\n                ... 6 more\nCaused by: org.xml.sax.SAXParseException: The element type \"xsl:template\" must be terminated by the matching end-tag \"</xsl:template>\".\n                at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)\n                at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)\n                at\n\n\nIs there a way, I can prevent this extensive memory usage and slow performance by using a default break ? I am ready to build the JAR myself. Is this a bug which has already been fixed ?\n\nthanks,\nJeet.", "id": 146415, "time": "2011-05-18T12:45:24Z", "creator": "abhijeet.iitr@gmail.com", "creation_time": "2011-05-18T12:45:24Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 51218, "is_private": false, "text": "Have you tried using FOP 1.0? 0.20 is no longer supported.", "id": 146416, "time": "2011-05-18T13:02:45Z", "creator": "med1985@gmail.com", "creation_time": "2011-05-18T13:02:45Z", "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 51218, "text": "Corrected the version. It is 1.0.", "id": 146417, "time": "2011-05-18T13:06:27Z", "creator": "abhijeet.iitr@gmail.com", "creation_time": "2011-05-18T13:06:27Z", "is_private": false, "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 51218, "text": "(In reply to comment #0)\n> \n> 1. FOP Performs unusually SLOW if there is a large paragraph\n> We have noticed that when there is an unusually large paragraph than FOP\n> performance is incredibly slow. FOP takes more than 15 minutes in the method\n> findBreakingPoints which is defined in BreakingAlgorithm.java. The paragraph\n> size is of around 50 thousand characters. This method seems to find the best\n> possible Break point. Can we not make this method return a default break point\n> that works for the English language ?\n\nSorry, I do not understand the point you are trying to make here. \nWhat is 'unusual' is having a paragraph with 50K chars in the first place, and then expecting an advanced layout algorithm to just process this as fast as one with only 500 chars.\n\nAdmittedly, FOP has a scalability problem here, but 50K chars? Really? Who is supposed to read that?\n\nCould it be that the paragraph is pre-formatted, perhaps? That is: Does it contain linefeeds that may be preserved? In that case, specify linefeed-treatment=\"preserve\" on the surrounding block and it will go significantly faster.\n\n> \n> 2. FOP uses unusually large memory when running in findBreakingPoints method\n> defined in BreakingAlgorithm.java. This method starts to consume around 500 MB\n> memory creating thousands of Objects of KnuthNode type. Such memory consumption\n> is unacceptable just for finding a line break :-(.\n\nIt is not 'finding a line-break'. It determines the most optimal line-breakS (plural).\n\nAnd again: we know of this issue, but fixing it is non-trivial, unfortunately.\n\n> Is there a way, I can prevent this extensive memory usage and slow performance\n> by using a default break ?\n\nYou can, as suggested above, make sure the linefeeds are preserved, if that is what you mean by 'default break'. Each line will then become a sub-paragraph, and the complete paragraph will take only a fraction of the time and memory to process.\n\nThe only other option is to split that monster-paragraph into smaller ones. Divide and conquer.", "id": 146432, "time": "2011-05-18T18:45:18Z", "creator": "adelmelle@apache.org", "creation_time": "2011-05-18T18:45:18Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "creator": "abhijeet.iitr@gmail.com", "is_private": false, "text": "Hi Andreas, \n\nThis data is coming as a part of the feed so I have no direct control over it. Most of the times we do get only small paragraphs in it.\n\n1. Your suggestion of adding (linefeed-treatment=\"preserve\") somehow didn't have any visible affect. I am putting the XSL below. However, I did see that this reduced the memory usage which doesn't grow exponentially anymore. I added tag to the block and other places too :-(\n\n2. Interestingly it looks that a default line break is coming in all the feeds that have large content. eg. \n\nInteractive&lt;br&gt;Group connections222 :&lt;br&gt;\n\nCan I use the custom BR tag to improve performance and reduce memory foot print ?\n\nA writeup is mentioned at http://www.stylusstudio.com/xsllist/200312/post00590.html\n\n3. Is there any other way to optimize performance findBreakingPoints by compromising formatting ? Like you mentioned a paragraph of larger than 50 thousand characters in difficult to read anyways. All I want is that the paragraph gets printed even if ill formatted. \n\nThanks in advance.", "id": 146468, "time": "2011-05-19T13:50:47Z", "bug_id": 51218, "creation_time": "2011-05-19T13:50:47Z", "attachment_id": null}, {"count": 5, "tags": [], "creator": "adelmelle@apache.org", "is_private": false, "text": "(In reply to comment #4)\n> \n> 1. Your suggestion of adding (linefeed-treatment=\"preserve\") somehow didn't\n> have any visible affect. I am putting the XSL below. However, I did see that\n> this reduced the memory usage which doesn't grow exponentially anymore. I added\n> tag to the block and other places too :-(\n\nBy 'no visible effect', do you mean in the output?\n\n> 2. Interestingly it looks that a default line break is coming in all the feeds\n> that have large content. eg. \n> \n> Interactive&lt;br&gt;Group connections222 :&lt;br&gt;\n> \n> Can I use the custom BR tag to improve performance and reduce memory foot print\n> ?\n\nDefinitely. That gives the line-layout algorithm hints about where a break MUST occur, and that allows at least some optimization, however... (see below)\n\n> A writeup is mentioned at\n> http://www.stylusstudio.com/xsllist/200312/post00590.html\n\n... In cases where you are sure that the <br/> just appears in between plain text, it is more optimal to transform it into a literal linefeed character (U+000A), and set linefeed-treatment on the parent block.\nThat will reduce memory usage even further. Empty blocks generate enough overhead to justify avoiding too many of those.\n\n> > 3. Is there any other way to optimize performance findBreakingPoints by\n> compromising formatting ? Like you mentioned a paragraph of larger than 50\n> thousand characters in difficult to read anyways. All I want is that the\n> paragraph gets printed even if ill formatted.\n\nSee above: I think that, apart from injecting forced breaks in the input, I do not immediately see a way to optimize further.", "id": 146471, "time": "2011-05-19T18:07:16Z", "bug_id": 51218, "creation_time": "2011-05-19T18:07:16Z", "attachment_id": null}, {"count": 6, "tags": [], "bug_id": 51218, "text": "Hi,\n\n        I haver tried with \".\" as delimiter and I dont find any change or any improvement while exporting to pdf.Please comment if you have any suggestions\n\nThanks,\nDeepthi", "id": 146923, "time": "2011-06-07T12:06:22Z", "creator": "deeba02@gmail.com", "creation_time": "2011-06-07T12:06:22Z", "is_private": false, "attachment_id": null}, {"count": 7, "tags": [], "creator": "gadams@apache.org", "attachment_id": null, "text": "resetting severity from major to normal pending further review", "id": 157263, "time": "2012-04-07T01:37:07Z", "bug_id": 51218, "creation_time": "2012-04-07T01:37:07Z", "is_private": false}, {"count": 8, "tags": [], "bug_id": 51218, "text": "resetting P2 open bugs to P3 pending further review", "id": 157436, "time": "2012-04-07T01:42:57Z", "creator": "gadams@apache.org", "creation_time": "2012-04-07T01:42:57Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "bug_id": 51218, "is_private": false, "text": "please provide minimal input FO test file, output PDF file(s), and full console output that demonstrates problem", "id": 157669, "time": "2012-04-08T05:17:27Z", "creator": "gadams@apache.org", "creation_time": "2012-04-08T05:17:27Z", "attachment_id": null}, {"count": 10, "tags": [], "creator": "gadams@apache.org", "is_private": false, "text": "(In reply to comment #9)\n> please provide minimal input FO test file, output PDF file(s), and full console\n> output that demonstrates problem\n\nAbhijeet, I am still awaiting your input as requested above. if I see no further input by April 30, I will close this bug due to lack of requested information. Regards, Glenn", "id": 158346, "time": "2012-04-24T05:42:25Z", "bug_id": 51218, "creation_time": "2012-04-24T05:42:25Z", "attachment_id": null}, {"count": 11, "tags": [], "bug_id": 51218, "is_private": false, "text": "this is an outofmemory issue so what does not work in one machine may work in some other. you only see the issue if your machine runs out of memory in which case you see the usual outofmemory error/exception. when that happens there is no output PDF.\n\nany very long paragraph of non self repeating content should work as an example. self repeating a short sentence to create a long paragraph is not a good example since the line breaking algorithm may break lines always in the same place.", "id": 158365, "time": "2012-04-24T08:40:44Z", "creator": "lmpmbernardo@gmail.com", "creation_time": "2012-04-24T08:40:44Z", "attachment_id": null}, {"count": 12, "tags": [], "creator": "lmpmbernardo@gmail.com", "attachment_id": 28665, "text": "Created attachment 28665\nexample\n\nrepeat the content inside the block (it is long enough to not trigger a simple line breaking solution) enough times until you see the problem.", "id": 158366, "time": "2012-04-24T08:45:26Z", "bug_id": 51218, "creation_time": "2012-04-24T08:45:26Z", "is_private": false}, {"count": 13, "tags": [], "bug_id": 51218, "text": "this is a resource (memory) issue, not a bug; if someone wishes to post a patch that redesigns the line breaker to operate more efficiently, then it will be given serious consideration;", "id": 158376, "time": "2012-04-24T13:19:50Z", "creator": "gadams@apache.org", "creation_time": "2012-04-24T13:19:50Z", "is_private": false, "attachment_id": null}, {"count": 14, "tags": [], "bug_id": 51218, "is_private": false, "id": 158573, "attachment_id": null, "creator": "gadams@apache.org", "creation_time": "2012-04-30T00:14:54Z", "time": "2012-04-30T00:14:54Z", "text": "batch transition resolved+wontfix to closed+wontfix"}, {"count": 15, "tags": [], "creator": "gadams@apache.org", "attachment_id": null, "is_private": false, "id": 158618, "time": "2012-04-30T00:17:19Z", "bug_id": 51218, "creation_time": "2012-04-30T00:17:19Z", "text": "batch transition resolved+wontfix to closed+wontfix; if you believe this remains a bug and can demonstrate it with appropriate input FO file and output PDF file (as applicable), then you may reopen"}]