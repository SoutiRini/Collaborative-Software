[{"count": 0, "tags": [], "bug_id": 47750, "text": "Running a load-balanced worker with two nodes - configuration is fine, as ISAPI filter starts up and works correctly.\n\nA change is made to a worker node using the jkstatus page (for example, stopping node2, then starting it again).  This works fine, as the worker stops correctly, then becomes available again and works fine.\n\nAfter an amount of time, the mod_jk log shows the ISAPI filter starting again - presumably this is IIS restarting something, although it doesn't behave the same as an app pool recycle so not sure what it is or what is triggering it.\nWhen this happens, the log shows the shared memory being reset in the log for the workers, and what appears to be the shm being updated with the previous values from the load-balancer worker's memory, although the sequence number from memory doesn't match the value that was previously reached from performing the updates via jkstatus:\njk_lb_worker.c (347): syncing shm for lb 'node-lb' from mem (0->1)\n\nThe log them shows shared memory for the load-balancer being synced again under worker maintenance - the sequence numbers do not match, with the value of p->sequence being the value previously reached from making the jkstatus changes, while the shm sequence is still 1 as a result of the previous sync.\nSo the log shows:\njk_lb_worker.c (292): syncing mem for lb 'node-lb' from shm (3->1)\n\nThe log then shows that, as a result of this lb sync, the \"changed\" workers are then sync'd from the shm.  However, as the data structure of the shm has been reset by the \"restart\" of the ISAPI filter, the values for that worker are set to zero.  As this includes the max_packet_size, any request to this worker will be larger than the max packet size of zero and so causes an \"error 413 request entity too large\" to be displayed.\n\nThe zero'd records display as such for the worker in jkstatus - manually updating these entries to the correct values allows that worker to function again.\n\n\nI have made a small amendment on my system so that any calls to jk_lb_pull will only occur if the mem sequeunce is less than the shm sequeunce (rather than just \"not equal\"), ie.\nchanged:\n    if (p->sequence != p->s->h.sequence)\n        jk_lb_pull(p, JK_TRUE, l);\nto:\n    if (p->sequence < p->s->h.sequence)\n        jk_lb_pull(p, JK_TRUE, l);\nfor all instances where jk_lb_pull is called as a result of this conditional.\nIt seems to have resolved this particular issue and the settings persist correctly, but not sure if it is actually a correct solution!", "id": 129995, "time": "2009-08-27T10:19:06Z", "creator": "robert.mawer@capita.co.uk", "creation_time": "2009-08-27T10:19:06Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "text": "I can see the problem. In order to fix it in the right way, I would like to understand, why the redirector does a second initialization.\n\nAs far as I can see, it is a second IIS process (separate process ID) that attaches to the shm and wipes it out. I can easily prevent that efect (the zeroing of the shared memory), but it would be more correct, if the second process actually got the right data from the already existing shared memory.\n\nAre you using web gardens and/or application pools? Which one of those and how are they configured?\n\nCould you please also provide your workers.properties and uriworkermap.properties as well as the isapi_redirect.properties.", "attachment_id": null, "id": 130105, "creator": "rainer.jung@kippdata.de", "time": "2009-09-01T10:50:22Z", "bug_id": 47750, "creation_time": "2009-09-01T10:50:22Z", "is_private": false}, {"count": 2, "tags": [], "text": "Created attachment 24198\nworkers.properties file", "attachment_id": 24198, "id": 130106, "creator": "robert.mawer@capita.co.uk", "time": "2009-09-01T12:06:42Z", "bug_id": 47750, "creation_time": "2009-09-01T12:06:42Z", "is_private": false}, {"count": 3, "tags": [], "creator": "robert.mawer@capita.co.uk", "attachment_id": 24199, "text": "Created attachment 24199\nisapi redirect file", "id": 130107, "time": "2009-09-01T12:07:06Z", "bug_id": 47750, "creation_time": "2009-09-01T12:07:06Z", "is_private": false}, {"count": 4, "tags": [], "bug_id": 47750, "text": "Created attachment 24200\nURI worker map", "id": 130108, "time": "2009-09-01T12:07:28Z", "creator": "robert.mawer@capita.co.uk", "creation_time": "2009-09-01T12:07:28Z", "is_private": false, "attachment_id": 24200}, {"count": 5, "tags": [], "bug_id": 47750, "text": "(In reply to comment #1)\n> I can easily prevent that efect (the\n> zeroing of the shared memory), but it would be more correct, if the second\n> process actually got the right data from the already existing shared memory.\nI did try zeroing the data to start with, but yes, it's not ideal for the worker status/changes to not be persistent when the second process starts!\n\n> Are you using web gardens and/or application pools? Which one of those and how\n> are they configured?\nJust running it out of the DefaultAppPool.\nRecycle worker processes set to 1740 minutes; Shutdown idle worker processes after being idle for 20 minutes; Limit kernel requests to 100; Maximum number of worker processes in the webgarden is set to 1.\nPinging is enabled and set to 30 seconds.\nRapid-fail protection is set to 5 failures in 5 minutes.\nStartup and shutdown time limits are set to 90 seconds.\nProcess is running as Network Service.\n\nThere are other applications running in the DefaultAppPool - I'm not sure if these could be influencing the second process starting?\n\n> Could you please also provide your workers.properties and\n> uriworkermap.properties as well as the isapi_redirect.properties.\nHave attached these to the bug report.", "id": 130109, "time": "2009-09-01T12:15:31Z", "creator": "robert.mawer@capita.co.uk", "creation_time": "2009-09-01T12:15:31Z", "is_private": false, "attachment_id": null}, {"count": 6, "tags": [], "bug_id": 47750, "text": "Thanks for the config, will have a look.\n\nThe request which triggered the second start was using the URL\n\n/EODPut/225/TEST.EOD225.20090826.txt\n\nand going to the same server name as all the other requests. Still reasoning, why this request started another (second) process.", "id": 130110, "time": "2009-09-01T12:41:20Z", "creator": "rainer.jung@kippdata.de", "creation_time": "2009-09-01T12:41:20Z", "is_private": false, "attachment_id": null}, {"count": 7, "tags": [], "bug_id": 47750, "attachment_id": null, "id": 130111, "time": "2009-09-01T12:43:14Z", "creator": "rainer.jung@kippdata.de", "creation_time": "2009-09-01T12:43:14Z", "is_private": false, "text": "config looks resonable."}, {"count": 8, "tags": [], "bug_id": 47750, "attachment_id": null, "id": 130112, "time": "2009-09-01T13:47:08Z", "creator": "robert.mawer@capita.co.uk", "creation_time": "2009-09-01T13:47:08Z", "is_private": false, "text": "(In reply to comment #6)\n> Thanks for the config, will have a look.\n> The request which triggered the second start was using the URL\n> /EODPut/225/TEST.EOD225.20090826.txt\n> and going to the same server name as all the other requests. Still reasoning,\n> why this request started another (second) process.\n\nThis is a WebDAV location, and the particular call above writes a file into the location - I did wonder if this was the trigger, but further experimentation showed that:\n1.  Calls to the WebDAV location don't usually trigger another start.\n2.  Other URLs trigger the start.\n\nAdditionally WebDAV is using a different application pool, so in theory should be separated from ISAPI redirect.  I also have another environment which experiences the originally reported condition, and that doesn't have WebDAV on it."}]