[{"count": 0, "tags": [], "bug_id": 23000, "text": "I run JMeter from Ant.\n\nWhen it reaches a Jmeter script (14 MB), it gives an out of memory error and \ndies, but it does not alert me to this. When I view the Jmeter report, I see \nthat fewer samplers were run that I had expected, and that was when I \ninvestigated and found out about the out of memory error.\n\nI increased the memory using the command line -- up to 512, but it was still \ngiving me the same error.\n\nIs there a limit to the size of JMeter script that can be run? If so, what is \nit?\n\nThanks!", "id": 43848, "time": "2003-09-08T17:29:39Z", "creator": "alan@messagecast.net", "creation_time": "2003-09-08T17:29:39Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 23000, "attachment_id": null, "id": 48580, "time": "2003-12-05T17:03:27Z", "creator": "mike_verdone@shaw.ca", "creation_time": "2003-12-05T17:03:27Z", "is_private": false, "text": "I also have this problem, though my jmx file is only 74kB. This is on JMeter \n1.9.1, running from Ant. The error produced is as follows: \n \n   [jmeter] Created the tree successfully \n   [jmeter] Starting the test \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n   [jmeter] java.lang.OutOfMemoryError \n \nI'm running my Threads individually, and after one thread craps out with the \nOutOfMemory error, the next thread still starts. It seems the \"leak\" may \ninvolve the receive buffer of an HTTP request, since this only occurs on large \nrequests (resulting in > 100kB downloads). However, once one thread has \ncrashed, it seems more likely the following ones will too. \n \nI will try to increase the maximum memory for the VM, to see if that helps. \nStill, there's no reason why JMeter should need this much memory. "}, {"count": 2, "tags": [], "creator": "mike_verdone@shaw.ca", "attachment_id": null, "text": "Retried my test run using the -Xincgc and -Xmx256m arguments. This reduced the \nnumber of OutOfMemoryErrors, but I still got one, which screwed up my test \nresults. There is definitely a \"leak\" of some sort. \n ", "id": 48822, "time": "2003-12-10T16:21:49Z", "bug_id": 23000, "creation_time": "2003-12-10T16:21:49Z", "is_private": false}, {"count": 3, "tags": [], "bug_id": 23000, "text": "Hi Mike, can you please:\n\n1/ Try running with this set of parameters:\nHEAP=\"-Xms256m -Xmx256m\"\nNEW=\"-XX:NewSize=128m -XX:MaxNewSize=128m\"\nSURVIVOR=\"-XX:SurvivorRatio=8 -XX:TargetSurvivorRatio=50%\"\nTENURING=\"-XX:MaxTenuringThreshold=2\"\nEVACUATION=\"-XX:MaxLiveObjectEvacuationRatio=20%\"\nRMIGC=\"-Dsun.rmi.dgc.client.gcInterval=600000 \\\n-Dsun.rmi.dgc.server.gcInterval=600000\"\nPERM=\"-XX:PermSize=64m -XX:MaxPermSize=64m\"\nDEBUG=\"-verbose:gc -XX:+PrintTenuringDistribution\"\n\nARGS=\"$HEAP $NEW $SURVIVOR $TENURING $EVACUATION $RMIGC $PERM $DEBUG\"\n\nor, for Windozes:\n\nset HEAP=-Xms256m -Xmx256m\nset NEW=-XX:NewSize=128m -XX:MaxNewSize=128m\nset SURVIVOR=-XX:SurvivorRatio=8 -XX:TargetSurvivorRatio=50%\nset TENURING=-XX:MaxTenuringThreshold=2\nset EVACUATION=-XX:MaxLiveObjectEvacuationRatio=20%\nset RMIGC=-Dsun.rmi.dgc.client.gcInterval=600000\n-Dsun.rmi.dgc.server.gcInterval=600000\nset PERM=-XX:PermSize=64m -XX:MaxPermSize=64m\nset DEBUG=-verbose:gc -XX:+PrintTenuringDistribution\nset ARGS=%HEAP% %NEW% %SURVIVOR% %TENURING% %EVACUATION% %RMIGC% %PERM% %DEBUG%\n\n2/ Check that you're not running at 100% CPU for more than a few seconds -- I've\nseen cases where load doesn't leave time to finalize objects, close disconnected\nconnections, etc.\n\n3/ Send, if possible, a reproducible test case using static pages only (so that\nI can copy them into my docroot and run it too).\n\n", "id": 49039, "time": "2003-12-13T00:04:30Z", "creator": "jsalvata@atg.com", "creation_time": "2003-12-13T00:04:30Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "bug_id": 23000, "text": "Thanks for your help. This seems to have fixed the problem. I didn't receive \nand OutOfMemoryErrors using these settings. I'm attaching the GC log, just in \ncase you want to look at it. You can see that the amount of heap used still \nincreases over time, even though it should not (tests are already complete and \nlogged, so they shouldn't use up memory). It just doesn't increase as badly as \nit used to. ", "id": 49205, "time": "2003-12-16T20:08:43Z", "creator": "mike_verdone@shaw.ca", "creation_time": "2003-12-16T20:08:43Z", "is_private": false, "attachment_id": null}, {"count": 5, "tags": [], "text": "Created attachment 9603\nGarbage Collection log", "is_private": false, "id": 49206, "creator": "mike_verdone@shaw.ca", "time": "2003-12-16T20:10:01Z", "bug_id": 23000, "creation_time": "2003-12-16T20:10:01Z", "attachment_id": 9603}, {"count": 6, "tags": [], "creator": "jsalvata@atg.com", "attachment_id": null, "text": "Had a look at the attached GC logs. They look great: loads of scavenges with\nhardly a full GC. Memory goes down as it should be expected when a Full GC happens.\n\nIt is normal for memory used after a scavenge (the figure after the \"->\" in the\n\"[GC\" entries) to steadily grow over time. Only a growth in memory used after\nfull GCs would be a symptom of a memory leak.\n\nResolving as fixed, since the parameters Mike used are alrady in place in CVS,\nboth for Unices and Windozes.", "id": 49210, "time": "2003-12-16T21:49:04Z", "bug_id": 23000, "creation_time": "2003-12-16T21:49:04Z", "is_private": false}]