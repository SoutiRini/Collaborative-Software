[{"count": 0, "tags": [], "bug_id": 57832, "attachment_id": null, "id": 182489, "time": "2015-04-19T19:21:52Z", "creator": "regis.leroy@makina-corpus.com", "creation_time": "2015-04-19T19:21:52Z", "is_private": false, "text": "The situation is a backend which is not apache httpd and where a successful\nresponse splitting attack can be done (It can be because of an application flaw\nor because of a bad implementation of something in the http protocol), and\nmod_proxy is used as a reverse proxy for this backend.\n\nI'd like mod_proxy to implement a basic detection of a bad behavior from the\nbackend by closing the keep-alive connection to this backend.\n\nThe current situation with Apache httpd 2.4.12 and before is that mod_proxy\ntrust the backend and does not even detect obvious problems, like having new \nhttp responses coming back from a backend before sending new requests.\n\nNote that this was discussed previously in the security mailing list. The\nproblem is not on httpd side, so it's not a security problem, it is simply an\nhardening feature for mod_proxy to reduce impacts of bad things when they\nhappen.\n\nFor example, here is what happen if the response splitting attacks generates two\nresponses when mod_proxy sends one request to the backend.\n\n\n     HTTP Client    | mod_proxy       |  Compromised backend\n                    |                 |\n      query1 -------|--> query1       |\n                    |      \\----------|--> sending back 2 responses\n                    |                 |   response1+BAD response\n                    |  read only  <---|---------/\n                    |  response1 [*]  |\n                    |      /          |\n      receive  <----|------           |\n     response1      |                 |\n                    |    [ BAD response is still there, stacked\n                    |     in the mod_proxy<->backend connection\n                    |     if the keep-alive status is maintained ]\n                    |                 |\n      query2 -------|--> query2 \u00a0[**] |\n                    |      \\----------|--> sending back\n                    |                 |      response2\n                    |      read <-----|------/\n                    |    BAD response | <======= here is the problem\n      receive  <----|----/            |\n       BAD response |\n\nThis can be tested also by sending a pipeline of two queries, where the first\nquery contains a splitting attack for the backend. mod_proxy will send back the\nsplitted response for the second pipelined query (for tests you can also use a\nphp script sending two http responses instead of one, as described below).\n\nIf the splitting attack can generate 100 http responses, theses 100 responses\nwill be present in the socket connection to the backend. The next 100 queries\nfrom mod_proxy directed to the same backend and reusing this tainted connection\nfrom the pool will read theses false 100 responses, one by one, and send the\nresults to the wrong users (or to the wrong caches entries).\n\nThe main problem here is not in httpd, it's the compromised backend, but shit\nhappens.\n\nWhat mod_proxy could detect, is that this backend was sending http responses\nwithout any http request; This could be detected in [*] or [**], i.e. when the\n1st response is extracted from the brigade or when the connection was requested\nfrom the connection pool, before sending a new query in this connection.\n**The backend socket should be empty** when we have read the response or when we\nwant to send a request.\n\nThe only way to have something in the socket would be using pipelines on the\nbackend communications, and AFAIK mod_proxy is not using pipelines, even when\npipelined queries are received mod_proxy is splitting each query in a classical\n1-request/1-response mode. And I don't think the expected-100-continue mode\ncould impact that. I'm pretty sure nothing should allow contents in this\nconnection before we send the request, but I'm maybe wrong.\n\nThe new way of handling the reverse proxy job could be expressed this way:\n\nYou have a socket opened in keepalive mode with a backend:\n 1 - You send only one query, never a pipeline of queries (done)\n 2 - you read 1 response even if several responses came back (done)\n 3 - you send the unique response to the initial requester (done)\n 4 - when receiving a new request (or for the next one the pipeline)\n     you ask the pool for a new connection to the backend and the pool ensure\n     that this connection is empty (no response waiting in the socket).\n 5 - you send the next query (back to step 1)\n\nClosing the backend connection if the socket is not empty is the most secure\nthing, but you could also just flush the socket content.\n\nFinally, adding such protection in mod_proxy would not prevent all http\nsplitting attacks from poisoning httpd's cache or mod_proxy request/responses\nmatching. Combined with the right timing a splitting attack could prevent the\nextra-responses to be send too early and could successfully wait until new\nrequests are made by mod_proxy in this same connection (the socket would be\nempty at step 4).\nBut adding temporisation in an http spitting attack is a complex task, and is\nnot always available. And even if this protection is not absolute it would at\nleast remove a very comfortable situation for the attacker where a big number\nof http responses can be stacked to mod_proxy right after the end of the first\nresponse.\n\nHow to reproduce\n-----------------\n\nThis is an example, tested on apache 2.4.12:\n\n- port 8888 apache webserver with mod_proxy\n- port 80 apache webserver (or nginx, anything) with php support (php-fpm in m\n  y case), PHP is used here to mimic a compromised application.\n\n    <VirtualHost *:8888>\n        ServerAdmin webmaster@dummy-host2.example.com\n        DocumentRoot \"/opt/apache2/htdocs\"\n        ServerName proxy-host.example.com\n        ErrorLog \"logs/proxy.example.com-error_log\"\n        CustomLog \"logs/proxy.example.com-access_log\" common\n        ProxyPass / http://www.dummy-host.example.com:80/\n        ProxyPassReverse / http://www.dummy-host.example.com:80/\n        LogLevel trace8 proxy:trace8\n    </VirtualHost>\n\nOn port 80 we add support for PHP\n\n    <VirtualHost *:80>\n        DocumentRoot \"/opt/apache2/docs/dummy-host.example.com\"\n        ServerName dummy-host.example.com\n        ServerAlias www.dummy-host.example.com\n        DirectoryIndex index.php\n        ProxyPassMatch ^/.*\\.php(/.*)?$ fcgi://127.0.0.1:9000/opt/apache2/docs/dummy-host.example.com\n        <Directory /opt/apache2/docs/dummy-host.example.com>\n            Require all granted\n        </Directory>\n    </VirtualHost>\n\nAnd finally the /opt/apache2/docs/dummy-host.example.com/index.php file:\n\n    <?\n    # I know that writing such script is killing your\n    # own server. But PHP is not the only way of sending\n    # 2 responses for one query. that's a test script.\n    # 1st regular HTTP response ---------\n    header(\"Content-Length: 17\");\n    \n    echo \"this may be ok.\\r\\n\";\n    # 2nd HTTP response ---------\n    echo \"HTTP/1.1 200 OK\\r\\n\";\n    echo \"Server: Fake\\r\\n\";\n    echo \"Date: Tue, 17 Mar 2015 21:33:18 GMT\\r\\n\";\n    echo \"Content-Type: text/html\\r\\n\";\n    echo \"Content-Length: 28\\r\\n\";\n    echo \"Connection: keep-alive\\r\\n\\r\\n\";\n    echo \"THIS SHOULD NEVER BE SEEN!\\r\\n\";\n    exit(0);\n\nBy requesting the index.php file via mod_proxy several times you should get the \n\"THIS SHOULD NEVER BE SEEN!\" result incoming."}, {"count": 1, "tags": [], "bug_id": 57832, "attachment_id": 32685, "is_private": false, "id": 182622, "time": "2015-04-25T07:31:15Z", "creator": "regis.leroy@makina-corpus.com", "creation_time": "2015-04-25T07:31:15Z", "text": "Created attachment 32685\nproposed patch on httpd 2.4.12\n\nHere is a proposal. That's my first try with buckets and brigades so it needs a deep review. But \"it works for me\".\n\nHere I add a check on the stream BEFORE sending any new request, I check that the input stream is empty (but allow one remaining crlf for backward compatibility with old backends). If it's not empty the bakend keepalived connection is rejected and marked for closure.\n\nThis is made in a retry loop (which was there to allow 2 retry on some sort of backend alive test), but I did not increment the retry counter. So if all backend connections are bad we can spend a quite long time in this loop, cleaning all bad connections, but I think this is better than sending 503 responses.\n\nI did not try to patch ap_proxy_connect_backend, where the backend connection is retrieved, because it may be used by some other protocols, with different expectations."}, {"count": 2, "tags": [], "text": "At least one fix to do, in the comment: It's RFC 7230 and not 7320", "is_private": false, "id": 182654, "creator": "regis.leroy@makina-corpus.com", "time": "2015-04-27T14:07:57Z", "bug_id": 57832, "creation_time": "2015-04-27T14:07:57Z", "attachment_id": null}, {"count": 3, "tags": [], "creator": "ylavic.dev@gmail.com", "attachment_id": 32698, "is_private": false, "id": 182738, "time": "2015-04-29T21:18:44Z", "bug_id": 57832, "creation_time": "2015-04-29T21:18:44Z", "text": "Created attachment 32698\nProposed patch for trunk\n\nAn effort has been made in r1656259 (trunk only) to reduce the time between the backend connection is checked for availability/readability and if that's OK then reused for the next request.\n\nThus I think the attached patch (on top) should be enough to address this potential issue.\n\nThe check is done in ap_proxy_connect_backend() because all proxy modules (reusing connections) currently handle/assume a transactional protocol (one request leading to one response for HTTP, AJP, ...).\nSince r1656259, ap_proxy_connect_backend() is called just before sending the (next) request, so it looks like the right place to fail if some data are readable.\n\nCan you give that a try (applying both r1656259 and the attached patch to 2.4.x seems to work too)?"}, {"count": 4, "tags": [], "bug_id": 57832, "attachment_id": null, "is_private": false, "id": 182969, "time": "2015-05-13T08:00:10Z", "creator": "regis.leroy@makina-corpus.com", "creation_time": "2015-05-13T08:00:10Z", "text": "I've tried to apply things from r1656259 and then your proposed patch. But neither patch or myself are able to find where to apply theses changes in the 2.4 branch. I think you'll need to make a regular 2.4 patch version if you want me to try it :-)\n\nBy the way I was thinking about the cleanup made on the connection level. There are maybe some modules that would like to escape the 1 request/1 response mode later and switch to an http tunnel mode. There is for example a websocket mod_proxy module 2.5, or we could imagine that the mod_proxy_fcgi would evolve to allow streamed inputs and/or outputs, unbuffered communications (on my last tests using chunked inputs with this module to feed php-fpm with a POST was not working). I do not know the internals as much as you do, but I wonder if preventing any mod_proxy module to handle non-transactionnal communications is a good move."}, {"count": 5, "tags": [], "text": "Created attachment 32734\nPatch for 2.4.x (r1516930+r1516965+r1530603+r1530792+r1656259+PR57832)\n\n(In reply to regilero from comment #4)\n> I've tried to apply things from r1656259 and then your proposed patch. But\n> neither patch or myself are able to find where to apply theses changes in\n> the 2.4 branch. I think you'll need to make a regular 2.4 patch version if\n> you want me to try it :-)\n\nYes, sorry, there are missing bits before r1656259.\nThe attached patch applies both to 2.4.x and 2.4.12, thanks for testing!\n\n> I wonder if preventing any mod_proxy module\n> to handle non-transactionnal communications is a good move.\n\nAs you can see, this patch only affects mod_proxy_http and mod_proxy_ajp (both transactionnal), the others do not reuse backend connections when done (polling loop until EOF), hence don't use ap_proxy_is_socket_connected().\nThe only change here is that the caller can now also know if the socket is readable (in addition to simply still connected), transactionnal proxy modules may use that (as this patch does).", "is_private": false, "id": 182971, "creator": "ylavic.dev@gmail.com", "time": "2015-05-13T09:29:50Z", "bug_id": 57832, "creation_time": "2015-05-13T09:29:50Z", "attachment_id": 32734}, {"count": 6, "tags": [], "text": "Created attachment 32735\nProposed patch for 2.4.x on top of r1656259\n\nHmm no, you really don't need all the previous stuff.\nHere is a minimal patch that applies on 2.4.x/2.4.12 (still on top of r1656259 to address HRS).", "is_private": false, "bug_id": 57832, "id": 182972, "time": "2015-05-13T09:46:40Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2015-05-13T09:46:40Z", "attachment_id": 32735}, {"count": 7, "tags": [], "creator": "regis.leroy@makina-corpus.com", "is_private": false, "text": "I made some tests with the last patch, on top of r1656259 's patch.\n\nIf the extra content injected after the 1st response is less than 8000 bytes (more or less) I get 1 for the return of is_socket_connected instead of 2 (USE_ALTERNATE_IS_CONNECTED && defined(APR_MSG_PEEK version). Not always, the attack succeed at 90%. With a big injected response the socket read is not empty and is_socket_connected is detecting this fact, but I do not get any response (no 502/503/400, just an RST).\n\nSo it means the real socket is empty (tested it with real reads and timeouts), but something as already stored this extra content and this storage is associated with the socket. So quite certainly something like some buckets which are not cleaned up after the 1st request. Note that this is hiding a potential problem that I had to fix on the 1st patch with backends sending one extra \\r\\n after the first response.\n\nBut I think the final solution will have to mix this is_socket_connected and a real cleanup of all data read from the socket while processing the first response.", "id": 182977, "time": "2015-05-13T18:58:55Z", "bug_id": 57832, "creation_time": "2015-05-13T18:58:55Z", "attachment_id": null}, {"count": 8, "tags": [], "bug_id": 57832, "attachment_id": 32740, "id": 183004, "time": "2015-05-17T22:51:35Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2015-05-17T22:51:35Z", "is_private": false, "text": "Created attachment 32740\nProposed patch for 2.4.x on top of r1656259\n\n(In reply to regilero from comment #7)\n> I made some tests with the last patch, on top of r1656259 's patch.\n\nThanks for testing!\n\n> With a big injected response the socket read is\n> not empty and is_socket_connected is detecting this fact, but I do not get\n> any response (no 502/503/400, just an RST).\n\nYes, I failed to reset \"connected\" from 2 to 0 in the previous patch.\n\n> \n> But I think the final solution will have to mix this is_socket_connected and\n> a real cleanup of all data read from the socket while processing the first\n> response.\n\nRight, we have to also check if data are already in the input filters' stack.\nThis is what the new attached patch does.\n\nI tested it with both early read and stacked data, but you probably have a more exhaustive tests suite, can you please give it a (re)try?"}, {"count": 9, "tags": [], "bug_id": 57832, "attachment_id": null, "id": 183007, "time": "2015-05-18T09:03:11Z", "creator": "regis.leroy@makina-corpus.com", "creation_time": "2015-05-18T09:03:11Z", "is_private": false, "text": "This version is OK.\n\nStored injections are always detected, small and big.\nThe only way to inject a new response is to have a fine control of the backend stream and use timers between responses, which ,by definition, cannot be detected by mod_proxy.\n\nSo it's almost good. I think there's maybe just one problem with responses from backends containing one extra CRLF. This is already managed by mod_proxy and allowed by the RFC. But here, if I'm not wrong on my tests, it makes a connection status 2."}, {"count": 10, "tags": [], "bug_id": 57832, "attachment_id": null, "is_private": false, "id": 194971, "time": "2016-11-14T12:26:59Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2016-11-14T12:26:59Z", "text": "Backported to upcoming 2.4.24 in r1766372."}]