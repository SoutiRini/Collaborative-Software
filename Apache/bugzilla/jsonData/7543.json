[{"attachment_id": null, "tags": [], "creator": "jim_greuel@hp.com", "text": "I'm seeing an ArrayOutOfBounds exception in StreamingCharReader:\n\njava.lang.ArrayIndexOutOfBoundsException\n        at org.apache.xerces.readers.StreamingCharReader.loadMoreChars\n(StreamingCharReader.java:1332)\n        at org.apache.xerces.readers.StreamingCharReader.loadNextChar\n(StreamingCharReader.java:1260)\n        at org.apache.xerces.readers.StreamingCharReader.scanQName\n(StreamingCharReader.java:725)\n        at org.apache.xerces.framework.XMLDocumentScanner.scanElementType\n(XMLDocumentScanner.java:2075)\n        at org.apache.xerces.framework.XMLDocumentScanner.access$100\n(XMLDocumentScanner.java:86)\n        at \norg.apache.xerces.framework.XMLDocumentScanner$ContentDispatcher.dispatch\n(XMLDocumentScanner.java:1220)\n        at org.apache.xerces.framework.XMLDocumentScanner.parseSome\n(XMLDocumentScanner.java:381)\n        at org.apache.xerces.framework.XMLParser.parse(XMLParser.java:948)\n\n\nIt appears that StreamingCharReader assumes that any chunk it gets from \nCharDataChunk.createChunk() will either not yet be allocated or will be a chunk \nthat is CharDataChunk.CHUNK_SIZE in length (see slowLoadNextChar() and \nloadNextChar()).  This however is not the case.  In particular, we are using \nXalan 1.2 for XSLT processing, and it appears that the XSLT processing \nallocates chunks (using CharDataChunk.setCharArray()) of variable sizes.  The \nexception occurs after StreamingCharReader uses up its first chunk, requests \nanother, and gets a previously used chunk of 123 characters.", "count": 0, "id": 12426, "time": "2002-03-27T21:26:39Z", "bug_id": 7543, "creation_time": "2002-03-27T21:26:39Z", "is_private": false}]