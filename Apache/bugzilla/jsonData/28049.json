[{"count": 0, "tags": [], "bug_id": 28049, "attachment_id": null, "text": "UTF-8 file generated with windows applications like Notepad add BOM (Byte-order\nmark) at the begining of the file. And when I try to import a .sql file in UTF-8\nfor \"sql\" ant task it's not able to read the file. If I erase the BOM, all is OK.\n\nOf course I added encoding=\"UTF-8\" in task definition.\n\nBOM are not mandatory in UTF-8 file. BOM is composed of bytes EF BB BF, in\nISO-8859-1 it is char \"\u00ef\u00bb\u00bf\".\n\nPerhaps I missed a parameter for the sql task definition?", "id": 54883, "time": "2004-03-30T15:36:47Z", "creator": "barliguy@laposte.net", "creation_time": "2004-03-30T15:36:47Z", "is_private": false}, {"count": 1, "tags": [], "bug_id": 28049, "attachment_id": null, "text": "In fact, according to http://www.unicode.org/unicode/faq/utf_bom.html#25 it can\nhave this BOM in UTF-8... It seems it's java that doesn't care of it when\nopenning an InputStreamReader whith \"utf-8\" charsetName.\n\nTo solve my problem I made a litle (and not good) hack in SQLExec.java in\nrunTransaction method. I replaced the line :\n\n---\nReader reader =\n                    (encoding == null) ? new FileReader(tSrcFile)\n                                       : new InputStreamReader(\n                                             new FileInputStream(tSrcFile),\n                                             encoding);\n---\n\nwith this block :\n\n---\nReader reader = new FileReader(tSrcFile);\n                \n                if (reader.read() == 0xEF && reader.read() == 0xBB &&\nreader.read() == 0xBF)\n                {\n                    reader.close();\n                    //Has to be UTF8\n                    reader = new InputStreamReader(new\nFileInputStream(tSrcFile), \"utf-8\");\n                    //Read the BOM char;\n                    reader.read();\n                }\n                else\n                {\n                    reader.close();\n                    reader =\n                    (encoding == null) ? new FileReader(tSrcFile)\n                                       : new InputStreamReader(\n                                             new FileInputStream(tSrcFile),\n                                             encoding);\n                }\n---\n\nWhat it does? it opens the file, checks if there is the utf8 BOM (EF BB BF). If\nBOM exists, open an InputStreamReader with utf8 charset and read first char (the\nBOM, else do like before.\n\nif file is less than 3 bytes, it will raise an exception I guess\n\n", "id": 54894, "time": "2004-03-30T19:23:48Z", "creator": "barliguy@laposte.net", "creation_time": "2004-03-30T19:23:48Z", "is_private": false}, {"count": 2, "tags": [], "creator": "bodewig@apache.org", "is_private": false, "id": 55304, "attachment_id": null, "bug_id": 28049, "creation_time": "2004-04-05T12:42:43Z", "time": "2004-04-05T12:42:43Z", "text": "This is an issue for so many other classes in Ant that any local fix for the\nsql task would be wrong.\n\nSun's own docs don't talk about a BOM for utf-8, so it's pretty likely they'll not\nsupport it properly.  Even the unicode FAQ you link to says \"Note that some\nrecipients of UTF-8 encoded data do not expect a BOM.\" and says it wouldn't make\nany difference for the endianess of the stream.  So Notepad is allowed to do that,\nbut it's useless and dangerous.  Obviously Java clients are in the \"do not expect\na BOM\" department.\n\nI'm not really sure what to do here.  Your patch should probably only apply if\nrequested or native encoding is UTF-8 and it should be farmed out into a helper\nclass so that othere tasks can reuse it."}, {"count": 3, "tags": [], "bug_id": 28049, "attachment_id": null, "text": "There is a (long term) outstanding java bug for this:\nhttp://developer.java.sun.com/developer/bugParade/bugs/4508058.html\n", "id": 55307, "time": "2004-04-05T13:03:55Z", "creator": "peter.reilly@corvil.com", "creation_time": "2004-04-05T13:03:55Z", "is_private": false}]