[{"count": 0, "tags": [], "creator": "torsten_lenya-dev@gcrud.org", "attachment_id": null, "id": 61998, "time": "2004-08-15T11:57:57Z", "bug_id": 30675, "creation_time": "2004-08-15T11:57:57Z", "is_private": false, "text": "Now if I create a new document (File -> New Document) the new document\nthat gets created is just the way I like it:\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\nAfter that, I just choose Edit -> Edit with Kupu. In Kupu I just add one\nsentence and hit Save & Exit.\n\nAfter that, the document is\n\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n\nand any non-latin characters are converted to direct Unicode numbers, such\nas:\n\n&#1605;&#1587;&#1575;&#1576;&#1602;&#1575;&#1578;"}, {"count": 1, "tags": [], "creator": "A.Kuckartz@ping.de", "attachment_id": null, "id": 63276, "time": "2004-09-09T12:48:35Z", "bug_id": 30675, "creation_time": "2004-09-09T12:48:35Z", "is_private": false, "text": "Added lenya-dev@cocoon.apache.org to CC-list."}, {"attachment_id": null, "tags": [], "bug_id": 30675, "text": "Saving what comes back from Kupu is done in the \nlenya.usecase=kupu&lenya.step=save usecase (see lenya/usecases.xmap) using the \nSourceWritingTransformer.\n\nWhat's not necessarily obvious: The SourceWritingTransformer is using the \nXMLSerializer to actually write the SAX stream to the file. This means that \nthe file is written using the encoding set on the XMLSerializer. This seems to \nbe ISO-8859-1 which is why the file gets written using that encoding.\n\nExplicitely setting the encoding in global-sitemap.xmap like this:\n\n    <map:serializer name=\"xml\" logger=\"sitemap.serializer.xml\" mime-\ntype=\"text/xml\" src=\"org.apache.cocoon.serialization.XMLSerializer\">\n      <encoding>UTF-8</encoding>\n    </map:serializer>\n\nwill actually make sure that content which is saved from Kupu will get written \nback to the file in UTF-8.\n\nNote: Of course the XML serializer is not only used by this usecase but \nglobally, so this means a global change. But I understand the plan was to move \nanything to UTF-8 anyway.\n\nSide note: This solves the document roundtrip UTF-8 issue, but at the same \ntime makes a new one visible. Kupu seems to have problem with UTF-8, at least \nin IE ...\n\n", "count": 2, "id": 65231, "time": "2004-10-17T13:56:56Z", "creator": "tschlabach@gmx.net", "creation_time": "2004-10-17T13:56:56Z", "is_private": false}, {"count": 3, "attachment_id": null, "bug_id": 30675, "text": "Note:\n\nThe above is true for release 1.2. Kupu integration was switched over to\nStreamGenerator in 1.2.1 and later.", "id": 65439, "time": "2004-10-21T13:31:56Z", "creator": "tschlabach@gmx.net", "creation_time": "2004-10-21T13:31:56Z", "tags": [], "is_private": false}, {"count": 4, "tags": [], "creator": "A.Kuckartz@ping.de", "attachment_id": null, "id": 65460, "time": "2004-10-21T18:17:40Z", "bug_id": 30675, "creation_time": "2004-10-21T18:17:40Z", "is_private": false, "text": "What does the previous comment mean ?\nIs the problem solved in 1.2.1 ?\n"}, {"attachment_id": null, "tags": [], "bug_id": 30675, "text": "Should work now. Please cross check.", "count": 5, "id": 65541, "time": "2004-10-22T21:04:55Z", "creator": "roku@apache.org", "creation_time": "2004-10-22T21:04:55Z", "is_private": false}, {"count": 6, "text": "Fixed also for BXE.\nProblem: The forms editor also changes the encoding after the doc is saved.\n\nWhat exactly is the problem re utf8 and the forms editor?\n\nBTW: Kupu removes the so called dummy namespaces, which will prevent to edit a\ndoc with the forms editor once you saved with kupu!", "bug_id": 30675, "attachment_id": null, "id": 65570, "time": "2004-10-23T07:20:46Z", "creator": "roku@apache.org", "creation_time": "2004-10-23T07:20:46Z", "tags": [], "is_private": false}, {"count": 7, "tags": [], "bug_id": 30675, "text": "Ok, as well fixed for the 1form editor.\nTODO: Fix forms editor re utf-8. -> PITA", "id": 65572, "time": "2004-10-23T07:48:51Z", "creator": "roku@apache.org", "creation_time": "2004-10-23T07:48:51Z", "is_private": false, "attachment_id": null}]