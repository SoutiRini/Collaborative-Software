[{"count": 0, "tags": [], "bug_id": 38598, "is_private": false, "text": "When processing text files, using the copy, move, concat (etc) has the current \nability to use filter readers. The current set of filter readers provides a \nvery useful set of functionality. The enhancement I would like would be a \nfilter that provide the following functionality.\n\nThe SubSet Filter is a filter that can be used within a filterchain to extract \ndata from a text file. It allows you to designate 2 reg exp patterns. The \nfirst pattern is what the filter uses to start the extraction and the second \nis the pattern is uses to stop the extraction.\n\nRules:\n1) If the beginning filter is not specified, starts at beginning\n\n2) If the beginning filter is never found, no lines are returned\n \n3) If the end filter is never found or not specified, then all lines till the \nend are returned\n \n4) If the skipstart attribute is set, it will skip N number of matches before \nit starts\n \n5) If the skipend attribute is set, it will skip N number of matches before it \nends\n\nAfter the lines are determined, each line can then be limited by column index. \nThe truncating of a line will keep the line-ending character.\n\nRules:\n \n1) If columnstart index is specified, the entire line is returned starting \nfrom that 0-based index\n \n2) If columnstart is greater than a the line length, nothing is returned\n \n3) If columnend is specified, only text up to that index is returned.\n \n4) If columnend is greater than line length, then everything up to line length \nis returned.\n\nNow obviously I have already tried to do this and think it is a useful filter \nthat would help complete the existing set of great filters. I have had a \nrecent set of tasks and chose ant to help do text file processing and found \nthat this was very useful. I realize you already have a great pool of talent \nbut would look forward to contributing the code I do have. It is fully unit \ntested using the anttest util. \n\nAnyways, hopefully I will see it in a future release.\n\nThanks,\nDonovan", "id": 85651, "time": "2006-02-09T23:59:23Z", "creator": "donovan.dillon@shaw.ca", "creation_time": "2006-02-09T23:59:23Z", "attachment_id": null}, {"count": 1, "tags": [], "creator": "mbenson@apache.org", "attachment_id": null, "id": 85653, "time": "2006-02-10T00:04:13Z", "bug_id": 38598, "creation_time": "2006-02-10T00:04:13Z", "is_private": false, "text": "This sounds useful.  I personally would rather NOT see functionality duplicated;\ni.e. you can select by column using existing regex stuff chained after the basic\nfunctionality you have outlined here..."}, {"id": 85683, "tags": [], "bug_id": 38598, "is_private": false, "count": 2, "text": "Rather than introducing new filters, I think the existing <head> and <tail> \nfilters could be extended to take an additional regex. The use case you \ndescribe matches head/tail IMHO, and simply extends the concept to have a \nregex rather than a simple line count to determine the start/end.\n\nI'm wouldn't be against adding a new filter to 'cut' lines by column numbers. \nAlthough it's certainly possible to achieve using regexps, it would likely be \neasier to use a cut-like column specific filter ;-) --DD", "time": "2006-02-10T17:33:12Z", "creator": "ddevienne@gmail.com", "creation_time": "2006-02-10T17:33:12Z", "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 38598, "attachment_id": null, "text": "okay, if we want to go down this road... ;) I would say that a cut filter should\nimplement cut fully, including fields and delims... but either way,\nmodularization is good.", "id": 85685, "time": "2006-02-10T17:47:22Z", "creator": "mbenson@apache.org", "creation_time": "2006-02-10T17:47:22Z", "is_private": false}]