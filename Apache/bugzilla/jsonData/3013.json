[{"count": 0, "tags": [], "creator": "lgalanis@cs.wisc.edu", "text": "Using the Xmark benchmark (found at http://monetdb.cwi.nl/xml/index.html) I\ntried to pare a really big file using SAX (doing nothing but parsing). When\npiping the output of \n\n<xmarkbinary> -f 20 through sax (approx. 2GB) I got the following:\n\njava.lang.RuntimeException: Internal Error: fPreviousChunk == NULL\n        at org.apache.xerces.framework.XMLParser.parse(XMLParser.java:1094)\n        at niagara.search_engine.xmark.DummyParser.main(DummyParser.java:22)\n\nFor values of -f such as 10,15,18  there is no problem. The binary can be made\nusing the file at http://monetdb.cwi.nl/xml/Assets/unix.c", "id": 4312, "time": "2001-08-06T20:47:58Z", "bug_id": 3013, "creation_time": "2001-08-06T20:47:58Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 3013, "text": "I reproduced this.\n\nThe problem is the input file is more than 2^31 bytes long.\n\nThe offset (XMLEntityReader.fCurrentOffset) hence wraps around to a negative \nnumber.\nShortly after xerces falls over in\norg.apache.xerces.utils.UTF8DataChunk.addSymbol\n\nI don't know what should be done. I would guess this is a WONTFIX, but the \nerror messages could be improved. Difficult to choose best place to catch it \nthough; I would assume that a minor change in the file would cause the sympton \n(i.e. the exact place things go wrong) to be very different.\n\nThe value of the argument offset to UTF8DataChunk.addSymbol when it crashes is\n-2147483551, there have been numerous calls to addSymbol with very large values \nof offset near Integer.MAX_VALUE.\n\n\n", "id": 4334, "time": "2001-08-07T11:53:23Z", "creator": "jjc@hpl.hp.com", "creation_time": "2001-08-07T11:53:23Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "creator": "robw@worldspot.com", "is_private": false, "text": "This is a show-stopper for many applications. Other Java parsers do not have\nthis problem...", "id": 10089, "time": "2002-01-30T21:16:25Z", "bug_id": 3013, "creation_time": "2002-01-30T21:16:25Z", "attachment_id": null}, {"count": 3, "tags": [], "creator": "gmarcy@us.ibm.com", "is_private": false, "text": "While this is true, Xerces 1 is not really where the current focus of the Apache \nparser development lies at this point.  Has anyone tried this with Xerces 2?  If \nit is not a problem, then the answer would be for you to switch to the new \nversion.  If the problem does still exists, then the version of this defect \nshould be changed to reflect that.  There are a great many things that could be \ndone to improve Xerces 1 at this point, but with limited resources the main \ndevelopment effort is on Xerces 2 now.  Considering that Xerces 1 has never been \nable to parse documents that large, it is not a regression but a limitation of \nthe old architecture that Xerces 1 was based upon.", "id": 10095, "time": "2002-01-30T23:29:20Z", "bug_id": 3013, "creation_time": "2002-01-30T23:29:20Z", "attachment_id": null}]