[{"attachment_id": null, "tags": [], "bug_id": 32789, "is_private": false, "count": 0, "id": 68755, "time": "2004-12-21T11:24:07Z", "creator": "yuanlue@crimsonlogic.com", "creation_time": "2004-12-21T11:24:07Z", "text": "Lack of support for multi-language seems to be happening in FOP. \n\nArabic is right to left, and there are rules for joining letters. \n\nWe did the following steps listed in \nhttp://www.javaranch.com/journal/200409/CreatingMultipleLanguagePDFusingApacheFO\nP.html\n\nHowever, the Arabic words are able to display letter by letter, but the words \nare broken. No glyphs to join letter with letter...\n\nInitially we thought it may be the font problem. Then we tried download quite a \nnumber of Arabic fonts, (like tradbdo.ttf, trado.ttf, nesf2.ttf, \nNafees_Naskh.ttf etc.) The font that contains most glyphs are Nafees_Naskh.ttf, \nwhich contains 581 number of glyphs. However, after rendering pdf using FOP, \nthe words are still broken."}, {"count": 1, "tags": [], "bug_id": 32789, "text": "There is no BIDI support in FOP 0.20.5, which not only means no support for\nfo:bidi and writing-direction=\"lr\" but also no detection of tb-rl scripts.\nThere had been a patch for the latter which required Java 1.4 (Java 1.3\ndoesn't have the necessary infrastructure). If you manage to find it, you\ncan use arabic and other tb-rl scripts, but you still have to remember to\nswap begin/end-margins and similar properties for blocks explicitely.", "id": 68779, "time": "2004-12-21T23:34:49Z", "creator": "j3322ptm@yahoo.de", "creation_time": "2004-12-21T23:34:49Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 32789, "text": "*** Bug 48184 has been marked as a duplicate of this bug. ***", "id": 133365, "time": "2010-01-06T00:18:02Z", "creator": "pascal.sancho@takoma.fr", "creation_time": "2010-01-06T00:18:02Z", "is_private": false, "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 32789, "attachment_id": 24934, "text": "Created attachment 24934\nSupport for Arabic PDF rendering using ICU4J\n\nThis patch uses ICU4J to do form-shaping and BIDI transformation of rendered text.  It is a patch for the FOP trunk.   It does not change the layout manager or the area tree handler or allow a writing-mode other than \u201clr-tb\u201d.   For this patch to be integrated with FOP, FOP would need to distribute the ICU4J library - icu4j-4_2_1.jar.   It affects both PDF and PCL rendering but has only been tested with PDF rendering.  So far results of testing with PDF rendering have been positive.  The PCL aspect of the patch looks correct given that the PDF aspect works.", "id": 134263, "time": "2010-02-05T14:33:18Z", "creator": "RN@Intersystems.com", "creation_time": "2010-02-05T14:33:18Z", "is_private": false}, {"count": 4, "tags": [], "creator": "j3322ptm@yahoo.de", "text": "I'd like to have a detection whether ICU4J and possibly also whether BIDI support\nis available at run time, and either fail with a sensible error message or degrade\noutput. Distributing ICU4J with FOP is a bit of a headache, but taking advantage\nof it if the user installed it separately is certainly ok.", "id": 134280, "time": "2010-02-07T05:12:27Z", "bug_id": 32789, "creation_time": "2010-02-07T05:12:27Z", "is_private": false, "attachment_id": null}, {"count": 5, "tags": [], "bug_id": 32789, "text": "Why is distributing ICU4J with FOP a bit of a headache?\n\nWould you use Java Relection to test whether the ICU4J classes this patch uses to support Arabic are available at run-time, and would you use reflection to call the ICU4J methods if they are available?", "id": 134283, "time": "2010-02-07T05:44:28Z", "creator": "levinson@intersystems.com", "creation_time": "2010-02-07T05:44:28Z", "is_private": false, "attachment_id": null}, {"count": 6, "tags": [], "creator": "j3322ptm@yahoo.de", "attachment_id": null, "id": 134286, "time": "2010-02-07T07:11:11Z", "bug_id": 32789, "creation_time": "2010-02-07T07:11:11Z", "is_private": false, "text": "(In reply to comment #5)\n> Why is distributing ICU4J with FOP a bit of a headache?\n\nThe jar is somewhat largish (6MB), and only a small part will be used (although\nother parts are useful too, like Thai support).\nAnyway, bundling a dependency may be good for users which prefer a self\ncontained installation but usually are a headache for people who want to\npackage FOP with their products, therefore I'd like to restrict bundled\njars to a \"minimal guaranteed feature set.\"\n \n> Would you use Java Relection to test whether the ICU4J classes this patch uses\n> to support Arabic are available at run-time\nYes. Testing for a single, typically used class should be sufficient.\n\n> and would you use reflection to\n> call the ICU4J methods if they are available?\nI don't think this is necessary, although I'm no longer on top of things\nwhen it comes to know when a JVM loads classes."}, {"count": 7, "tags": [], "bug_id": 32789, "attachment_id": null, "id": 134311, "time": "2010-02-08T04:13:10Z", "creator": "vhennebert@gmail.com", "creation_time": "2010-02-08T04:13:10Z", "is_private": false, "text": "Hi,\n\nThanks for your patch. Do you have an example FO file that could be used for testing purpose (even better, with an English translation)?\n\nIIUC, Arabic shaping is about replacing glyphs for standalone letters with suitable ligature glyphs for building words. Surely that affects character widths, so line breaking decisions? In the patch, shaping is performed at the rendering stage, so isn't there a danger of getting inconsistent results?\n\nAlso, IIC Arabic shaping affects glyphs selection. How do you make sure that the right glyphs are being embedded in the PDF file?\n\nThe same piece of code is duplicated in the PCL and PDF painters. The same would probably also need to be done for other painters. This is not desirable.\n\nFinally, what is the impact on performance? It looks like shaping will be applied to just any text, even non-arabic one.\n\nThanks,\nVincent\n\n\n(In reply to comment #3)\n> Created an attachment (id=24934) [details]\n> Support for Arabic PDF rendering using ICU4J\n> \n> This patch uses ICU4J to do form-shaping and BIDI transformation of rendered\n> text.  It is a patch for the FOP trunk.   It does not change the layout manager\n> or the area tree handler or allow a writing-mode other than \u201clr-tb\u201d.   For this\n> patch to be integrated with FOP, FOP would need to distribute the ICU4J library\n> - icu4j-4_2_1.jar.   It affects both PDF and PCL rendering but has only been\n> tested with PDF rendering.  So far results of testing with PDF rendering have\n> been positive.  The PCL aspect of the patch looks correct given that the PDF\n> aspect works."}, {"count": 8, "tags": [], "creator": "levinson@intersystems.com", "text": "Hi Vincent,\n\nI will attach the .fo file I've been using for testing.  I will also attach the generated pdf.  This is from an example our Dubai team gave me for my own testing as I developed the code.\n\nOur Dubai team has been testing with a large variety of Arabic script - but they are using a report creation tool that invokes fop.bat with xsl input so the .fo file isn't part of their output.\n\nI could give them instructions for creating .fo files.\n\nWe have found in testing that what is most important is the BIDI algorithm is applied so that text (including embedded numerals) is in the right order and that form shaping is correct.  You need to know the Arabic alphabet and its rules to assess the output of testing.  We have a team that knows Arabic to do our testing.  They \"eyeball\" the reports to make sure they are in proper Arabic with text and sub-text in the right order.  Embedded numerals can be in a different order - left-to-right rather than right-to-left. It isn't clear to me how this process can be automated.\n\nYou are right that widths change and this could change line breaking decisions.  Do you know where in the FOP pipeline before we reach the rendering pipeline the Arabic shaping could go so as to be able to affect width selection?\n\nI believe that what ensures the right glyphs are embedded in the PDF file is the nature of the ICU4J algorithm which transforms the UNICODE representation of the string.  The output for our Dubai team is PDFs with embedded fonts and these are working so ICU4J must have solved the problem in some way, and I believe the way they solve it is by using different UNICODE codes.\n\nI don't have performance numbers to give you yet.  If ICU4J was clever about the way they wrote their transform algorithm it should not be much of a performance impact since they only need to transform text in the Arabic UNICODE code range and testing whether text is in this range should be quick.\n\nThanks,\nJonathan\n\n(In reply to comment #7)\n> Hi,\n> Thanks for your patch. Do you have an example FO file that could be used for\n> testing purpose (even better, with an English translation)?\n> IIUC, Arabic shaping is about replacing glyphs for standalone letters with\n> suitable ligature glyphs for building words. Surely that affects character\n> widths, so line breaking decisions? In the patch, shaping is performed at the\n> rendering stage, so isn't there a danger of getting inconsistent results?\n> Also, IIC Arabic shaping affects glyphs selection. How do you make sure that\n> the right glyphs are being embedded in the PDF file?\n> The same piece of code is duplicated in the PCL and PDF painters. The same\n> would probably also need to be done for other painters. This is not desirable.\n> Finally, what is the impact on performance? It looks like shaping will be\n> applied to just any text, even non-arabic one.\n> Thanks,\n> Vincent\n> (In reply to comment #3)\n> > Created an attachment (id=24934) [details] [details]\n> > Support for Arabic PDF rendering using ICU4J\n> > \n> > This patch uses ICU4J to do form-shaping and BIDI transformation of rendered\n> > text.  It is a patch for the FOP trunk.   It does not change the layout manager\n> > or the area tree handler or allow a writing-mode other than \u201clr-tb\u201d.   For this\n> > patch to be integrated with FOP, FOP would need to distribute the ICU4J library\n> > - icu4j-4_2_1.jar.   It affects both PDF and PCL rendering but has only been\n> > tested with PDF rendering.  So far results of testing with PDF rendering have\n> > been positive.  The PCL aspect of the patch looks correct given that the PDF\n> > aspect works.", "id": 134327, "time": "2010-02-08T06:58:15Z", "bug_id": 32789, "creation_time": "2010-02-08T06:58:15Z", "is_private": false, "attachment_id": null}, {"count": 9, "tags": [], "text": "Created attachment 24947\nExample fo - one of many used in testing Arabic patch", "attachment_id": 24947, "id": 134328, "creator": "levinson@intersystems.com", "time": "2010-02-08T07:00:33Z", "bug_id": 32789, "creation_time": "2010-02-08T07:00:33Z", "is_private": false}, {"count": 10, "tags": [], "text": "Created attachment 24948\ngenerated PDF from sample .fo", "attachment_id": 24948, "id": 134329, "creator": "levinson@intersystems.com", "time": "2010-02-08T07:01:31Z", "bug_id": 32789, "creation_time": "2010-02-08T07:01:31Z", "is_private": false}, {"count": 11, "tags": [], "text": "Hi Jonathan,\n\n(In reply to comment #8)\n> Hi Vincent,\n> \n> I will attach the .fo file I've been using for testing.  I will also attach the\n> generated pdf.  This is from an example our Dubai team gave me for my own\n> testing as I developed the code.\n\nWell... It's a bit light for an example. Just a single word...\n\n\n> Our Dubai team has been testing with a large variety of Arabic script - but\n> they are using a report creation tool that invokes fop.bat with xsl input so\n> the .fo file isn't part of their output.\n> \n> I could give them instructions for creating .fo files.\n> \n> We have found in testing that what is most important is the BIDI algorithm is\n> applied so that text (including embedded numerals) is in the right order and\n> that form shaping is correct.  You need to know the Arabic alphabet and its\n> rules to assess the output of testing.  We have a team that knows Arabic to do\n> our testing.  They \"eyeball\" the reports to make sure they are in proper Arabic\n> with text and sub-text in the right order.  Embedded numerals can be in a\n> different order - left-to-right rather than right-to-left. It isn't clear to me\n> how this process can be automated.\n> \n> You are right that widths change and this could change line breaking decisions.\n>  Do you know where in the FOP pipeline before we reach the rendering pipeline\n> the Arabic shaping could go so as to be able to affect width selection?\n\nSomething needs to be done in the layout engine, possibly also on the FO tree. At least section 5.8 (\u201cUnicode BIDI Processing\u201d) of XSL-FO 1.1 deserves a look as it explains how the Unicode algorithm should be blended in XSL-FO processing. Inline-level stuff is likely to be affected. It needs to be seen how and when character re-ordering should be done WRT line breaking.\n\nAlso, something might need to be done at the font level. I don't know what ICU4J does, but I suspect it replaces characters from the Arabic range (U+0600\u2013U+06FF) with ones from Arabic Presentation Forms-A (U+FB50\u2013U+FDFF). AFAIU from the Unicode specification this is legacy that may not be supported by every font. I suppose modern fonts (especially OpenType ones) use the standard ligature mechanism to provide contextual glyphs.\n\n\n> I believe that what ensures the right glyphs are embedded in the PDF file is\n> the nature of the ICU4J algorithm which transforms the UNICODE representation\n> of the string.  The output for our Dubai team is PDFs with embedded fonts and\n> these are working so ICU4J must have solved the problem in some way, and I\n> believe the way they solve it is by using different UNICODE codes.\n\nActually this is taken care of by the font library called by PDFPainter. I suspect the same is done at the layout stage, with the standalone glyphs. Which would be suboptimal, as both standalone and contextual glyphs would be embedded in the final PDF.\n\n\n> I don't have performance numbers to give you yet.  If ICU4J was clever about\n> the way they wrote their transform algorithm it should not be much of a\n> performance impact since they only need to transform text in the Arabic UNICODE\n> code range and testing whether text is in this range should be quick.\n> \n> Thanks,\n> Jonathan\n> \n> (In reply to comment #7)\n> > Hi,\n> > Thanks for your patch. Do you have an example FO file that could be used for\n> > testing purpose (even better, with an English translation)?\n> > IIUC, Arabic shaping is about replacing glyphs for standalone letters with\n> > suitable ligature glyphs for building words. Surely that affects character\n> > widths, so line breaking decisions? In the patch, shaping is performed at the\n> > rendering stage, so isn't there a danger of getting inconsistent results?\n> > Also, IIC Arabic shaping affects glyphs selection. How do you make sure that\n> > the right glyphs are being embedded in the PDF file?\n> > The same piece of code is duplicated in the PCL and PDF painters. The same\n> > would probably also need to be done for other painters. This is not desirable.\n> > Finally, what is the impact on performance? It looks like shaping will be\n> > applied to just any text, even non-arabic one.\n> > Thanks,\n> > Vincent\n> > (In reply to comment #3)\n> > > Created an attachment (id=24934) [details] [details] [details]\n> > > Support for Arabic PDF rendering using ICU4J\n> > > \n> > > This patch uses ICU4J to do form-shaping and BIDI transformation of rendered\n> > > text.  It is a patch for the FOP trunk.   It does not change the layout manager\n> > > or the area tree handler or allow a writing-mode other than \u201clr-tb\u201d.   For this\n> > > patch to be integrated with FOP, FOP would need to distribute the ICU4J library\n> > > - icu4j-4_2_1.jar.   It affects both PDF and PCL rendering but has only been\n> > > tested with PDF rendering.  So far results of testing with PDF rendering have\n> > > been positive.  The PCL aspect of the patch looks correct given that the PDF\n> > > aspect works.\n\n\nVincent", "is_private": false, "bug_id": 32789, "id": 134425, "time": "2010-02-11T12:25:40Z", "creator": "vhennebert@gmail.com", "creation_time": "2010-02-11T12:25:40Z", "attachment_id": null}, {"count": 12, "tags": [], "bug_id": 32789, "attachment_id": null, "id": 134446, "time": "2010-02-12T01:10:43Z", "creator": "levinson@intersystems.com", "creation_time": "2010-02-12T01:10:43Z", "is_private": false, "text": "Hi Vincent,\n\nBefore committing the work I did on Arabic to the trunk, the Apache FOP organization seems to want five things:\n\n1)\tModify ICU4J change to check if classes available and if not don't call them\n\n2)\tProvide Apache organization with performance data to assess performance cost of Arabic Shaping classes\n\n3)\tProvide Apache organization with better examples of use of Arabic\n\n4)\tMove Arabic form shaping and BIDI algorithm to layout manager\n\n5)\tNot use ICU4J to do UNICODE transformation but use the standard ligature mechanism to provide contextual glyphs.  This is a request for a complete rewrite of the patch to use a mechanism that isn't known to me currently, but maybe could become known if I had the right pointers.\n\n(4) is highly non-trivial.  I haven\u2019t a clue as to how to do (5).\n\nFor (4) could you point me at the source code files in the layout manager that would have to be changed?  Can you give me some pointers as to where this sort of information is processed by the layout manager?  I've read the layout manager code and tried to locate where it processes the width of characters and what would have to change to have right-to-left printing but I've been unable to penetrate the forest for the trees.  I have read Knuth's algorithm for line breaking and I think I have a good understanding of what a KnuthElement is - glue, penalties and the basics of Knuth's algorithm, but I'm having trouble converting this theoretical understanding into a practical understanding of what has to change in the code to move the printing from right to left.\n\nI\u2019m not sure what to do about (5).  Do you have any references, is there some pointer to what algorithm would do more than UNICODE transformation but would do contextual glyphs based on the glyphs in a font.  How do I tell the characteristics of an Arabic character in  a font, whether it is in initial, intermediate or final position?  I suppose this information would vary from font to font.  Where in FOP is font information like this processed and how do I \u201ctell\u201d a font I want the Arabic character at UNICODE position X but I want from the font that the character be in final position?  Does the layout manager actually process the font information about a character?  I suppose it must to know character widths, which are necessary for Knuth's algorithm, but please forgive me, I don't see where this code lives.  FOP has over 11,000 files!\n\nI used ICU4J to avoid having to write a ton of code.  That is why my patch is so small.\n\nI'm not complaining.  I'm hoping I can get some more pointers to what changes need to be made to support Arabic and where the changes have to go.  Even if I'm not the one who eventually does the work, whoever eventually implements right-to-left printing and Arabic support will certainly find our discussion valuable.  I'm sure you'll agree that FOP needs to become truly international at some point. That would really open a new community of users to the benefits of FOP, which are considerable.\n\nIn fact, I agree that it is hard to see how there can be a robust solution to the problem of printing Arabic text that simply involves the PDF renderer; theoretically and probably practically the layout manager has to be involved.\n\nI\u2019ve looked at the FOP SVG rendering code which tries to do Arabic form shaping and it seems to be just doing UNICODE transformations.  It doesn\u2019t seem to be responding to the ability of a font that you are discussing, to display a single UNICODE code in many different forms.  It seems to be just doing a simple table look up that transforms a UNICODE code.  So you already have code in FOP, in  your SVG renderer, that seems to do the same thing I tried to do using ICU4J.  This doesn't mean the code I wrote using ICU4J is doing the right thing, but it does mean that simply transforming one UNICODE code to another is the simplest first step in solving this difficult problem.\n\nCould we agree that we could live with an ICU4J approach if (1),(2),(3), and (4) were met as conditions, and that (5) - a complete rewrite using modern font techniques could be deferred.  Of course, I'm interested in learning how I could achieve (5); I'm not dismissing (5), I'm just looking for a bottom-line that would allow FOP to practically meet the needs of rendering Arabic text, even if the result isn't perfect yet.  \n\nBest Regards,\nJonathan\n\n(In reply to comment #11)\n> Hi Jonathan,\n> \n> (In reply to comment #8)\n> > Hi Vincent,\n> > \n> > I will attach the .fo file I've been using for testing.  I will also attach the\n> > generated pdf.  This is from an example our Dubai team gave me for my own\n> > testing as I developed the code.\n> \n> Well... It's a bit light for an example. Just a single word...\n> \n> \n> > Our Dubai team has been testing with a large variety of Arabic script - but\n> > they are using a report creation tool that invokes fop.bat with xsl input so\n> > the .fo file isn't part of their output.\n> > \n> > I could give them instructions for creating .fo files.\n> > \n> > We have found in testing that what is most important is the BIDI algorithm is\n> > applied so that text (including embedded numerals) is in the right order and\n> > that form shaping is correct.  You need to know the Arabic alphabet and its\n> > rules to assess the output of testing.  We have a team that knows Arabic to do\n> > our testing.  They \"eyeball\" the reports to make sure they are in proper Arabic\n> > with text and sub-text in the right order.  Embedded numerals can be in a\n> > different order - left-to-right rather than right-to-left. It isn't clear to me\n> > how this process can be automated.\n> > \n> > You are right that widths change and this could change line breaking decisions.\n> >  Do you know where in the FOP pipeline before we reach the rendering pipeline\n> > the Arabic shaping could go so as to be able to affect width selection?\n> \n> Something needs to be done in the layout engine, possibly also on the FO tree.\n> At least section 5.8 (\u201cUnicode BIDI Processing\u201d) of XSL-FO 1.1 deserves a look\n> as it explains how the Unicode algorithm should be blended in XSL-FO\n> processing. Inline-level stuff is likely to be affected. It needs to be seen\n> how and when character re-ordering should be done WRT line breaking.\n> \n> Also, something might need to be done at the font level. I don't know what\n> ICU4J does, but I suspect it replaces characters from the Arabic range\n> (U+0600\u2013U+06FF) with ones from Arabic Presentation Forms-A (U+FB50\u2013U+FDFF).\n> AFAIU from the Unicode specification this is legacy that may not be supported\n> by every font. I suppose modern fonts (especially OpenType ones) use the\n> standard ligature mechanism to provide contextual glyphs.\n> \n> \n> > I believe that what ensures the right glyphs are embedded in the PDF file is\n> > the nature of the ICU4J algorithm which transforms the UNICODE representation\n> > of the string.  The output for our Dubai team is PDFs with embedded fonts and\n> > these are working so ICU4J must have solved the problem in some way, and I\n> > believe the way they solve it is by using different UNICODE codes.\n> \n> Actually this is taken care of by the font library called by PDFPainter. I\n> suspect the same is done at the layout stage, with the standalone glyphs. Which\n> would be suboptimal, as both standalone and contextual glyphs would be embedded\n> in the final PDF.\n> \n> \n> > I don't have performance numbers to give you yet.  If ICU4J was clever about\n> > the way they wrote their transform algorithm it should not be much of a\n> > performance impact since they only need to transform text in the Arabic UNICODE\n> > code range and testing whether text is in this range should be quick.\n> > \n> > Thanks,\n> > Jonathan\n> > \n> > (In reply to comment #7)\n> > > Hi,\n> > > Thanks for your patch. Do you have an example FO file that could be used for\n> > > testing purpose (even better, with an English translation)?\n> > > IIUC, Arabic shaping is about replacing glyphs for standalone letters with\n> > > suitable ligature glyphs for building words. Surely that affects character\n> > > widths, so line breaking decisions? In the patch, shaping is performed at the\n> > > rendering stage, so isn't there a danger of getting inconsistent results?\n> > > Also, IIC Arabic shaping affects glyphs selection. How do you make sure that\n> > > the right glyphs are being embedded in the PDF file?\n> > > The same piece of code is duplicated in the PCL and PDF painters. The same\n> > > would probably also need to be done for other painters. This is not desirable.\n> > > Finally, what is the impact on performance? It looks like shaping will be\n> > > applied to just any text, even non-arabic one.\n> > > Thanks,\n> > > Vincent\n> > > (In reply to comment #3)\n> > > > Created an attachment (id=24934) [details] [details] [details] [details]\n> > > > Support for Arabic PDF rendering using ICU4J\n> > > > \n> > > > This patch uses ICU4J to do form-shaping and BIDI transformation of rendered\n> > > > text.  It is a patch for the FOP trunk.   It does not change the layout manager\n> > > > or the area tree handler or allow a writing-mode other than \u201clr-tb\u201d.   For this\n> > > > patch to be integrated with FOP, FOP would need to distribute the ICU4J library\n> > > > - icu4j-4_2_1.jar.   It affects both PDF and PCL rendering but has only been\n> > > > tested with PDF rendering.  So far results of testing with PDF rendering have\n> > > > been positive.  The PCL aspect of the patch looks correct given that the PDF\n> > > > aspect works.\n> \n> \n> Vincent"}, {"attachment_id": null, "tags": [], "creator": "vhennebert@gmail.com", "text": "Hi Jonathan,\n\nI'm lacking the knowledge to properly answer all of your questions, but I'll try anyway.\n\n(In reply to comment #12)\n> Hi Vincent,\n> \n> Before committing the work I did on Arabic to the trunk, the Apache FOP\n> organization seems to want five things:\n> \n> 1)    Modify ICU4J change to check if classes available and if not don't call\n> them\n\nI would leave that aside for now. This can be done in the last refinements, once everything else is in place.\n\n\n> 2)    Provide Apache organization with performance data to assess performance\n> cost of Arabic Shaping classes\n> \n> 3)    Provide Apache organization with better examples of use of Arabic\n> \n> 4)    Move Arabic form shaping and BIDI algorithm to layout manager\n> \n> 5)    Not use ICU4J to do UNICODE transformation but use the standard ligature\n> mechanism to provide contextual glyphs.  This is a request for a complete\n> rewrite of the patch to use a mechanism that isn't known to me currently, but\n> maybe could become known if I had the right pointers.\n> \n> (4) is highly non-trivial.  I haven\u2019t a clue as to how to do (5).\n\nI didn't say it was trivial :-)\n\n\n> For (4) could you point me at the source code files in the layout manager that\n> would have to be changed?  Can you give me some pointers as to where this sort\n> of information is processed by the layout manager?  I've read the layout\n> manager code and tried to locate where it processes the width of characters and\n> what would have to change to have right-to-left printing but I've been unable\n> to penetrate the forest for the trees.  I have read Knuth's algorithm for line\n> breaking and I think I have a good understanding of what a KnuthElement is -\n> glue, penalties and the basics of Knuth's algorithm, but I'm having trouble\n> converting this theoretical understanding into a practical understanding of\n> what has to change in the code to move the printing from right to left.\n\nI don't really know myself where to look either. Without talking about the FOP code yet, it must be seen how to do character re-ordering, line breaking and glyph shaping. The three processes probably have an impact on each other. Does a glyph change whether it is at the end of a line or not? How does hyphenation work (apparently, only applies to the Uighur script)? Also, contrary to Western scripts, I think justification is not done by increasing inter-word spaces, but by using wider alternative glyphs.\nObviously, the appropriate sections of the XSL-FO Recommendation need to be studied, as well as the Unicode Standard (in particular, UAX #9 about the Bidirectional Algorithm). And also other resources on the web.\n\nYou can use the Wiki to gather your thoughts:\nhttp://wiki.apache.org/xmlgraphics-fop/DeveloperPages\n\n\n> I\u2019m not sure what to do about (5).  Do you have any references, is there some\n> pointer to what algorithm would do more than UNICODE transformation but would\n> do contextual glyphs based on the glyphs in a font.  How do I tell the\n> characteristics of an Arabic character in  a font, whether it is in initial,\n> intermediate or final position?  I suppose this information would vary from\n> font to font.  Where in FOP is font information like this processed and how do\n> I \u201ctell\u201d a font I want the Arabic character at UNICODE position X but I want\n> from the font that the character be in final position?  Does the layout manager\n> actually process the font information about a character?  I suppose it must to\n> know character widths, which are necessary for Knuth's algorithm, but please\n> forgive me, I don't see where this code lives.  FOP has over 11,000 files!\n\nI'm almost sure that the OpenType font format provides the necessary mechanisms to do contextual glyph shaping. But I've never really looked into it. I guess one mechanism or the other will have to be selected depending on which one the font supports.\n\n\n> I used ICU4J to avoid having to write a ton of code.  That is why my patch is\n> so small.\n\nWhich is a good idea. We will probably need ICU4J anyway. But there /is/ going to be a lot of code to write, simply because the whole issue is all but trivial. Some heavy refactoring of the layout code will probably be needed, too.\n\n\n> I'm not complaining.  I'm hoping I can get some more pointers to what changes\n> need to be made to support Arabic and where the changes have to go.  Even if\n> I'm not the one who eventually does the work, whoever eventually implements\n> right-to-left printing and Arabic support will certainly find our discussion\n> valuable.  I'm sure you'll agree that FOP needs to become truly international\n> at some point. That would really open a new community of users to the benefits\n> of FOP, which are considerable.\n> \n> In fact, I agree that it is hard to see how there can be a robust solution to\n> the problem of printing Arabic text that simply involves the PDF renderer;\n> theoretically and probably practically the layout manager has to be involved.\n> \n> I\u2019ve looked at the FOP SVG rendering code which tries to do Arabic form shaping\n> and it seems to be just doing UNICODE transformations.  It doesn\u2019t seem to be\n> responding to the ability of a font that you are discussing, to display a\n> single UNICODE code in many different forms.  It seems to be just doing a\n> simple table look up that transforms a UNICODE code.  So you already have code\n> in FOP, in  your SVG renderer, that seems to do the same thing I tried to do\n> using ICU4J.  This doesn't mean the code I wrote using ICU4J is doing the right\n> thing, but it does mean that simply transforming one UNICODE code to another is\n> the simplest first step in solving this difficult problem.\n> \n> Could we agree that we could live with an ICU4J approach if (1),(2),(3), and\n> (4) were met as conditions, and that (5) - a complete rewrite using modern font\n> techniques could be deferred.  Of course, I'm interested in learning how I\n> could achieve (5); I'm not dismissing (5), I'm just looking for a bottom-line\n> that would allow FOP to practically meet the needs of rendering Arabic text,\n> even if the result isn't perfect yet.\n\n(5) can surely be left aside for now, as long as the code structure allows it to be implemented and plugged in later on, with a transparent switch from one mechanism to the other depending on the font used.\n  \n\n> Best Regards,\n> Jonathan\n\nHTH,\nVincent", "count": 13, "id": 134456, "time": "2010-02-12T11:15:07Z", "bug_id": 32789, "creation_time": "2010-02-12T11:15:07Z", "is_private": false}, {"count": 14, "tags": [], "bug_id": 32789, "text": "You touch many complicated points. I will try to give some hints regarding item 4)    Move Arabic form shaping and BIDI algorithm to layout manager. Since I worked with this code a while ago, I go with what I remember.\n\nThe relevant layout managers are lineLayoutManager and textLayoutManager. LineLM initiates the linebreaking algorithm. Input is the string, which is converted into boxes using font width info. Here the rl text must be presented in boxes in the proper order. In fully Arabic paragraphs this could be rl order, but then the breakpoints must be interpreted as breaks at the lhs. In mixed paragraphs lr order may be best, unless lhs breaks are again used. The algorithm itself is basically writing order agnostic.\n\nIn LM.addAreas the areas for the words and lines are created. I suppose they contain the string to be rendered, so that the renderers can insert glyphs.\n\nThe linebreaking algorithm needs to know pre-break, post-break and no-break pieces. In Western texts this is done using penalty widths. I think we did something with post-break pieces, but I do not remember precisely. You should find out whether the outcome of the linebreaking algorithm, esp. the stretch of a line, contains sufficient information for Arabic rendering.\n\nOn further points: If we can use work done by ICU, then by all means let us do that. I am a bit confused about the options to use either ICU or OpenType font info. The latter is more focussed to that particular font, I would guess. But if ICU's string transformation does the trick for all fonts, we can use it.\n\nMost of all, let us go with a good solution. Better is the enemy of good. I would rather have a good solution than the best but not yet available solution.", "id": 134464, "time": "2010-02-12T19:48:16Z", "creator": "spepping@apache.org", "creation_time": "2010-02-12T19:48:16Z", "is_private": false, "attachment_id": null}, {"count": 15, "tags": [], "text": "Created attachment 25010\nBetter example of FO file that uses Arabic\n\nI will also attach generated PDF.", "is_private": false, "bug_id": 32789, "id": 134605, "time": "2010-02-17T14:27:28Z", "creator": "levinson@intersystems.com", "creation_time": "2010-02-17T14:27:28Z", "attachment_id": 25010}, {"count": 16, "tags": [], "bug_id": 32789, "attachment_id": 25011, "text": "Created attachment 25011\nHere is generated PDF from better example of FO file", "id": 134606, "time": "2010-02-17T14:28:37Z", "creator": "levinson@intersystems.com", "creation_time": "2010-02-17T14:28:37Z", "is_private": false}, {"count": 17, "attachment_id": null, "bug_id": 32789, "text": "FYI, I am preparing a candidate patch that will add direct support for Arabic (and other complex scripts). This primarily involves making use of the advanced typographic tables present in TrueType and OpenType fonts (e.g., 'mort', 'morx', 'GSUB' and 'GPOS' tables). Initial support will focus on use of the GSUB table. This patch will not have any external dependencies, i.e., it does not make use of ICU4J.\n\nRegards,\nGlenn Adams", "id": 136029, "time": "2010-04-12T01:00:37Z", "creator": "gadams@apache.org", "creation_time": "2010-04-12T01:00:37Z", "tags": [], "is_private": false}, {"count": 18, "tags": [], "bug_id": 32789, "text": "(In reply to comment #17)\n> FYI, I am preparing a candidate patch that will add direct support for Arabic\n> (and other complex scripts). This primarily involves making use of the advanced\n> typographic tables present in TrueType and OpenType fonts (e.g., 'mort',\n> 'morx', 'GSUB' and 'GPOS' tables). Initial support will focus on use of the\n> GSUB table. This patch will not have any external dependencies, i.e., it does\n> not make use of ICU4J.\n> \n> Regards,\n> Glenn Adams\n\n\nGlenn,\nCan you please provide more information on this as to when & how will this update be available?\n\nRegards,\nSachin Sharma.", "id": 136555, "time": "2010-04-30T01:42:49Z", "creator": "ssharma7884@gmail.com", "creation_time": "2010-04-30T01:42:49Z", "is_private": false, "attachment_id": null}, {"count": 19, "tags": [], "text": "\nbasically, the patch will do the following (in summary):\n\n* enhance org.apache.fop.fonts.truetype.TTFFile in order to read the OpenType GSUB and GPOS tables, creating new org.apache.fop.fonts.GlyphTable instances which are added to MultiByteFont instances;\n\n* enhance org.apache.fop.fonts.apps.TTFReader in order to write out XML representation of this new data into the FOP metrics file;\n\n* enhance org.apache.fop.fonts.FontReader to read the new GSUB/GPOS data stored in the FOP metrics file;\n\n* enhance the knuth elements generation in org.apache.fop.layoutmgr.inline.TextLayoutManager, specifically, #processWord, in order to perform substitution processing, which, if the current font supports substitution, causes the font to invoke substitution processing using the new metrics; this substitution process is a multi-stage process starting with a mapping from a sequence of character codes to a sequence of glyph indices, followed by one or more mappings from sequence of glyph indices to sequences of glyph indices, and finally mapping back to a sequence of character codes denoting the final mapped glyphs to be used;\n\n* similarly, if font supports these new metrics, then perform glyph positioning process to produce sequence of [dx,dy] adjustments to apply, the application of which follows a somewhat updated logic to handle both X and Y advancements on a per-resultant-glyph (= per output character) basis;\nimplement bidi algorithm specified in XSL-FO 1.1 Section 5.8 \"Unicode Bidi Processing\", which essentially involves resolving the final inline-progression-direction for each glyph or inline area child of an inline area and each inline child of a line area;\n\n* enhance area generation process to make use of inline-progress-direction produced by bidi processing in order to reorder areas to satisfy unicode bidi semantics (both explicit and implied);\ninitially, i am testing against the set of Arabic fonts shipped with Windows 7; but I expect to work with a few other fonts that have GSUB/GPOS tables as well; i am actually doing this work on MacOSX 10.6, so at some point I would hope to add support for the TrueType GX tables known as 'mort' and 'morx' which perform similar processes;\n\nnote that these processes (substitution/positioning/etc) allow support for a number of complex scripts, not just arabic script; e.g., the indic scripts, southeast asian, mongolian, tibetan scripts, etc, and also advanced typographic effects on latin, greek, cyrillic, etc., and east asian scripts (e.g., JISX4051) are supported by these processes as well; nevertheless, in order to make use of specific sub-tables of GSUB/GPOS, it is necessary to make use of script specific processing; therefore, I have implemented a mechanism to make use of script information, either supplied by the XSL-FO script property or, by default, scanning the characters to determine their dominant script; I have started by implementing this general mechanism and also specific Arabic and Default script processors; it will then be straightforward to add other script specific support;\n\ni don't have a fixed schedule, but I have most of the GSUB code working and tested; i am wrapping up the bidi algorithm work now, and when that is complete to submit a patch for potential incorporation into the trunk; i am hoping to have that patch done within the next 2 to 4 weeks time;\n\nas a teaser, i will add an attachment containing several files, one showing an FOP metrics file with the new data (see the <script-extras/> element); the others show the GlyphSubstitutionTable and ArabicScriptProcessor classes, which are not functionally complete, but are sufficiently complete to perform basic Arabic glyphs substitution (but not yet ligature processing);\n\nregarding how it will be used, you will need to:\n\n* possess or have access to a font in the form of a TTF file that contains GSUB/GPOS metrics; if it is to be used with Arabic, then it must should contain the GSUB lookup tables for the following features, e.g., 'isol', 'init', 'medi', 'fina', and 'liga';\n\n* create the FOP font metrics file for it by using the org.apache.fop.fonts.apps.TTFReader application;\nupdate your FOP configuration file as needed to refer to the new font and metrics;\nreference the font as usual using XSL-FO properties;\n\n* where necessary, add explicit use of <fo:bidi-override/> in order to override the default Unicode bidi logic; e.g., to override implicit directionality or to create embedding levels; you can also make use of the explicit Unicode bidi control characters, LRO RLO LRE RLE and PDF, but it is better to use explicit markup with <fo:bidi-override/>;\n\n* where necessary, to force or prevent joining behavior when the default would not join or would join, then you can use the ZWJ and ZWNJ Unicode controls, however, forced joining must be supported by the font to have an effect; while force non-joining doesn't depend on the font (though if font did not support joining of two characters in the first place then ZWNJ would have no visible effect);\n\nregards,\nglenn\n\np.s. I have an ICLA on file with the apache office;\n\n(In reply to comment #18)\n> (In reply to comment #17)\n> > FYI, I am preparing a candidate patch that will add direct support for Arabic\n> > (and other complex scripts). This primarily involves making use of the advanced\n> > typographic tables present in TrueType and OpenType fonts (e.g., 'mort',\n> > 'morx', 'GSUB' and 'GPOS' tables). Initial support will focus on use of the\n> > GSUB table. This patch will not have any external dependencies, i.e., it does\n> > not make use of ICU4J.\n> > \n> > Regards,\n> > Glenn Adams\n> \n> \n> Glenn,\n> Can you please provide more information on this as to when & how will this\n> update be available?\n> \n> Regards,\n> Sachin Sharma.", "is_private": false, "bug_id": 32789, "id": 136559, "time": "2010-04-30T03:21:13Z", "creator": "gadams@apache.org", "creation_time": "2010-04-30T03:21:13Z", "attachment_id": null}, {"count": 20, "tags": [], "bug_id": 32789, "attachment_id": 25380, "id": 136560, "time": "2010-04-30T03:28:52Z", "creator": "gadams@apache.org", "creation_time": "2010-04-30T03:28:52Z", "is_private": false, "text": "Created attachment 25380\narabic patch teaser - sample font metrics, arabic script processing code"}, {"count": 21, "tags": [], "bug_id": 32789, "text": "(In reply to comment #20)\n> Created an attachment (id=25380) [details]\n> arabic patch teaser - sample font metrics, arabic script processing code\n\nGlenn,\nThanks for the update.\n\nRegards,\nSachin Sharma.", "id": 136807, "time": "2010-05-12T08:05:50Z", "creator": "ssharma7884@gmail.com", "creation_time": "2010-05-12T08:05:50Z", "is_private": false, "attachment_id": null}, {"count": 22, "tags": [], "text": "(In reply to comment #19)\n> basically, the patch will do the following (in summary):\n> * enhance org.apache.fop.fonts.truetype.TTFFile in order to read the OpenType\n> GSUB and GPOS tables, creating new org.apache.fop.fonts.GlyphTable instances\n> which are added to MultiByteFont instances;\n> * enhance org.apache.fop.fonts.apps.TTFReader in order to write out XML\n> representation of this new data into the FOP metrics file;\n> * enhance org.apache.fop.fonts.FontReader to read the new GSUB/GPOS data stored\n> in the FOP metrics file;\n> * enhance the knuth elements generation in\n> org.apache.fop.layoutmgr.inline.TextLayoutManager, specifically, #processWord,\n> in order to perform substitution processing, which, if the current font\n> supports substitution, causes the font to invoke substitution processing using\n> the new metrics; this substitution process is a multi-stage process starting\n> with a mapping from a sequence of character codes to a sequence of glyph\n> indices, followed by one or more mappings from sequence of glyph indices to\n> sequences of glyph indices, and finally mapping back to a sequence of character\n> codes denoting the final mapped glyphs to be used;\n> * similarly, if font supports these new metrics, then perform glyph positioning\n> process to produce sequence of [dx,dy] adjustments to apply, the application of\n> which follows a somewhat updated logic to handle both X and Y advancements on a\n> per-resultant-glyph (= per output character) basis;\n> implement bidi algorithm specified in XSL-FO 1.1 Section 5.8 \"Unicode Bidi\n> Processing\", which essentially involves resolving the final\n> inline-progression-direction for each glyph or inline area child of an inline\n> area and each inline child of a line area;\n> * enhance area generation process to make use of inline-progress-direction\n> produced by bidi processing in order to reorder areas to satisfy unicode bidi\n> semantics (both explicit and implied);\n> initially, i am testing against the set of Arabic fonts shipped with Windows 7;\n> but I expect to work with a few other fonts that have GSUB/GPOS tables as well;\n> i am actually doing this work on MacOSX 10.6, so at some point I would hope to\n> add support for the TrueType GX tables known as 'mort' and 'morx' which perform\n> similar processes;\n> note that these processes (substitution/positioning/etc) allow support for a\n> number of complex scripts, not just arabic script; e.g., the indic scripts,\n> southeast asian, mongolian, tibetan scripts, etc, and also advanced typographic\n> effects on latin, greek, cyrillic, etc., and east asian scripts (e.g.,\n> JISX4051) are supported by these processes as well; nevertheless, in order to\n> make use of specific sub-tables of GSUB/GPOS, it is necessary to make use of\n> script specific processing; therefore, I have implemented a mechanism to make\n> use of script information, either supplied by the XSL-FO script property or, by\n> default, scanning the characters to determine their dominant script; I have\n> started by implementing this general mechanism and also specific Arabic and\n> Default script processors; it will then be straightforward to add other script\n> specific support;\n> i don't have a fixed schedule, but I have most of the GSUB code working and\n> tested; i am wrapping up the bidi algorithm work now, and when that is complete\n> to submit a patch for potential incorporation into the trunk; i am hoping to\n> have that patch done within the next 2 to 4 weeks time;\n> as a teaser, i will add an attachment containing several files, one showing an\n> FOP metrics file with the new data (see the <script-extras/> element); the\n> others show the GlyphSubstitutionTable and ArabicScriptProcessor classes, which\n> are not functionally complete, but are sufficiently complete to perform basic\n> Arabic glyphs substitution (but not yet ligature processing);\n> regarding how it will be used, you will need to:\n> * possess or have access to a font in the form of a TTF file that contains\n> GSUB/GPOS metrics; if it is to be used with Arabic, then it must should contain\n> the GSUB lookup tables for the following features, e.g., 'isol', 'init',\n> 'medi', 'fina', and 'liga';\n> * create the FOP font metrics file for it by using the\n> org.apache.fop.fonts.apps.TTFReader application;\n> update your FOP configuration file as needed to refer to the new font and\n> metrics;\n> reference the font as usual using XSL-FO properties;\n> * where necessary, add explicit use of <fo:bidi-override/> in order to override\n> the default Unicode bidi logic; e.g., to override implicit directionality or to\n> create embedding levels; you can also make use of the explicit Unicode bidi\n> control characters, LRO RLO LRE RLE and PDF, but it is better to use explicit\n> markup with <fo:bidi-override/>;\n> * where necessary, to force or prevent joining behavior when the default would\n> not join or would join, then you can use the ZWJ and ZWNJ Unicode controls,\n> however, forced joining must be supported by the font to have an effect; while\n> force non-joining doesn't depend on the font (though if font did not support\n> joining of two characters in the first place then ZWNJ would have no visible\n> effect);\n> regards,\n> glenn\n> p.s. I have an ICLA on file with the apache office;\n> (In reply to comment #18)\n> > (In reply to comment #17)\n> > > FYI, I am preparing a candidate patch that will add direct support for Arabic\n> > > (and other complex scripts). This primarily involves making use of the advanced\n> > > typographic tables present in TrueType and OpenType fonts (e.g., 'mort',\n> > > 'morx', 'GSUB' and 'GPOS' tables). Initial support will focus on use of the\n> > > GSUB table. This patch will not have any external dependencies, i.e., it does\n> > > not make use of ICU4J.\n> > > \n> > > Regards,\n> > > Glenn Adams\n> > \n> > \n> > Glenn,\n> > Can you please provide more information on this as to when & how will this\n> > update be available?\n> > \n> > Regards,\n> > Sachin Sharma.\n\nHi Glenn,\n\nThanks for the arabic patch teaser attachment, as this could be very useful to rendering the indic texts, and other fonts as mentioned in your comments. We are trying hard for rendering the correct letters for indic texts and other fonts too, since last few days.\n\nCan you please provide more detail information regarding how this patch to be applied / enhance to FOP 0.95?\n\nIt would be better if you can provide more information regarding changes to the following instances:-\n\n1) org.apache.fop.fonts.truetype.TTFFile\n2) org.apache.fop.fonts.apps.TTFReader\n3) org.apache.fop.fonts.FontReader\n4) org.apache.fop.layoutmgr.inline.TextLayoutManager\n\nRegards,\nDharmesh Rana", "is_private": false, "bug_id": 32789, "id": 137003, "time": "2010-05-21T01:20:21Z", "creator": "dharmesh_rana@yahoo.com", "creation_time": "2010-05-21T01:20:21Z", "attachment_id": null}, {"attachment_id": null, "tags": [], "bug_id": 32789, "is_private": false, "count": 23, "id": 137834, "time": "2010-06-23T00:43:58Z", "creator": "dharmesh_rana@yahoo.com", "creation_time": "2010-06-23T00:43:58Z", "text": "Hi Glenn,\n\nWhen is this Arabic patch going to be rleased?\n\nRegards,\nDharmesh Rana\n\n(In reply to comment #19)\n> basically, the patch will do the following (in summary):\n> * enhance org.apache.fop.fonts.truetype.TTFFile in order to read the OpenType\n> GSUB and GPOS tables, creating new org.apache.fop.fonts.GlyphTable instances\n> which are added to MultiByteFont instances;\n> * enhance org.apache.fop.fonts.apps.TTFReader in order to write out XML\n> representation of this new data into the FOP metrics file;\n> * enhance org.apache.fop.fonts.FontReader to read the new GSUB/GPOS data stored\n> in the FOP metrics file;\n> * enhance the knuth elements generation in\n> org.apache.fop.layoutmgr.inline.TextLayoutManager, specifically, #processWord,\n> in order to perform substitution processing, which, if the current font\n> supports substitution, causes the font to invoke substitution processing using\n> the new metrics; this substitution process is a multi-stage process starting\n> with a mapping from a sequence of character codes to a sequence of glyph\n> indices, followed by one or more mappings from sequence of glyph indices to\n> sequences of glyph indices, and finally mapping back to a sequence of character\n> codes denoting the final mapped glyphs to be used;\n> * similarly, if font supports these new metrics, then perform glyph positioning\n> process to produce sequence of [dx,dy] adjustments to apply, the application of\n> which follows a somewhat updated logic to handle both X and Y advancements on a\n> per-resultant-glyph (= per output character) basis;\n> implement bidi algorithm specified in XSL-FO 1.1 Section 5.8 \"Unicode Bidi\n> Processing\", which essentially involves resolving the final\n> inline-progression-direction for each glyph or inline area child of an inline\n> area and each inline child of a line area;\n> * enhance area generation process to make use of inline-progress-direction\n> produced by bidi processing in order to reorder areas to satisfy unicode bidi\n> semantics (both explicit and implied);\n> initially, i am testing against the set of Arabic fonts shipped with Windows 7;\n> but I expect to work with a few other fonts that have GSUB/GPOS tables as well;\n> i am actually doing this work on MacOSX 10.6, so at some point I would hope to\n> add support for the TrueType GX tables known as 'mort' and 'morx' which perform\n> similar processes;\n> note that these processes (substitution/positioning/etc) allow support for a\n> number of complex scripts, not just arabic script; e.g., the indic scripts,\n> southeast asian, mongolian, tibetan scripts, etc, and also advanced typographic\n> effects on latin, greek, cyrillic, etc., and east asian scripts (e.g.,\n> JISX4051) are supported by these processes as well; nevertheless, in order to\n> make use of specific sub-tables of GSUB/GPOS, it is necessary to make use of\n> script specific processing; therefore, I have implemented a mechanism to make\n> use of script information, either supplied by the XSL-FO script property or, by\n> default, scanning the characters to determine their dominant script; I have\n> started by implementing this general mechanism and also specific Arabic and\n> Default script processors; it will then be straightforward to add other script\n> specific support;\n> i don't have a fixed schedule, but I have most of the GSUB code working and\n> tested; i am wrapping up the bidi algorithm work now, and when that is complete\n> to submit a patch for potential incorporation into the trunk; i am hoping to\n> have that patch done within the next 2 to 4 weeks time;\n> as a teaser, i will add an attachment containing several files, one showing an\n> FOP metrics file with the new data (see the <script-extras/> element); the\n> others show the GlyphSubstitutionTable and ArabicScriptProcessor classes, which\n> are not functionally complete, but are sufficiently complete to perform basic\n> Arabic glyphs substitution (but not yet ligature processing);\n> regarding how it will be used, you will need to:\n> * possess or have access to a font in the form of a TTF file that contains\n> GSUB/GPOS metrics; if it is to be used with Arabic, then it must should contain\n> the GSUB lookup tables for the following features, e.g., 'isol', 'init',\n> 'medi', 'fina', and 'liga';\n> * create the FOP font metrics file for it by using the\n> org.apache.fop.fonts.apps.TTFReader application;\n> update your FOP configuration file as needed to refer to the new font and\n> metrics;\n> reference the font as usual using XSL-FO properties;\n> * where necessary, add explicit use of <fo:bidi-override/> in order to override\n> the default Unicode bidi logic; e.g., to override implicit directionality or to\n> create embedding levels; you can also make use of the explicit Unicode bidi\n> control characters, LRO RLO LRE RLE and PDF, but it is better to use explicit\n> markup with <fo:bidi-override/>;\n> * where necessary, to force or prevent joining behavior when the default would\n> not join or would join, then you can use the ZWJ and ZWNJ Unicode controls,\n> however, forced joining must be supported by the font to have an effect; while\n> force non-joining doesn't depend on the font (though if font did not support\n> joining of two characters in the first place then ZWNJ would have no visible\n> effect);\n> regards,\n> glenn\n> p.s. I have an ICLA on file with the apache office;\n> (In reply to comment #18)\n> > (In reply to comment #17)\n> > > FYI, I am preparing a candidate patch that will add direct support for Arabic\n> > > (and other complex scripts). This primarily involves making use of the advanced\n> > > typographic tables present in TrueType and OpenType fonts (e.g., 'mort',\n> > > 'morx', 'GSUB' and 'GPOS' tables). Initial support will focus on use of the\n> > > GSUB table. This patch will not have any external dependencies, i.e., it does\n> > > not make use of ICU4J.\n> > > \n> > > Regards,\n> > > Glenn Adams\n> > \n> > \n> > Glenn,\n> > Can you please provide more information on this as to when & how will this\n> > update be available?\n> > \n> > Regards,\n> > Sachin Sharma."}, {"count": 24, "tags": [], "bug_id": 32789, "text": "See also patch at, which address my prior comments on this thread:\n\nhttps://issues.apache.org/bugzilla/show_bug.cgi?id=49687\n\nRegards,\nGlenn", "id": 138811, "time": "2010-08-02T05:48:48Z", "creator": "gadams@apache.org", "creation_time": "2010-08-02T05:48:48Z", "is_private": false, "attachment_id": null}, {"count": 25, "tags": [], "creator": "gadams@apache.org", "text": "Added complex script support (bidi, shaping, etc) at revision 1293736.", "id": 154289, "time": "2012-02-27T18:09:38Z", "bug_id": 32789, "creation_time": "2012-02-27T18:09:38Z", "is_private": false, "attachment_id": null}]