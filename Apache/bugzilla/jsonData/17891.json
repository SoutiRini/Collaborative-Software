[{"count": 0, "tags": [], "creator": "chales@california.com", "is_private": false, "text": "I haven't yet tracked down the code, but if you increase the number of \nthreads per process using the worker MPM to about 50 and repeatedly hit the \nserver, you end up with 404 errors for ~ user directories that do exist.  We've \nhad a relatively easy time recreating this bug, but the solution is to reduce \nthe number of threads per process to a more reasonable number. (20 in our \ncase)  My appologies if there are known issues with large numbers of threads \nper process.  I marked this as a mod_userdir, because I couldn't recreate the \nbug with any other type of request.\n\nSteps to recreate bug:\nUsing the Worker MPM, increase the number of threads per process to 50\nLoad the web server with requests (both ~ and non ~ requests)\nWatch for 404 errors loading ~ directories that do in fact exist.", "id": 32985, "time": "2003-03-11T20:18:28Z", "bug_id": 17891, "creation_time": "2003-03-11T20:18:28Z", "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 17891, "text": "There are no known issues with large number of threads per process.  (I \nrecently spoke with some users on AIX with 3900 threads in a single\nchild process.  I've heard of more.)\n\nAlso, mod_userdir has limited room for thread-safety problems (not saying\nit is impossible, just unlikely).\n\nWhat sort of filesystem contains the user directory with the accessibility\nproblems?  NFS perhaps?\n\nCan you map this same user directory into URL space via a mechanism other than\nmod_userdir (e.g., Alias) and see if you have the same problem?\n\nThanks!\n", "id": 33015, "time": "2003-03-12T10:14:55Z", "creator": "trawick@apache.org", "creation_time": "2003-03-12T10:14:55Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 17891, "attachment_id": null, "id": 33987, "time": "2003-03-27T21:57:22Z", "creator": "chales@california.com", "creation_time": "2003-03-27T21:57:22Z", "is_private": false, "text": "Using AliasMatch the problem goes away.  Seems like the error is in the UserDir \nmodule.  This seems related to bug #14250, which also mentions intermitent \nproblems, but in this case with an additional UserDir entry.  There was only \none present in my config file, with only a single directory on it.  It may help \nto note that decreasing the number of threads in the worker MPM did help lessen \nthe problem, but didn't completely eliminate it.\nPerhaps this is in reality a library problem with Solaris?  (Noting that bug \n14250 also was a sun solaris machine)  If it receives too many user lookup \nrequests at once it fails some of them?"}, {"count": 3, "tags": [], "creator": "trawick@apache.org", "text": "What version of Solaris are you running?\n\nAnother Solaris 7 user is getting user id lookup failures when no file\ndescriptors < 256 are available.  Apparently Solaris 7 uses stdio to read\n/etc/passwd, and 32-bit Solaris stdio is busted for file descriptors >= 256.\n\nThis could cause intermittent failures at run-time based on how many file\ndescriptors are in use by other threads (a changing quantity).\n\nI can't hit the problem on a Solaris 8 box, as it uses a different mechanism to\ndo user id lookups; but I have a lot of patches applied, and it could have been\nchanged in a patch.\n", "id": 41786, "time": "2003-07-30T15:07:43Z", "bug_id": 17891, "creation_time": "2003-07-30T15:07:43Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "creator": "trawick@apache.org", "is_private": false, "text": "no response from submitter...  feel free to provide more info...\n\nif this is older Solaris that uses stdio for getpwnam() and the user id lookup\nis failing because file descriptors < 256 are in-use, there isn't a practical\nsolution for us to do\n\nyou can verify this Solaris behavior by doing a truss of the server when it\nhandles a request with mod_userdir...  with older Solaris, open() will be done\nto look up the user id...  with newer Solaris, there are door() calls\n\nrunning pfiles against a child process should tell whether or not you're running\nfairly close to the 256-file-descriptor mark\n\nto be safe, the number of file descriptors in use when idle + 2*ThreadsPerChild\nshould still be < 256...  possibly some modules would result in more than 2 open\nfds per request though\n\nif you drastically reduce the number of threads per child process and/or use\nprefork MPM maybe that will keep you far enough away from the\n256-file-descriptor mark\n", "id": 47038, "time": "2003-11-08T11:56:12Z", "bug_id": 17891, "creation_time": "2003-11-08T11:56:12Z", "attachment_id": null}]