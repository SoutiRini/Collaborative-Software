[{"count": 0, "tags": [], "creator": "waterdh@hotmail.com", "text": "sometimes ,server's cpu reaches 100%,and keep 100% all the time,until restart the server.\nthere's about 100 servers using tomcat6.0.18(nio), and each server receives more than 120 request per second, and the java version is 1.6.0_03.\ni use ps -eL to find the nid which is using highest cpu%, \nhere's the jstack infomation:\n\"http-8080-ClientPoller\" daemon prio=10 tid=0x0000002aee1ca400 nid=0x4a21 runnable [0x0000000040b39000..0x0000000040b39c30]\n   java.lang.Thread.State: RUNNABLE\n        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:184)\n        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)\n        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)\n        - locked <0x0000002a9f6c1f98> (a sun.nio.ch.Util$1)\n        - locked <0x0000002a9f6c1f80> (a java.util.Collections$UnmodifiableSet)\n        - locked <0x0000002a9edd3488> (a sun.nio.ch.EPollSelectorImpl)\n        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)\n        at org.apache.tomcat.util.net.NioEndpoint$Poller.run(NioEndpoint.java:1473)\n        at java.lang.Thread.run(Thread.java:619)\n\nhere's server.xml conf:\n<Connector executor=\"tomcatThreadPool\" port=\"8080\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" enableLookups=\"false\" \n                                   maxThreads=\"200\" acceptCount=\"500\" acceptorThreadCount=\"1\" connectionTimeout=\"5000\" compression=\"on\" redirectPort=\"8443\" />", "id": 123211, "time": "2008-12-10T02:46:49Z", "bug_id": 46373, "creation_time": "2008-12-10T02:46:49Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 46373, "is_private": false, "text": "What happens if you turn compression off?\nThere has been a bug reported to Sun about the selector waking up but reporting no keys, causing the selector thread to spin. But we haven't got a reproducible case yet.\nYour jstack output shows the thread waiting in a select, and not spinning at the very moment.\n\nIf you have more info, we would like to hear from you, to see if we can get a reproducible test case\n\nbest\nFilip", "id": 123222, "time": "2008-12-10T06:45:07Z", "creator": "fhanik@apache.org", "creation_time": "2008-12-10T06:45:07Z", "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 46373, "attachment_id": null, "is_private": false, "id": 123236, "time": "2008-12-11T01:57:22Z", "creator": "waterdh@hotmail.com", "creation_time": "2008-12-11T01:57:22Z", "text": "\n   there's many servers with compression \"on\" or \"off\",and a few of both kind of server has been found to show the same situation, cpu grows 100% suddenly,and the jstack infomation is the same, until restart tomcat.\n\n   it's hard to reproduce, there's no regular rule, but all of the servers need to process over 200 request per second .there may be something wrong with the concorrency\n   \n "}, {"count": 3, "tags": [], "bug_id": 46373, "is_private": false, "text": "This looks like it is still a JDK bug\n\nGrizzly  seem to have the same issue on linux\nhttp://www.nabble.com/Comet-handler-starts-terminating-TCP-connections-with-RST--td20337445.html\n\nFilip\n\n", "id": 123372, "time": "2008-12-17T08:49:38Z", "creator": "fhanik@apache.org", "creation_time": "2008-12-17T08:49:38Z", "attachment_id": null}, {"count": 4, "tags": [], "text": "Will it be fixed in jdk 7 ? NIO's performance is very good.\n\n", "is_private": false, "id": 123388, "creator": "waterdh@hotmail.com", "time": "2008-12-17T18:24:28Z", "bug_id": 46373, "creation_time": "2008-12-17T18:24:28Z", "attachment_id": null}, {"count": 5, "tags": [], "bug_id": 46373, "is_private": false, "id": 123389, "attachment_id": null, "creator": "fhanik@apache.org", "creation_time": "2008-12-17T20:44:37Z", "time": "2008-12-17T20:44:37Z", "text": "Well, the JDK folks thought it was already fixed, but apparently not.\nWe could try to implement a workaround for it (namely cancelling the selector and starting a new one) but that can get real messy real fast.\n\none key factor would be to have a scenario that we can reproduce, so as of now, I can't give you any certain dates when this will be fixed"}, {"count": 6, "tags": [], "bug_id": 46373, "attachment_id": null, "text": "All right, if there's some good news, let me know please. \nThank you anyway.\n\n\nBest\nWater.DH\n            ", "id": 123390, "time": "2008-12-17T21:13:27Z", "creator": "waterdh@hotmail.com", "creation_time": "2008-12-17T21:13:27Z", "is_private": false}, {"text": "Making this as invalid since it is a JVM bug.\n\nIf you can provide a reproducible test case then please re-open and we can look at the possibility of putting in a work around although as Filip suggested earlier, that could be tricky.", "tags": [], "bug_id": 46373, "is_private": false, "count": 7, "id": 123499, "time": "2008-12-23T05:21:50Z", "creator": "markt@apache.org", "creation_time": "2008-12-23T05:21:50Z", "attachment_id": null}, {"count": 8, "attachment_id": null, "creator": "knst.kolinko@gmail.com", "is_private": false, "id": 123503, "time": "2008-12-23T08:04:43Z", "bug_id": 46373, "creation_time": "2008-12-23T08:04:43Z", "tags": [], "text": "For reference:\nThe JDK bug 6403933 (mentioned in message which is referenced in comment #3) is mentioned as fixed in JDK 6u4 release notes,\n\nhttp://java.sun.com/javase/6/webnotes/6u4.html\n\nThus you should try at least that version, or better 6u7. Cannot recommend 6u10 or 6u11 yet, though."}, {"count": 9, "tags": [], "bug_id": 46373, "attachment_id": null, "is_private": false, "id": 123510, "time": "2008-12-24T00:54:14Z", "creator": "waterdh@hotmail.com", "creation_time": "2008-12-24T00:54:14Z", "text": "Ok, we will try it,thank you"}]