[{"count": 0, "tags": [], "bug_id": 49504, "attachment_id": null, "id": 137907, "time": "2010-06-25T12:08:08Z", "creator": "scott.severtson@digitalmeasures.com", "creation_time": "2010-06-25T12:08:08Z", "is_private": false, "text": "On Solaris 10 u8, HTTPD 2.2.15 occasionally has one child process hang during a graceful restart.\n\nSymptoms:\n1. At debug-level logging, the error log shows:\n[Wed Jun 23 14:38:21 2010] [debug] worker.c(1083): the listener thread didn't exit\n\nI understand this is not a major issue (https://issues.apache.org/bugzilla/show_bug.cgi?id=9011), but provides insight into execution.\n\n2. pstack of the hanging child shows the main thread is hanging while shutting down worker threads:\n\n-----------------  lwp# 1 / thread# 1  --------------------\n fffffd7fff06cdea lwp_wait (3, fffffd7fffdff964)\n fffffd7fff063eee _thrp_join () + 3e\n fffffd7fff0640cc pthread_join () + 1c\n fffffd7fff27b195 apr_thread_join () + 25\n 0000000000470a19 join_workers () + e9\n 0000000000470de3 child_main () + 353\n 0000000000471137 make_child () + 147\n 0000000000471a6e ap_mpm_run () + 8be\n 000000000042fd81 main () + 8b1\n 000000000042f08c _start () + 6c\n-----------------  lwp# 3 / thread# 3  --------------------\n fffffd7fff067527 lwp_park (0, 0, 0)\n fffffd7fff0610b9 cond_wait_queue () + 59\n fffffd7fff061647 _cond_wait () + 57\n fffffd7fff061676 cond_wait () + 26\n fffffd7fff0616b9 pthread_cond_wait () + 9\n 0000000000472cc2 ap_queue_pop () + 72\n 000000000047032d worker_thread () + 11d\n fffffd7fff06727b _thr_setup () + 5b\n fffffd7fff0674b0 _lwp_start ()\n-----------------  lwp# 4 / thread# 4  --------------------\n fffffd7fff067527 lwp_park (0, 0, 0)\n fffffd7fff0610b9 cond_wait_queue () + 59\n fffffd7fff061647 _cond_wait () + 57\n fffffd7fff061676 cond_wait () + 26\n fffffd7fff0616b9 pthread_cond_wait () + 9\n 0000000000472cc2 ap_queue_pop () + 72\n 000000000047032d worker_thread () + 11d\n fffffd7fff06727b _thr_setup () + 5b\n fffffd7fff0674b0 _lwp_start ()\n\n---SNIP---\n...lots more threads in lwp_park(0, 0, 0)...\n---SNIP---\n\n-----------------  lwp# 28 / thread# 28  --------------------\n fffffd7fff06ce2a lwp_mutex_timedlock (fffffd7ffeee0000, 0)\n fffffd7fff05fb78 mutex_lock_internal () + 328\n fffffd7fff05ff62 mutex_lock_impl () + 112\n fffffd7fff06002b mutex_lock () + b\n fffffd7fff26e5a5 proc_mutex_proc_pthread_acquire () + 15\n 000000000046ff4c listener_thread () + 3bc\n fffffd7fff06727b _thr_setup () + 5b\n fffffd7fff0674b0 _lwp_start ()\n\nIt appears that join_workers() is hanging on a call to apr_thread_join(...), in line 1104 of worker.c.\n\n\nHTTPD was compiled with Solaris's default GCC (3.4.3), with the following flags:\n\nCFLAGS=\"-O3 -m64 -march=athlon64\"\nLDFLAGS=\"-R$INSTALL_SSL/lib -L$INSTALL_SSL/lib\"\n./configure -C \\\n                --prefix=$INSTALL \\\n                --enable-mods-shared=\"deflate expires headers proxy proxy-ajp proxy-balancer proxy-connect proxy-http rewrite ssl usertrack dav status log-config logio\" \\\n                -with-ssl=$INSTALL_SSL \\\n                --with-mpm=worker \\\n                --enable-nonportable-atomics \n\nAnything other information I can provide to diagnose this issue?"}, {"count": 1, "tags": [], "bug_id": 49504, "text": "I'm seeing this on apache 2.2.22 on s11u1 as well.  More information to follow.", "id": 163103, "time": "2012-10-31T22:43:27Z", "creator": "johansen@opensolaris.org", "creation_time": "2012-10-31T22:43:27Z", "is_private": false, "attachment_id": null}, {"count": 2, "tags": [], "creator": "johansen@opensolaris.org", "attachment_id": null, "text": "As part of restarting apache, we'll send httpd a graceful restart\nsignal.  When that happens, many of the prefork children get stuck\ntrying to exit with stacks that look like this.  These processes never\nfinish exiting, and hang out indefinitely consuming system resources.\n\n151404: /usr/apache2/current/bin/httpd -f /var/run/ak/httpd.conf -k start\n fee9bd17 lwp_mutex_timedlock (fb3a0000, 0, fec72a40)\n fee8e12c mutex_lock_internal (fb3a0000, 0, 1, fee8e521) + 254\n fee8e6f0 mutex_lock_impl (fb3a0000, 0, 806954d, fee8e7ab) + 1e0\n fee8e7de mutex_lock (fb3a0000, 0, 8293228, fec9c0d1) + 42\n fec9c0e6 proc_mutex_proc_pthread_acquire (8198260, 0, 17, 80dfe00, 8047b98, fefa0970) + 22\n fec9c5d2 apr_proc_mutex_lock (8198260, 2, 0, 0) + 16\n 080a90ba child_main (17, 80a8a90, 8047c78, 80ab11b) + 2ba\n 080ab160 ap_mpm_run (80e1230, 810f2e8, 80e3128, 8072703) + 654\n 08072710 main     (5, 8047d38, 8047d50, 8047d2c) + da8\n 080718cd _start   (5, 8047e14, 8047e33, 8047e36, 8047e4d, 8047e50) + 7d\n\nThe process is blocked trying to acquire the accept_mutex in\nchild_main().  Looking at a variety of the accept_mutex fields in the\nprocesses shows many that are uninitialized, like the two below:\n\nfb3a0000 {\n    fb3a0000 flags = {\n        fb3a0000 flag1 = 0x1\n        fb3a0002 flag2 = 0\n        fb3a0003 ceiling = 0\n        fb3a0004 mbcp_type_un = {\n            fb3a0004 bcptype = 0\n            fb3a0004 mtype_rcount = {\n                fb3a0004 count_type1 = 0\n                fb3a0005 count_type2 = 0\n            }\n        }\n        fb3a0006 magic = 0\n    }\n    fb3a0008 lock = {\n        fb3a0008 lock64 = {\n            fb3a0008 pad = [ 0, 0, 0, 0, 0, 0, 0x1, 0x1 ]\n        }\n        fb3a0008 lock32 = {\n            fb3a0008 ownerpid = 0\n            fb3a000c lockword = 0x1010000\n        }\n        fb3a0008 owner64 = 0x101000000000000\n    }\n    fb3a0010 data = 0xfec72a40\n}\nfb3a0000 {\n    fb3a0000 flags = {\n        fb3a0000 flag1 = 0\n        fb3a0002 flag2 = 0\n        fb3a0003 ceiling = 0\n        fb3a0004 mbcp_type_un = {\n            fb3a0004 bcptype = 0\n            fb3a0004 mtype_rcount = {\n                fb3a0004 count_type1 = 0\n                fb3a0005 count_type2 = 0\n            }\n        }\n        fb3a0006 magic = 0\n    }\n    fb3a0008 lock = {\n        fb3a0008 lock64 = {\n            fb3a0008 pad = [ 0, 0, 0, 0, 0, 0, 0x1, 0x1 ]\n        }\n        fb3a0008 lock32 = {\n            fb3a0008 ownerpid = 0\n            fb3a000c lockword = 0x1010000\n        }\n        fb3a0008 owner64 = 0x101000000000000\n    }\n    fb3a0010 data = 0xfec72a40\n}\n\nThese don't have their magic bits set, and don't have flags that\ncorrespond to being a process robust mutex.  Here's what a good one\nought to look like:\n\nfb3a0000 {\n    fb3a0000 flags = {\n        fb3a0000 flag1 = 0x4\n        fb3a0002 flag2 = 0\n        fb3a0003 ceiling = 0\n        fb3a0004 mbcp_type_un = {\n            fb3a0004 bcptype = 0x51\n            fb3a0004 mtype_rcount = {\n                fb3a0004 count_type1 = 0x51\n                fb3a0005 count_type2 = 0\n            }\n        }\n        fb3a0006 magic = 0x4d58\n    }\n    fb3a0008 lock = {\n        fb3a0008 lock64 = {\n            fb3a0008 pad = [ 0xf2, 0xf9, 0x1, 0, 0, 0, 0, 0x1 ]\n        }\n        fb3a0008 lock32 = {\n            fb3a0008 ownerpid = 0x1f9f2\n            fb3a000c lockword = 0x1000000\n        }\n        fb3a0008 owner64 = 0x10000000001f9f2\n    }\n    fb3a0010 data = 0xfec72a40\n}\n\nSince we got lucky, and had all of the processes map this mutex at the\nsame location in their address space, it's possible to walk the mapping\nsegments in the kernel, and observe who is sharing anonymous mappings.\nWhen a process uses mmap(2) with MAP_SHARED and MAP_ANON, all processes\nthat share the same anonymous mapping use the same struct anon_map.\n\nHere are the refcounts for all of the anon_map entries for segments\nmapped at this address.\n\nfffff6033c5493e0 refcnt = 0x6\nfffff6033c5493e0 refcnt = 0x6\nfffff6033c5493e0 refcnt = 0x6\nfffff6033c5493e0 refcnt = 0x6\nfffff6033c5493e0 refcnt = 0x6\nfffff6033c5493e0 refcnt = 0x6\nfffff60331b0a938 refcnt = 0x5\nfffff60331b0a938 refcnt = 0x5\nfffff60331b0a938 refcnt = 0x5\nfffff60331b0a938 refcnt = 0x5\nfffff60331b0a938 refcnt = 0x5\nfffff60315a4c240 refcnt = 0x3\nfffff60315a4c240 refcnt = 0x3\nfffff60315a4c240 refcnt = 0x3\nfffff60336801470 refcnt = 0x3\nfffff60336801470 refcnt = 0x3\nfffff60336801470 refcnt = 0x3\nfffff6035cb691c8 refcnt = 0x2\nfffff6035cb691c8 refcnt = 0x2\nfffff6032f20e4e8 refcnt = 0x2\nfffff6032f20e4e8 refcnt = 0x2\nfffff6033c30e030 refcnt = 0x1\nfffff60385a833d8 refcnt = 0x2\nfffff60385a833d8 refcnt = 0x2\nfffff6036a7f2f08 refcnt = 0x3\nfffff6036a7f2f08 refcnt = 0x3\nfffff6036a7f2f08 refcnt = 0x3\nfffff603eb317f08 refcnt = 0x4\nfffff603eb317f08 refcnt = 0x4\nfffff603eb317f08 refcnt = 0x4\nfffff603eb317f08 refcnt = 0x4\nfffff60496ccebe0 refcnt = 0x2\nfffff60496ccebe0 refcnt = 0x2\nfffff60443485580 refcnt = 0x3\nfffff60443485580 refcnt = 0x3\nfffff60443485580 refcnt = 0x3\nfffff6026ef6fb50 refcnt = 0x3\nfffff6026ef6fb50 refcnt = 0x3\nfffff6026ef6fb50 refcnt = 0x3\nfffff60425527d68 refcnt = 0x3\nfffff60425527d68 refcnt = 0x3\nfffff60425527d68 refcnt = 0x3\nfffff6016d080d70 refcnt = 0x1\nfffff60088c6f8b0 refcnt = 0x2\nfffff60088c6f8b0 refcnt = 0x2\nfffff60314dd5028 refcnt = 0x2\nfffff60314dd5028 refcnt = 0x2\nfffff60308085ac0 refcnt = 0x1\nIf the mutex were being correctly shared between all httpd processes, we\nshould only a single anon_map object, with a much higher reference\ncount.  Instead, there are multiple anon_map structures, each with a few\nmappings referencing them.  This strongly implies that somebody has\nunmapped the shared mutex, and created a new mapping on top of it.\n\nUsing DTrace, we can see some suspicious invocations of both the create\nand cleanup of this type of mutex.\n\n  1 125899 proc_mutex_proc_pthread_cleanup:entry\n              libapr-1.so.0.3.9`proc_mutex_proc_pthread_cleanup\n              libapr-1.so.0.3.9`apr_proc_mutex_cleanup+0x16\n              libapr-1.so.0.3.9`apr_pool_clear+0x7bf\n              httpd`main+0xc7d\n              httpd`_start+0x7d\n\n  1 125900 proc_mutex_proc_pthread_create:entry\n              libapr-1.so.0.3.9`proc_mutex_proc_pthread_create\n              libapr-1.so.0.3.9`apr_proc_mutex_create+0x98\n              httpd`ap_mpm_run+0x82\n              httpd`main+0xda8\n              httpd`_start+0x7d\n\nSince we know the address of the accept_mutex, it's actually possible to\ncatch the specific call to the cleanup and the munmap.  This looks bad.\n\ndestroying accept mutex 8198260\n\n              libapr-1.so.0.3.9`proc_mutex_proc_pthread_cleanup\n              libapr-1.so.0.3.9`apr_proc_mutex_cleanup+0x16\n              libapr-1.so.0.3.9`apr_pool_clear+0x7bf\n              httpd`main+0xc7d\n              httpd`_start+0x7d\n\nUnmapping mutex at fb3a0000\n\n              libc.so.1`munmap+0x7\n              libapr-1.so.0.3.9`apr_proc_mutex_cleanup+0x16\n              libapr-1.so.0.3.9`apr_pool_clear+0x7bf\n              httpd`main+0xc7d\n              httpd`_start+0x7d\n\nAccording to DTrace, we're calling proc_mutex_proc_pthread_cleanup on\nthe accept_mutex out of apr_pool_clear every time we go back to the top\nof the for loop in main().\n\nHere's an explanation of the code flow:\n\nin server/main.c main():\n\n    for (;;) {\n        apr_hook_deregister_all();\n(3) --> apr_pool_clear(pconf);\n\n        for (mod = ap_prelinked_modules; *mod != NULL; mod++) {\n            ap_register_hooks(*mod, pconf);\n        }\n\n        /* This is a hack until we finish the code so that it only reads\n         * the config file once and just operates on the tree already in\n         * memory.  rbb\n         */\n        ap_conftree = NULL;\n        apr_pool_create(&ptemp, pconf);\n        apr_pool_tag(ptemp, \"ptemp\");\n        ap_server_root = def_server_root;\n        server_conf = ap_read_config(process, ptemp, confname, &ap_conftree);\n        if (!server_conf) {\n            destroy_and_exit_process(process, 1);\n        }\n        /* sort hooks here to make sure pre_config hooks are sorted properly */\n        apr_hook_sort_all();\n\n        if (ap_run_pre_config(pconf, plog, ptemp) != OK) {\n            ap_log_error(APLOG_MARK, APLOG_STARTUP |APLOG_ERR,\n                         0, NULL, \"Pre-configuration failed\");\n            destroy_and_exit_process(process, 1);\n        }\n\n        if (ap_process_config_tree(server_conf, ap_conftree, process->pconf,\n                                   ptemp) != OK) {\n            destroy_and_exit_process(process, 1);\n        }\n        ap_fixup_virtual_hosts(pconf, server_conf);\n        ap_fini_vhost_config(pconf, server_conf);\n        /*\n         * Sort hooks again because ap_process_config_tree may have added\n         * modules and hence hooks. This happens with mod_perl and modules\n         * written in perl.\n         */\n        apr_hook_sort_all();\n        apr_pool_clear(plog);\n        if (ap_run_open_logs(pconf, plog, ptemp, server_conf) != OK) {\n            ap_log_error(APLOG_MARK, APLOG_STARTUP |APLOG_ERR,\n                         0, NULL, \"Unable to open logs\");\n            destroy_and_exit_process(process, 1);\n        }\n\n        if (ap_run_post_config(pconf, plog, ptemp, server_conf) != OK) {\n            ap_log_error(APLOG_MARK, APLOG_STARTUP |APLOG_ERR,\n                         0, NULL, \"Configuration Failed\");\n            destroy_and_exit_process(process, 1);\n        }\n\n        apr_pool_destroy(ptemp);\n        apr_pool_lock(pconf, 1);\n\n        ap_run_optional_fn_retrieve();\n\n(1) --> if (ap_mpm_run(pconf, plog, server_conf))\n            break;\n\n        apr_pool_lock(pconf, 0);\n    }\n\nin server/mpm/prefork/prefork.c ap_mpm_run():\n\n    int ap_mpm_run(apr_pool_t *_pconf, apr_pool_t *plog, server_rec *s)\n    {\n        int index;\n        int remaining_children_to_start;\n        apr_status_t rv;\n\n        ap_log_pid(pconf, ap_pid_fname);\n\n        first_server_limit = server_limit;\n        if (changed_limit_at_restart) {\n            ap_log_error(APLOG_MARK, APLOG_WARNING, 0, s,\n                         \"WARNING: Attempt to change ServerLimit \"\n                         \"ignored during restart\");\n            changed_limit_at_restart = 0;\n        }\n\n        /* Initialize cross-process accept lock */\n        ap_lock_fname = apr_psprintf(_pconf, \"%s.%\" APR_PID_T_FMT,\n                                     ap_server_root_relative(_pconf, ap_lock_fname),\n                                     ap_my_pid);\n\n(2) --> rv = apr_proc_mutex_create(&accept_mutex, ap_lock_fname,\n                                   ap_accept_lock_mech, _pconf);\n        <...>\n\nin srclib/apr/locks/unix/proc_mutex.c proc_mutex_pthread_cleanup():\n\n    static apr_status_t proc_mutex_proc_pthread_cleanup(void *mutex_)\n    {\n        apr_proc_mutex_t *mutex=mutex_;\n        apr_status_t rv;\n\n        if (mutex->curr_locked == 1) {\n            if ((rv = pthread_mutex_unlock(mutex->pthread_interproc))) {\n    #ifdef HAVE_ZOS_PTHREADS\n                rv = errno;\n    #endif\n                return rv;\n            }\n        }\n        /* curr_locked is set to -1 until the mutex has been created */\n        if (mutex->curr_locked != -1) {\n(4) -->     if ((rv = pthread_mutex_destroy(mutex->pthread_interproc))) {\n    #ifdef HAVE_ZOS_PTHREADS\n                rv = errno;\n    #endif\n                return rv;\n            }\n        }\n(5) --> if (munmap((caddr_t)mutex->pthread_interproc, sizeof(pthread_mutex_t))) {\n            return errno;\n        }\n        return APR_SUCCESS;\n    }\n\nEach call to ap_mpm_run (1) generates a call to apr_proc_mutex_create\n(2).  This means that every time through the for(;;) loop we call\nap_mpm_run, we'll be creating a new accept_mutex.  The exiting threads\nend up getting stuck when ap_mpm_run returns, goes to the top of the for\nloop and calls apr_pool_clear (3).  This causes the\nproc_mutex_proc_pthread_cleanup function to be invoked on the\naccept_mutex.  This results in the mutex being uninitialized (4) and\nthen unmapped (5).  Because there are other processes operating on this\nshared mapping at the time that (4) and (5) occur, the master process\neffectively zeros the mutex, and releases the mapping stranding the\nforked worker processes with an uninitialized mutex.  Any attempt to\nacquire this lock now blocks indefinitely, because the mutex is in an\nundefined state.\n\nI can think of a couple possible solutions, but there are probably more\nclever ones available too.\n\n - Re use the accept_mutex across ap_mpm_calls instead of creating a new\n   one each time.\n\n - Reference count the mutex and only call pthread_mutex_destroy when\n   the reference count reaches zero.", "id": 163104, "time": "2012-10-31T22:45:57Z", "bug_id": 49504, "creation_time": "2012-10-31T22:45:57Z", "is_private": false}, {"count": 3, "tags": [], "bug_id": 49504, "text": "Same problem on linux-2.6.32 (libc6-2.11, having pthread_mutexattr_setrobust_np) and httpd-2.2.24, though the child does not hang but logs :\n [Wed Apr 17 17:08:04 2013] [debug] worker.c(792): (22)Invalid argument: apr_proc_mutex_unlock failed. Attempting to shutdown process gracefully.\n\nThe 2 following patches (against 2.2.x and trunk) fix the problem by creating the (proc_pthread_)accept_mutex on the process pool, and reusing on restarts.", "id": 166676, "time": "2013-04-17T15:16:01Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2013-04-17T15:16:01Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "bug_id": 49504, "attachment_id": 30207, "id": 166677, "time": "2013-04-17T15:19:50Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2013-04-17T15:19:50Z", "is_private": false, "text": "Created attachment 30207\nAccept mutex on process pool against 2.2.x\n\nThis patch is against 2.2.x"}, {"count": 5, "tags": [], "creator": "ylavic.dev@gmail.com", "attachment_id": 30208, "text": "Created attachment 30208\nAccept mutex on process pool against trunk\n\nThis patch is against trunk", "id": 166678, "time": "2013-04-17T15:21:44Z", "bug_id": 49504, "creation_time": "2013-04-17T15:21:44Z", "is_private": false}, {"count": 6, "tags": [], "bug_id": 49504, "text": "The patch against trunk also works on 2.4.x.", "id": 166679, "time": "2013-04-17T15:47:02Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2013-04-17T15:47:02Z", "is_private": false, "attachment_id": null}, {"count": 7, "tags": [], "creator": "rainer.jung@kippdata.de", "attachment_id": null, "text": "*** Bug 55239 has been marked as a duplicate of this bug. ***", "id": 168940, "time": "2013-07-30T08:33:13Z", "bug_id": 49504, "creation_time": "2013-07-30T08:33:13Z", "is_private": false}, {"count": 8, "tags": [], "creator": "ylavic.dev@gmail.com", "attachment_id": null, "text": "Can someone with a Solaris system test the above patch?\nThis seems to be an issue related to proc_mutex's pool lifetime, which is addressed there.\n\nIt runs since one year now in production systems (Linux only though, not Solaris), no problem so far.\nThe caveat is that (graceful-)restarts leak a mmaped (pthread_)mutex should it not be used anymore (the process pool is never cleared).\nThat's a small sizeof(pthread_mutex_t) leak however, and listeners don't change that much on restarts (usually).", "id": 174941, "time": "2014-04-30T12:13:22Z", "bug_id": 49504, "creation_time": "2014-04-30T12:13:22Z", "is_private": false}, {"count": 9, "tags": [], "bug_id": 49504, "text": "A non-leaking patch should be relatively easy to create...", "id": 177432, "time": "2014-08-28T20:28:58Z", "creator": "jim@apache.org", "creation_time": "2014-08-28T20:28:58Z", "is_private": false, "attachment_id": null}, {"count": 10, "tags": [], "creator": "ylavic.dev@gmail.com", "attachment_id": null, "text": "(In reply to Jim Jagielski from comment #9)\n> A non-leaking patch should be relatively easy to create...\n\nI don't find it so easy because we have to wait for all the children using the mutex to exit before we can pthread_mutex_destroy() it (so to avoid the corruption of the shared-mmap()ing while the children are sill running).\n\nFor graceful restarts, this may happen long after the parent has reloaded the new configuration, hence created/destroyed the new/unused-old mutexes.\n\nWe could use a refcounter, incremented whenever a child is created, decremented when it exits, and then destroy the mutex only when the counter reaches 0 (the parent process would hold its own reference until the mutex is not configured anymore to avoid some race conditions).\nBut this seems to require a synchronisation which does not exist yet in httpd (between the mpm creating the child and perform_idle_server_maintenance() where the child exit is taken into account?).\n\nAnother possibility would be to include this refcounter into the mmap()ing (eg. sizeof(refcounter_t) + sizeof(pthread_mutex_t)), and then increment in proc_mutex_proc_pthread_create() AND proc_mutex_proc_pthread_child_init() (which is proc_mutex_no_child_init() for now). To decrement the refcounter, apr_proc_mutex_child_init() would register a cleanup on its given pool (pchild) which should be destroyed/cleared upon exit (mpm's clean_child_exit() does destroy pchild).\nHowever that won't work with [seg]faulting children (they don't destroy pchild), so the refcounter may still be wrong and the mutex still leak...\n\nYet another possibility would be to not call pthread_mutex_destroy() in proc_mutex_proc_pthread_cleanup(), only munmap()ing the region (the mmap()ing would still be valid for all the fork()ed children until all of them exit).\nThis shouldn't hurt since (AFAICT) pthread_mutex_t does not hold system resources, otherwise \"mutex = PTHREAD_MUTEX_INITIALIZER;\" could not be used to initialize a mutex instead of pthread_mutex_init().\nSo the only leek to care about when cleaning up is probably the mmap()ing.\n\nThe last two proposals are APR things though, not httpd.\n\nI guess I'm missing an obvious solution...", "id": 177440, "time": "2014-08-29T14:03:05Z", "bug_id": 49504, "creation_time": "2014-08-29T14:03:05Z", "is_private": false}, {"count": 11, "tags": [], "creator": "ylavic.dev@gmail.com", "attachment_id": null, "text": "(In reply to Yann Ylavic from comment #10)\n> Yet another possibility would be to not call pthread_mutex_destroy() in\n> proc_mutex_proc_pthread_cleanup(), only munmap()ing the region\n\nproc_mutex_proc_pthread_cleanup() could also destroy a copy of the pthread_mutex_t, eg.\n\nIndex: locks/unix/proc_mutex.c\n===================================================================\n--- locks/unix/proc_mutex.c\t(revision 1568989)\n+++ locks/unix/proc_mutex.c\t(working copy)\n@@ -347,7 +347,8 @@ static apr_status_t proc_mutex_proc_pthread_cleanu\n     }\n     /* curr_locked is set to -1 until the mutex has been created */\n     if (mutex->curr_locked != -1) {\n-        if ((rv = pthread_mutex_destroy(mutex->pthread_interproc))) {\n+        pthread_mutex_t copy = *mutex->pthread_interproc;\n+        if ((rv = pthread_mutex_destroy(&copy))) {\n #ifdef HAVE_ZOS_PTHREADS\n             rv = errno;\n #endif", "id": 177441, "time": "2014-08-29T14:19:11Z", "bug_id": 49504, "creation_time": "2014-08-29T14:19:11Z", "is_private": false}, {"text": "Hi,\n\nsame problem here.\nBug was not in our compilation of apache 2.4.4\nI do see this bug in \n2.4.12 the latest official release and\n2.4.14 snapshot", "tags": [], "creator": "RLehmann.external@V-TServices.unicredit.de", "attachment_id": null, "count": 12, "id": 183619, "time": "2015-06-18T07:32:20Z", "bug_id": 49504, "creation_time": "2015-06-18T07:32:20Z", "is_private": false}, {"count": 13, "tags": [], "creator": "RLehmann.external@V-TServices.unicredit.de", "attachment_id": null, "text": "Hi,\n\ntried it with just released\n2.4.16\nThe number of \"G\" apache processes still grows with every graceful restart.", "id": 184464, "time": "2015-08-11T08:04:55Z", "bug_id": 49504, "creation_time": "2015-08-11T08:04:55Z", "is_private": false}, {"count": 14, "tags": [], "bug_id": 49504, "attachment_id": null, "id": 187661, "time": "2016-01-14T12:36:58Z", "creator": "RLehmann.external@V-TServices.unicredit.de", "creation_time": "2016-01-14T12:36:58Z", "is_private": false, "text": "Hi,\n\ntried 2.4.18 on Solaris 10.\nStill the number of leaked processes grows, but not with every graceful restart, as it was seen with 2.4.16.\nSometimes a graceful restart does not increase the number of lost processes. I have not found a real rule, of when it happens and when it does not happen."}, {"count": 15, "tags": [], "creator": "ylavic.dev@gmail.com", "attachment_id": null, "text": "Proposed fix commited in r1733694.", "id": 189129, "time": "2016-03-05T09:35:21Z", "bug_id": 49504, "creation_time": "2016-03-05T09:35:21Z", "is_private": false}, {"count": 16, "tags": [], "bug_id": 49504, "text": "Backported in 1.5.x (r1738800) and 1.6.x (r1738793).", "id": 190210, "time": "2016-04-13T12:08:41Z", "creator": "ylavic.dev@gmail.com", "creation_time": "2016-04-13T12:08:41Z", "is_private": false, "attachment_id": null}]