[{"count": 0, "tags": [], "bug_id": 45073, "is_private": false, "text": "The APR connector doesn't support pipelined requests. This is because the InternalAPRInputBuffer is flushed between requests and may be reassigned to a different socket. This could loose a pipelined request.\n\nPipelined requests are defined in RFC2616, sec 8.1.2.2. I have attached a simple python test script. The behavior is different depending on whether the APR or internal Http11 connector is used.\n\nThere is no-requirement for 2 requests to be in different packets and if TCP_NODELAY is _NOT_ set they may well be coalesced into the same packet by the Nagle algorithm. This means that they will both be read into the InputBuffer together but the second will be discarded when the first request is completed.\n\nThe connector unable to enforce the maxKeepAliveRequests configuration parameter. Currently this works to enable or disable keep alives but cannot enforce anything else because the current limit (number remaining) for this socket isn't passed around between the poller, sendfile, worker etc.\n\n<opinion>\nProbably the correct fix here is to assign the InternalAPRInputBuffer and InternalAPROutputBuffer to the connection in the acceptor and then pass these around for the life of the socket. We can also add the limits and statistics to these buffers. In this way, if a second request is read up into the buffer with the first, it will still be there when the first request is completed.\n</opinion>", "id": 116942, "time": "2008-05-23T15:07:29Z", "creator": "alex@planet-barclay.com", "creation_time": "2008-05-23T15:07:29Z", "attachment_id": null}, {"count": 1, "tags": [], "text": "Created attachment 21998\nSend 2 pipelined requests. See what happens\n\nThis simple script (you'll have to modify to where you have put your files) works on the internal Http11 connector but only gives the first file on the APR connector.\n\nI have not tested this against the NIO connector.", "is_private": false, "id": 116945, "creator": "alex@planet-barclay.com", "time": "2008-05-23T16:00:43Z", "bug_id": 45073, "creation_time": "2008-05-23T16:00:43Z", "attachment_id": 21998}, {"count": 2, "text": "That's a design decision. In some cases, pipelining will not happen. This will not be fixed.", "bug_id": 45073, "is_private": false, "id": 116953, "time": "2008-05-25T08:20:34Z", "creator": "remm@apache.org", "creation_time": "2008-05-25T08:20:34Z", "tags": [], "attachment_id": null}, {"count": 3, "tags": [], "bug_id": 45073, "text": "Thinking about it some more, this is not the case. If data which belongs to another request has been read, it will be used. Otherwise, it will get to the poller. No data will be lost.", "id": 116956, "time": "2008-05-25T08:27:14Z", "creator": "remm@apache.org", "creation_time": "2008-05-25T08:27:14Z", "is_private": false, "attachment_id": null}, {"count": 4, "tags": [], "text": "Then you're missing the point.\n\n1) You didn't actually try the test case. Your code is broken. It doesn't support HTTP1.1. If you want to rename it to an HTTP1.0 connector then this would be fine.\n\n2) The second request may be in-flight before the response has been sent. It wouldn't be read _BUT_ when the buffer is recycled it is reset and you LOST that second request\n\n3) I don't see anywhere in the HTTP1.1 specification where it says \"The server MAY support pipelining in some cases\".\n\n4) If the data has already been read it will not be used because the buffer was recycled after the data was sent.\n\nIt may have been a design decision but it was an exceptionally poor one.\n", "is_private": false, "id": 116958, "creator": "alex@planet-barclay.com", "time": "2008-05-25T11:38:09Z", "bug_id": 45073, "creation_time": "2008-05-25T11:38:09Z", "attachment_id": null}, {"count": 5, "tags": [], "bug_id": 45073, "text": "I recommend finding a server which suits your needs then. As I said, pipelining does work (it is obvious the main loop in process will use bytes that have been read into the buffer). In special cases, like comet or sendfile, pipelining may not be supported, and that's really the way it is (don't use these features if you are using pipelining). Please do not reopen the report.", "id": 116959, "time": "2008-05-25T11:57:03Z", "creator": "remm@apache.org", "creation_time": "2008-05-25T11:57:03Z", "is_private": false, "attachment_id": null}, {"count": 6, "tags": [], "text": "I will stop reopening this defect when you actually address the issues raised other than saying, \"we don't want to follow HTTP1.1\". Which is an absolutely ludicrous approach.\n\n", "is_private": false, "bug_id": 45073, "id": 116960, "time": "2008-05-25T13:39:50Z", "creator": "alex@planet-barclay.com", "creation_time": "2008-05-25T13:39:50Z", "attachment_id": null}, {"count": 7, "tags": [], "bug_id": 45073, "text": "You should clarify your report, as your \"test case\" that I supposedly have to use does nothing by itself.\n\nSupporting pipelining is quite complex for comet and async sendfile, so this looks like some reasonable limitation to me (if you want to comply with the letter of the spec, it is possible to close the connection after processing such a request if there was leftover input - this sounds useless to me, but is a possibility). If the pipelining problem affects regular requests (everything happens synchronously inside the process method of the processor, so I don't see how your vague claims about \"in flight\" stuff could mean something), feel free to reopen the report. Otherwise, you might want to start working on a more accurate bug report.", "id": 116961, "time": "2008-05-25T14:06:19Z", "creator": "remm@apache.org", "creation_time": "2008-05-25T14:06:19Z", "is_private": false, "attachment_id": null}]