[{"count": 0, "tags": [], "bug_id": 51814, "text": "if mod_proxy, but during being FIN_WAIT2 in server side, it leaves as CLOSE_WAIT for a long time in mod_proxy side.\n\nThis might be only a small bad effect for this phenomenon, but we think this occurs because of  not preferred implementation of Apache httpd mod_proxy.\nSpecifically, mod_prxoy sends FIN by KeepAliveTimeout from backend server side. When it gets it, it returns using FIN and ACK, then wants to release ports that is in use.\n \nThis is because of the following reasons:\n*Keeping unnecessary resource for a long time, this might occur some unexpected bugs in the future.\n*If CLOSE_WAIT condition continues for a long time and then there is Firewall between mod_proxy_http and backend, then you have to keep unnecessary session and this might affect communication session.\n*If there is FIN and ACK that after there is a long time gap, then it would already be after Firewall destroys that session and Firewall might show warning messages.  \n  \nAlso in mod_proxy in Apache 2.0, if client doesn't use KeepAlive, the connection between mod_proxy and backend server ends, and confirms that CLOSE_WAIT doesn\u2019t stays.   In short, Apache 2.2 doesn't behave good than Apache 2.0.\nWhen we compare Apache 2.2 and 2.0 source, in Apache 2.0 mod_proxy, client side TCP session extension of the ending process, it closes TCP session between backend server using apr_socket_close() function. However, in Apache 2.2 mod_proxy_http, it changes as to call connection_clceanup() or socket_cleanup(), and we thiknk this is because it doesn\u2019t do apr_socket_close() in the function. In short, 2.2 doesn't close the session that is immediately close when KeepAlive is invalid. We assume that this is a simple bug that forgets to close when mod_proxy\u2019s refactoring.\n\n\n\n\n(1) Client is HTTP/1.0 and KeepAlive is none, so every time the connection ends by FIN. \n\n(2) mod_proxy_http doesn\u2019t disconnect after receiving the result of backend server  request.\n\n(3) Backend server though FIN at 30.007sec by KeepAliveTimeout. mod_proxy_http doesn\u2019t return FIN for this. \n\nPort 47875 of mod_proxy_http becomes CLOSE_WAIT after this.   \n(4) New request reaches mod_proxy_http at 41.547sec and creating a different new TCP section at 41.546sec. This is also throwing FIN and then disconnecting it, but it\u2019s NOT disconnecting in the backend server side. However, it\u2019s disconnecting from backend server side at 71,545, but mod_proxy_http doesn\u2019t return FIN. After this, Port 47486 of mod_proxy_http becomes CLOSE_WAI.T\n\n(5) Client throws a new request to mod_proxy_http at 77.157sec. At this time, at 77.159sec, mod_proxy_http thows FIN and ACK from the above # (3), port 47485, then the first time that (3) session ends here.  It took 47 seconds until here, and if we compare it with KeepAliveTimeout that is set at the backend server, there is a big gap.\n \nWe have done it a few times and found out the following:  \na) mod_proxy_http uses KeepAlive between backend, although client doesn't use KeepAlive.\n\nb) Even if Backend send FIN by KeepAliveTimeout, mod_proxy_http doesn\u2019t response and become CLOSE_WAIT.\n\nc) mod_proxy_http becomes CLOSE_WAIT when a new request recives.\n\nd) However, if a new request doesn\u2019t come then it never sends FIN to an old connection and stays as CLOSE_WAIT forever.\n \nWe assume that b) and d) are not good behaviors for TCP/IP connections.  Already connection to client is disconnected; it doesn\u2019t depend on client\u2019s KeepAlive behavior.", "id": 149242, "time": "2011-09-14T20:49:53Z", "creator": "wendell_hatcher@comcast.net", "creation_time": "2011-09-14T20:49:53Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "creator": "sebastien.allamand@orange.com", "text": "Hello, Is there any news about this bug ?", "id": 162790, "time": "2012-10-17T09:56:51Z", "bug_id": 51814, "creation_time": "2012-10-17T09:56:51Z", "is_private": false, "attachment_id": null}, {"count": 2, "attachment_id": null, "bug_id": 51814, "is_private": false, "id": 162793, "time": "2012-10-17T11:43:21Z", "creator": "covener@gmail.com", "creation_time": "2012-10-17T11:43:21Z", "tags": [], "text": "NEEDINFO = info needed from originator"}, {"count": 3, "tags": [], "text": "I'm reclassifying this an enhancement -- check for closed idle connections in the pool more frequently or asynchronously. The fact that they may sit in a closed state before being noticed is not itself a defect IMO.", "is_private": false, "bug_id": 51814, "id": 162794, "time": "2012-10-17T12:03:16Z", "creator": "covener@gmail.com", "creation_time": "2012-10-17T12:03:16Z", "attachment_id": null}]