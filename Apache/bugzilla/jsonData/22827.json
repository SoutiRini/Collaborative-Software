[{"count": 0, "tags": [], "bug_id": 22827, "attachment_id": null, "is_private": false, "id": 43490, "time": "2003-08-29T23:37:34Z", "creator": "eseidel@apple.com", "creation_time": "2003-08-29T23:37:34Z", "text": "I'm assuming this is a concious choice (that it's not fixed in 1.3.x), but as i \ndid not find the bug in your database, I figured I would report it... and get \nthe offical answer.  if this is \"not to be fixed\" it would be great to add it \nto the FAQ.\n\nSo the problem is, Content-Length in 1.3.x is a signed int.  If I remember from \nthe HTTP 1.1 spec, Content-Length is actually unsigned... or at least negative \nvalues have no meaning.\n\nThe signed-int limitation causes apache 1.3.x to return negative content \nlenghts for files over 2 gig in size.  wget handles this OK, but curl and many \nbrowsers do not.  (We've had to hack our version of curl to handle these large \nnegatives.)\n\nMy proposed \"hack\" would be to typecast the signed int as an unsigned int, \nbefore printing, but I imagine you all have many good reasons not to do this...  \nI would just love to hear them.  (If that were to happen, suddenly 1.3.x would \nsupport 2 - 4 gig files correctly.)\n\nAnyway, thanks for your time.\n\n-eric\n\np.s. Should I file a feature request to Apache 2.x that they use something \nlarger than an unsigned int to hold content length?  My last reading through \nthe code suggested that 2.x would also break at the 4 gig barrier which we are \nrapidly approaching (at least hear at Apple)."}, {"text": "A patch to print c-l as an unsigned long would make some sense for 1.3. \n\n2.0 uses off_t to store file sizes throughout so should be able to cope\ncorrectly with files > 4gb in size on BSD-derivatives, though there will be some\nissues since this doesn't get exercised much (e.g. bug 28898).", "tags": [], "creator": "jorton@redhat.com", "is_private": false, "count": 1, "id": 62436, "time": "2004-08-24T20:49:48Z", "bug_id": 22827, "creation_time": "2004-08-24T20:49:48Z", "attachment_id": null}, {"count": 2, "tags": [], "bug_id": 22827, "attachment_id": null, "is_private": false, "id": 66270, "time": "2004-11-02T04:11:54Z", "creator": "merlin@ghostwheel.com", "creation_time": "2004-11-02T04:11:54Z", "text": "I encountered this problem this evening with a 2.5G file on an Apache 1.3.31\nserver.  I attempted to duplicate on my server which is 1.3.33, and I was able\nto reproduce:\n\nCreated a dummy file:\nprimus# dd if=/dev/zero\nof=/usr/home/merlin/www.ghostwheel.com/htdocs/sizetest.bin bs=1048576 count=2560\n2560+0 records in\n2560+0 records out\n2684354560 bytes transferred in 430.192793 secs (6239887 bytes/sec)\n\nRetrieved the headers for the test file using the perl lwp HEAD command:\nprimus# HEAD http://www.ghostwheel.com/sizetest.bin\n200 OK\nConnection: close\nDate: Tue, 02 Nov 2004 04:09:10 GMT\nAccept-Ranges: bytes\nETag: \"220820-a0000000-418706db\"\nServer: Apache/1.3.33 (Unix)\nContent-Length: -1610612736\nContent-Type: application/octet-stream\nLast-Modified: Tue, 02 Nov 2004 04:02:35 GMT\nClient-Date: Tue, 02 Nov 2004 04:09:10 GMT\nClient-Peer: 66.118.178.74:80\nClient-Response-Num: 1\n\nI did search through the bug db, and noticed that this one was opened over a\nyear ago.  As storage gets cheaper files get larger this bug will appear to end\nusers more often; so I felt it worthwhile to update this bug entry.\n\n-Chris"}, {"count": 3, "tags": [], "bug_id": 22827, "attachment_id": null, "is_private": false, "id": 67854, "time": "2004-12-03T01:55:40Z", "creator": "jim@apache.org", "creation_time": "2004-12-03T01:55:40Z", "text": "1.3 has quite a few internal assumptions regarding 32 bit (signed) values... this would be one\nsmall step in the right direction, but this is really a reason to upgrade to 2.x"}]