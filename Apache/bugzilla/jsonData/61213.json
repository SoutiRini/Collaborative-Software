[{"count": 0, "tags": [], "creator": "fanningpj@yahoo.com", "text": "I have been looking at a replacement. I will attach the code shortly. I would like to get it reviewed before merging it.", "id": 199376, "time": "2017-06-24T09:28:19Z", "bug_id": 61213, "creation_time": "2017-06-24T09:28:19Z", "is_private": false, "attachment_id": null}, {"count": 1, "tags": [], "bug_id": 61213, "attachment_id": 35073, "text": "Created attachment 35073\nuse Stax to parse the worksheet data\n\nI can merge this if it is ok", "id": 199377, "time": "2017-06-24T10:08:21Z", "creator": "fanningpj@yahoo.com", "creation_time": "2017-06-24T10:08:21Z", "is_private": false}, {"count": 2, "tags": [], "creator": "fanningpj@yahoo.com", "text": "Created attachment 35074\nreload the patch.tar.gz", "id": 199378, "time": "2017-06-24T10:09:50Z", "bug_id": 61213, "creation_time": "2017-06-24T10:09:50Z", "is_private": false, "attachment_id": 35074}, {"count": 3, "tags": [], "text": "Did take a quick look: We are currently just copying the XML Stream as text and would now parse the XML again and write it out again via XML serialization, do you have an idea of how much impact that has for very large files? \n\nSXSSF is used specifically for handling huge files (customers seemsto have documents with more than 4GB uncompressed size, also multiple millions of rows), we need to check that doing this additional parsing/serializing is not slower for such large files.", "is_private": false, "id": 199423, "creator": "dominik.stadler@gmx.at", "time": "2017-06-26T13:18:10Z", "bug_id": 61213, "creation_time": "2017-06-26T13:18:10Z", "attachment_id": null}, {"count": 4, "tags": [], "creator": "fanningpj@yahoo.com", "is_private": false, "text": "Thanks Dominik - I would expect some performance impact but I think it is more robust for the code not to make assumptions about file encodings etc. I also think the SAX code is easier to understand.\nStAX parsers are very fast but it is worth evaluating the impact to see if it is excessive.\nSince SXSSFWorkbook is for writing large files, I think the best performance test would be for me to write a test case that adds a large number of rows and to compare the times for the existing code and my proposed change.", "id": 199431, "time": "2017-06-26T15:03:50Z", "bug_id": 61213, "creation_time": "2017-06-26T15:03:50Z", "attachment_id": null}, {"count": 5, "tags": [], "text": "You can take a look at the FAQ at http://poi.apache.org/faq.html#faq-N10165, it points to a sample which we used for comparing raw performance of HSSF/XSSF/SXSSF in the past.", "is_private": false, "id": 199444, "creator": "dominik.stadler@gmx.at", "time": "2017-06-27T07:26:53Z", "bug_id": 61213, "creation_time": "2017-06-27T07:26:53Z", "attachment_id": null}, {"count": 6, "tags": [], "creator": "fanningpj@yahoo.com", "is_private": false, "text": "I did some initial testing and the Stax based code is significantly slower. I will spend a little more time to see if the performance can be improved.\nhttps://github.com/pjfanning/poi-sxssf-stax - not very scientific but if I use SXSSFWorkbook, the test takes 3 seconds but 25 seconds with the STAX equivalent.", "id": 199496, "time": "2017-06-29T19:23:07Z", "bug_id": 61213, "creation_time": "2017-06-29T19:23:07Z", "attachment_id": null}, {"count": 7, "tags": [], "bug_id": 61213, "attachment_id": null, "text": "This approach is much slower", "id": 199755, "time": "2017-07-13T07:16:28Z", "creator": "fanningpj@yahoo.com", "creation_time": "2017-07-13T07:16:28Z", "is_private": false}]